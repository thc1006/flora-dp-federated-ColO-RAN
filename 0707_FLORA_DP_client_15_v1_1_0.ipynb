{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thc1006/flora-dp-federated-ColO-RAN/blob/main/0707_FLORA_DP_client_15_v1_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 1: ç’°å¢ƒè¨­å®šèˆ‡å‡½å¼åº«åŒ¯å…¥ï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
        "!pip install --upgrade opacus -q\n",
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np, pandas as pd, random, copy, json, os, time, warnings, math, re, contextlib\n",
        "from collections import deque\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from dataclasses import dataclass, asdict\n",
        "from sklearn.cluster import KMeans\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "from opacus.data_loader import DPDataLoader\n",
        "\n",
        "# --- ç’°å¢ƒè¨­å®š ---\n",
        "try: torch._dynamo.disable()\n",
        "except Exception: pass\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=\".*overflow encountered.*\", category=RuntimeWarning)\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "print(\"âœ… Cell 1: ç’°å¢ƒèˆ‡å‡½å¼åº«æº–å‚™å°±ç·’ã€‚\")\n",
        "import opacus\n",
        "print(f\"PyTorch/Opacus ç‰ˆæœ¬: {torch.__version__} / {opacus.__version__}\")\n",
        "print(f\"CUDA æ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8scIko-a3n-",
        "outputId": "dd8f1d50-63dd-4a1e-bfdf-d800cf839ae0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 1: ç’°å¢ƒèˆ‡å‡½å¼åº«æº–å‚™å°±ç·’ã€‚\n",
            "PyTorch/Opacus ç‰ˆæœ¬: 2.6.0+cu124 / 1.5.4\n",
            "CUDA æ˜¯å¦å¯ç”¨: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 2: ğŸ“ å¯¦é©—åƒæ•¸è¨­å®šï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰\n",
        "from dataclasses import dataclass, field\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    \"\"\"\n",
        "    å„²å­˜æ‰€æœ‰å¯¦é©—çš„è¶…åƒæ•¸èˆ‡è¨­å®šã€‚\n",
        "\n",
        "    Attributes:\n",
        "        # å¯¦é©—åŸºæœ¬è¨­å®š\n",
        "        experiment_name (str): å¯¦é©—çš„å”¯ä¸€åç¨±ã€‚\n",
        "        output_dir (str): å„²å­˜çµæœèˆ‡æ¨¡å‹çš„ç›®éŒ„ã€‚\n",
        "        mode (str): è¨“ç·´æ¨¡å¼ï¼Œä¾‹å¦‚ \"ClusteredFL\", \"FedProx\", \"FedAvg\", \"CQL\"ã€‚\n",
        "        random_seed (int): ç”¨æ–¼å¯é‡ç¾æ€§çš„éš¨æ©Ÿç¨®å­ã€‚\n",
        "        comm_rounds (int): è¯é‚¦å­¸ç¿’çš„ç¸½é€šä¿¡è¼ªæ•¸ã€‚\n",
        "\n",
        "        # Non-IID å®¢æˆ¶ç«¯ç”Ÿæˆ (ä»»å‹™ 1)\n",
        "        num_clients (int): è¦ç”Ÿæˆçš„ç¸½å®¢æˆ¶ç«¯æ•¸é‡ã€‚\n",
        "        dirichlet_alpha (float): Dirichlet åˆ†ä½ˆçš„ alpha åƒæ•¸ï¼Œç”¨æ–¼æ§åˆ¶ Non-IID ç¨‹åº¦ã€‚alpha è¶Šå°ï¼Œç•°è³ªæ€§è¶Šé«˜ã€‚\n",
        "        min_samples_per_client (int): ç¢ºä¿æ¯å€‹å®¢æˆ¶ç«¯è‡³å°‘æ“æœ‰çš„æ¨£æœ¬æ•¸ã€‚\n",
        "\n",
        "        # è¯é‚¦å­¸ç¿’è¨­å®š\n",
        "        num_clients_to_select (int): æ¯è¼ªéš¨æ©Ÿé¸æ“‡åƒèˆ‡è¨“ç·´çš„å®¢æˆ¶ç«¯æ•¸é‡ã€‚\n",
        "        fedprox_mu (float): FedProx çš„è¿‘ç«¯é …ä¿‚æ•¸ muã€‚è¨­ç‚º 0 ç­‰åŒæ–¼ FedAvgã€‚\n",
        "        num_clusters (int): åœ¨ ClusteredFL æ¨¡å¼ä¸‹çš„èšé¡æ•¸é‡ã€‚\n",
        "        cluster_update_freq (int): ClusteredFL æ¨¡å¼ä¸‹æ›´æ–°èšé¡çš„é »ç‡ï¼ˆå–®ä½ï¼šè¼ªï¼‰ã€‚\n",
        "\n",
        "        # åŠéåŒæ­¥/å®¹éŒ¯èšåˆ (ä»»å‹™ 4)\n",
        "        async_threshold (float): è§¸ç™¼éåŒæ­¥å¼èšåˆçš„å®¢æˆ¶ç«¯è¶…æ™‚/æ‰ç·šæ¯”ä¾‹é–¾å€¼ã€‚\n",
        "\n",
        "        # RL è¨“ç·´åƒæ•¸\n",
        "        local_episodes_per_round (int): æ¯è¼ªä¸­ï¼Œæ¯å€‹å®¢æˆ¶ç«¯æœ¬åœ°è¨“ç·´çš„ episode æ•¸é‡ã€‚\n",
        "        steps_per_episode (int): æ¯å€‹ episode çš„æœ€å¤§æ­¥æ•¸ã€‚\n",
        "        batch_size (int): è¨“ç·´æ™‚çš„æ‰¹æ¬¡å¤§å°ã€‚\n",
        "        gamma (float): RL ä¸­çš„æŠ˜æ‰£å› å­ã€‚\n",
        "        lr (float): å­¸ç¿’ç‡ã€‚\n",
        "        target_update_freq (int): ç›®æ¨™ç¶²è·¯æ›´æ–°çš„é »ç‡ï¼ˆå–®ä½ï¼šepisodeï¼‰ã€‚\n",
        "\n",
        "        # RL æ¢ç´¢åƒæ•¸\n",
        "        epsilon_start (float): Epsilon-greedy ç­–ç•¥çš„åˆå§‹æ¢ç´¢ç‡ã€‚\n",
        "        epsilon_decay (float): Epsilon çš„è¡°æ¸›ç‡ã€‚\n",
        "        epsilon_min (float): Epsilon çš„æœ€å°å€¼ã€‚\n",
        "\n",
        "        # è¨˜æ†¶é«”èˆ‡å›æ”¾\n",
        "        memory_capacity (int): ç¶“é©—å›æ”¾ç·©è¡å€çš„å¤§å°ã€‚\n",
        "        replay_start_size (int): é–‹å§‹é€²è¡Œç¶“é©—å›æ”¾æ‰€éœ€çš„æœ€å°æ¨£æœ¬æ•¸ã€‚\n",
        "        replay_frequency (int): é€²è¡Œç¶“é©—å›æ”¾çš„é »ç‡ï¼ˆå–®ä½ï¼šæ­¥ï¼‰ã€‚\n",
        "        replay_batches_per_call (int): æ¯æ¬¡èª¿ç”¨ replay æ™‚è¨“ç·´çš„æ‰¹æ¬¡æ•¸é‡ã€‚\n",
        "\n",
        "        # é›¢ç·š RL åå·®æ ¡æ­£ (ä»»å‹™ 2)\n",
        "        enable_cql (bool): æ˜¯å¦å•Ÿç”¨ Conservative Q-Learning (CQL)ã€‚\n",
        "        cql_alpha (float): CQL æå¤±çš„æ¬Šé‡ã€‚\n",
        "        cql_temperature (float): CQL ä¸­ç”¨æ–¼ log-sum-exp çš„æº«åº¦åƒæ•¸ã€‚\n",
        "\n",
        "        # å·®åˆ†éš±ç§ (DP) è¨­å®š\n",
        "        enable_dp (bool): æ˜¯å¦å•Ÿç”¨å·®åˆ†éš±ç§ã€‚\n",
        "        dp_target_epsilon (float): ç›®æ¨™çš„ç¸½éš±ç§é ç®— epsilonã€‚\n",
        "        dp_target_delta (float): ç›®æ¨™çš„ delta å€¼ï¼Œé€šå¸¸ç‚º 1/dataset_sizeã€‚\n",
        "        dp_max_grad_norm (float): æ¯å€‹æ¨£æœ¬æ¢¯åº¦çš„è£å‰ªç¯„æ•¸ (clipping bound)ã€‚\n",
        "        dp_noise_multiplier (float): æ·»åŠ åˆ°æ¢¯åº¦ä¸­çš„å™ªè²ä¹˜æ•¸ã€‚\n",
        "\n",
        "        # Adaptive Clipping (ä»»å‹™ 3)\n",
        "        enable_adaptive_clipping (bool): æ˜¯å¦å•Ÿç”¨è‡ªé©æ‡‰æ¢¯åº¦è£å‰ªé è¨ˆç®—ã€‚\n",
        "        adaptive_clipping_percentile (float): ç”¨æ–¼é è¨ˆç®—çš„æ¢¯åº¦ç¯„æ•¸ç™¾åˆ†ä½æ•¸ã€‚\n",
        "\n",
        "        # DP é‡è¨­æ©Ÿåˆ¶\n",
        "        enable_dp_reset (bool): æ˜¯å¦å…è¨±åœ¨éš±ç§é ç®—è¶…æ”¯æ™‚é‡è¨­éš±ç§æœƒè¨ˆã€‚\n",
        "        dp_reset_threshold_multiplier (float): è§¸ç™¼é‡è¨­çš„é–¾å€¼ (ç›¸å°æ–¼ target_epsilon)ã€‚\n",
        "\n",
        "        # ç³»çµ±èˆ‡ç•°è³ªæ€§è¨­å®š\n",
        "        enable_heterogeneity (bool): æ˜¯å¦æ¨¡æ“¬å®¢æˆ¶ç«¯æ‰ç·š (dropout) å’Œå»¶é² (straggler)ã€‚\n",
        "        straggler_ratio (float): å»¶é²å®¢æˆ¶ç«¯çš„æ¯”ä¾‹ã€‚\n",
        "        dropout_ratio (float): æ‰ç·šå®¢æˆ¶ç«¯çš„æ¯”ä¾‹ã€‚\n",
        "        enable_compression (bool): æ˜¯å¦å•Ÿç”¨æ¨¡å‹å£“ç¸® (quantize_fp16)ã€‚\n",
        "        use_pfl_finetune (bool): æ˜¯å¦åœ¨è©•ä¼°æ™‚åŸ·è¡Œå€‹æ€§åŒ–å¾®èª¿ (PFL)ã€‚\n",
        "        local_finetune_episodes (int): PFL å¾®èª¿çš„ episode æ•¸é‡ã€‚\n",
        "        device (str): è¨“ç·´è¨­å‚™ (\"cuda\" æˆ– \"cpu\")ã€‚\n",
        "    \"\"\"\n",
        "    # å¯¦é©—åŸºæœ¬è¨­å®š\n",
        "    experiment_name: str = \"DFRL_Experiment\"\n",
        "    output_dir: str = \"outputs\"\n",
        "    mode: str = \"ClusteredFL\"\n",
        "    random_seed: int = 42\n",
        "    comm_rounds: int = 20\n",
        "\n",
        "    # Non-IID å®¢æˆ¶ç«¯ç”Ÿæˆ (ä»»å‹™ 1)\n",
        "    num_clients: int = 15\n",
        "    dirichlet_alpha: float = 0.4\n",
        "    min_samples_per_client: int = 500\n",
        "\n",
        "    # è¯é‚¦å­¸ç¿’è¨­å®š\n",
        "    num_clients_to_select: int = 8\n",
        "    fedprox_mu: float = 0.01\n",
        "    num_clusters: int = 3\n",
        "    cluster_update_freq: int = 8\n",
        "\n",
        "    # åŠéåŒæ­¥/å®¹éŒ¯èšåˆ (ä»»å‹™ 4)\n",
        "    async_threshold: float = 0.3\n",
        "\n",
        "    # RL è¨“ç·´åƒæ•¸\n",
        "    local_episodes_per_round: int = 5\n",
        "    steps_per_episode: int = 500\n",
        "    batch_size: int = 128\n",
        "    gamma: float = 0.99\n",
        "    lr: float = 1e-4\n",
        "    target_update_freq: int = 15\n",
        "\n",
        "    # RL æ¢ç´¢åƒæ•¸\n",
        "    epsilon_start: float = 1.0\n",
        "    epsilon_decay: float = 0.9995\n",
        "    epsilon_min: float = 0.05\n",
        "\n",
        "    # è¨˜æ†¶é«”èˆ‡å›æ”¾\n",
        "    memory_capacity: int = 50000\n",
        "    replay_start_size: int = 1000\n",
        "    replay_frequency: int = 2\n",
        "    replay_batches_per_call: int = 2\n",
        "\n",
        "    # é›¢ç·š RL åå·®æ ¡æ­£ (ä»»å‹™ 2)\n",
        "    enable_cql: bool = False\n",
        "    cql_alpha: float = 5.0\n",
        "    cql_temperature: float = 1.0\n",
        "\n",
        "    # å·®åˆ†éš±ç§ (DP) è¨­å®š\n",
        "    enable_dp: bool = True\n",
        "    dp_target_epsilon: float = 8.0\n",
        "    dp_target_delta: float = 1e-5\n",
        "    dp_max_grad_norm: float = 1.0\n",
        "    dp_noise_multiplier: float = 0.5\n",
        "\n",
        "    # Adaptive Clipping (ä»»å‹™ 3)\n",
        "    enable_adaptive_clipping: bool = False\n",
        "    adaptive_clipping_percentile: float = 0.75\n",
        "\n",
        "    # DP é‡è¨­æ©Ÿåˆ¶\n",
        "    enable_dp_reset: bool = True\n",
        "    dp_reset_threshold_multiplier: float = 1.5\n",
        "\n",
        "    # ç³»çµ±èˆ‡ç•°è³ªæ€§è¨­å®š\n",
        "    enable_heterogeneity: bool = True\n",
        "    straggler_ratio: float = 0.1\n",
        "    dropout_ratio: float = 0.05\n",
        "    enable_compression: bool = True\n",
        "    compression_type: str = \"quantize_fp16\" # ä¿æŒæ­¤åƒæ•¸ä»¥å…¼å®¹\n",
        "    use_pfl_finetune: bool = True\n",
        "    local_finetune_episodes: int = 15\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"å¾Œè™•ç†è¨­å®šï¼Œé€²è¡Œå‹•æ…‹æª¢æŸ¥èˆ‡é…ç½®ã€‚\"\"\"\n",
        "        # GPU ç’°å¢ƒæª¢æ¸¬\n",
        "        if self.device == \"cuda\" and torch.cuda.is_available():\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            print(f\"ğŸš€ GPU ç’°å¢ƒæª¢æ¸¬åˆ°: {gpu_name}\")\n",
        "        else:\n",
        "            self.device = \"cpu\"\n",
        "            print(\"ğŸ’» ä½¿ç”¨ CPU æ¨¡å¼\")\n",
        "\n",
        "        # æ¨¡å¼ç‰¹å®šè¨­å®š\n",
        "        if self.mode == 'Centralized':\n",
        "            self.enable_dp = False\n",
        "            self.enable_heterogeneity = False\n",
        "            print(\"ğŸ”¹ é›†ä¸­å¼è¨“ç·´æ¨¡å¼ï¼Œå·²è‡ªå‹•ç¦ç”¨ DP å’Œç•°è³ªæ€§æ¨¡æ“¬ã€‚\")\n",
        "\n",
        "        if self.mode == \"FedAvg\":\n",
        "            self.fedprox_mu = 0.0\n",
        "            print(\"ğŸ”¹ FedAvg æ¨¡å¼ï¼Œfedprox_mu å·²è¨­ç‚º 0ã€‚\")\n",
        "\n",
        "        if self.mode == \"CQL\":\n",
        "            self.enable_cql = True\n",
        "            print(\"ğŸ”¹ CQL æ¨¡å¼ï¼Œå·²å•Ÿç”¨ Conservative Q-Learningã€‚\")\n",
        "\n",
        "        # é¡¯ç¤ºæ ¸å¿ƒé…ç½®\n",
        "        print(f\"\\n--- æ ¸å¿ƒå¯¦é©—é…ç½® ---\")\n",
        "        print(f\"æ¨¡å¼: {self.mode} | å®¢æˆ¶ç«¯æ•¸: {self.num_clients} (Non-IID, Î±={self.dirichlet_alpha})\")\n",
        "        print(f\"æ¯è¼ªåƒèˆ‡: {self.num_clients_to_select} | é€šä¿¡è¼ªæ•¸: {self.comm_rounds}\")\n",
        "\n",
        "        if self.enable_dp and self.mode != 'Centralized':\n",
        "            print(f\"ğŸ›¡ï¸  å·®åˆ†éš±ç§ (DP): å•Ÿç”¨\")\n",
        "            print(f\"   - ç›®æ¨™é ç®—: Îµ={self.dp_target_epsilon}, Î´={self.dp_target_delta}\")\n",
        "            print(f\"   - å™ªè²ä¹˜æ•¸: {self.dp_noise_multiplier}\")\n",
        "            print(f\"   - æ¢¯åº¦è£å‰ª: {'è‡ªé©æ‡‰' if self.enable_adaptive_clipping else f'å›ºå®š({self.dp_max_grad_norm})'}\")\n",
        "            print(f\"   - é ç®—é‡è¨­: {'å•Ÿç”¨' if self.enable_dp_reset else 'ç¦ç”¨'}\")\n",
        "        else:\n",
        "            print(f\"ğŸ›¡ï¸  å·®åˆ†éš±ç§ (DP): ç¦ç”¨\")\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\"å°‡ç•¶å‰é…ç½®ä»¥ JSON æ ¼å¼ä¿å­˜åˆ°è¼¸å‡ºç›®éŒ„ã€‚\"\"\"\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        path = os.path.join(self.output_dir, f'{self.experiment_name}_config.json')\n",
        "        # å°‡ dataclass è½‰æ›ç‚ºå¯åºåˆ—åŒ–çš„å­—å…¸\n",
        "        config_dict = asdict(self)\n",
        "        with open(path, 'w') as f:\n",
        "            json.dump(config_dict, f, indent=4)\n",
        "        print(f\"âœ… é…ç½®å·²ä¿å­˜è‡³: {path}\")\n",
        "\n",
        "print(\"âœ… Cell 2: TrainingConfigï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPCaXasOa6sn",
        "outputId": "684b4832-20a7-48bc-ef36-5a1013f44f6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 2: TrainingConfigï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 3: ğŸ§© æ•¸æ“šèˆ‡ç’°å¢ƒæº–å‚™ï¼ˆNon-IID å°ˆå®¶ä¿®æ­£ç‰ˆï¼‰\n",
        "from typing import Dict # <--- ä¿®æ­£ï¼šåŠ å…¥æ­¤è¡ŒåŒ¯å…¥èªå¥\n",
        "\n",
        "class DataManager:\n",
        "    \"\"\"\n",
        "    è² è²¬æ•¸æ“šçš„è®€å–ã€é è™•ç†ã€ä»¥åŠ Non-IID å®¢æˆ¶ç«¯æ•¸æ“šåˆ‡åˆ†ã€‚\n",
        "    ä»»å‹™ 1 çš„ä¸»è¦å¯¦ä½œåœ¨æ­¤é¡åˆ¥ä¸­ã€‚\n",
        "    \"\"\"\n",
        "    def __init__(self, data_path: str, config: 'TrainingConfig'):\n",
        "        \"\"\"\n",
        "        åˆå§‹åŒ– DataManagerã€‚\n",
        "\n",
        "        Args:\n",
        "            data_path (str): Parquet æ•¸æ“šæ–‡ä»¶çš„è·¯å¾‘ã€‚\n",
        "            config (TrainingConfig): å¯¦é©—é…ç½®å°è±¡ã€‚\n",
        "        \"\"\"\n",
        "        print(f\"\\n[DataManager] æ­£åœ¨å¾ {data_path} è®€å–æ•¸æ“š...\")\n",
        "        self.df_kpi = pd.read_parquet(data_path)\n",
        "        self.config = config\n",
        "        self.tput_col = None\n",
        "        self.lat_col = None\n",
        "        self._sanitize_column_names()\n",
        "        self._preflight_check()\n",
        "\n",
        "    def _sanitize_column_names(self):\n",
        "        \"\"\"æ¸…ç† DataFrame çš„æ¬„ä½åç¨±ï¼Œä½¿å…¶æ›´æ˜“æ–¼ä½¿ç”¨ã€‚\"\"\"\n",
        "        sanitized_columns = [re.sub(r'[\\\\[\\\\]\\\\(\\\\)%\\\\s\\\\.-]+', '_', col.strip().lower()).strip('_')\n",
        "                           for col in self.df_kpi.columns]\n",
        "        self.df_kpi.columns = sanitized_columns\n",
        "\n",
        "    def _preflight_check(self):\n",
        "        \"\"\"\n",
        "        åŸ·è¡Œå•Ÿå‹•å‰çš„æ•¸æ“šé æª¢æŸ¥ï¼Œç¢ºä¿å¿…è¦æ¬„ä½å­˜åœ¨ã€‚\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*20 + \" DataManager å•Ÿå‹•å‰é æª¢æŸ¥ \" + \"=\"*20)\n",
        "        cols = self.df_kpi.columns.tolist()\n",
        "        tput_cand = ['throughput_dl_mbps', 'tx_brate_downlink_mbps']\n",
        "        lat_cand = ['buffer_occupancy_dl_bytes', 'dl_buffer_bytes']\n",
        "\n",
        "        self.tput_col = next((c for c in tput_cand if c in cols), None)\n",
        "        self.lat_col = next((c for c in lat_cand if c in cols), None)\n",
        "\n",
        "        print(f\"âœ… æ¸…ç†å¾Œçš„æ¬„ä½åˆ—è¡¨ (å…± {len(cols)} å€‹)\")\n",
        "        if not self.tput_col or not self.lat_col:\n",
        "            raise ValueError(\"é æª¢æŸ¥å¤±æ•—: æ‰¾ä¸åˆ°å¿…è¦çš„ååé‡æˆ–å»¶é²æ•¸æ“šæ¬„ä½ã€‚\")\n",
        "\n",
        "        print(f\"   - ååé‡æ¬„ä½æˆåŠŸåŒ¹é…: '{self.tput_col}'\")\n",
        "        print(f\"   - å»¶é²/ç·©è¡å€æ¬„ä½æˆåŠŸåŒ¹é…: '{self.lat_col}'\")\n",
        "        print(\"=\"*65 + \"\\n\")\n",
        "\n",
        "    def _get_merged_trajectory(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        å°‡ä¸åŒåŸºç«™å’Œåˆ‡ç‰‡çš„æ•¸æ“šåˆä½µæˆä¸€å€‹çµ±ä¸€çš„æ™‚é–“åºåˆ— DataFrameã€‚\n",
        "        é€™æ˜¯ Non-IID åˆ‡åˆ†çš„åŸºç¤ã€‚\n",
        "        \"\"\"\n",
        "        print(\"[DataManager] æ­£åœ¨åˆä½µ eMBB å’Œ URLLC çš„æ•¸æ“šè»Œè·¡...\")\n",
        "        available_bs = sorted(self.df_kpi['bs_id'].unique())\n",
        "        all_merged_dfs = []\n",
        "\n",
        "        # æˆ‘å€‘éœ€è¦ä¸€å€‹åƒè€ƒBSä¾†é€²è¡Œåˆä½µï¼Œé€™è£¡é¸æ“‡ç¬¬ä¸€å€‹å¯ç”¨çš„BS\n",
        "        # ä½†å¯¦éš›ä¸Šï¼Œæˆ‘å€‘æ‡‰è©²å°‡æ‰€æœ‰BSçš„æ•¸æ“šéƒ½è¦–ç‚ºä¸€å€‹å¤§çš„æ•¸æ“šæ± \n",
        "        # é€™è£¡æˆ‘å€‘ç°¡åŒ–è™•ç†ï¼Œå°‡æ‰€æœ‰æ•¸æ“šåˆä½µ\n",
        "        df_embb = self.df_kpi[self.df_kpi['slice_id'] == 0]\n",
        "        df_urllc = self.df_kpi[self.df_kpi['slice_id'] == 2]\n",
        "\n",
        "        # é‡å‘½åä»¥é¿å…åˆä½µè¡çª\n",
        "        df_embb = df_embb[['timestamp', self.tput_col, self.lat_col]].rename(\n",
        "            columns={self.tput_col: 'throughput_embb', self.lat_col: 'latency_embb'}\n",
        "        ).dropna()\n",
        "        df_urllc = df_urllc[['timestamp', self.tput_col, self.lat_col]].rename(\n",
        "            columns={self.tput_col: 'throughput_urllc', self.lat_col: 'latency_urllc'}\n",
        "        ).dropna()\n",
        "\n",
        "        # ä½¿ç”¨ merge_asof å°‡å…©å€‹åˆ‡ç‰‡çš„æ•¸æ“šæŒ‰æ™‚é–“å°é½Š\n",
        "        merged_df = pd.merge_asof(\n",
        "            df_embb.sort_values('timestamp'),\n",
        "            df_urllc.sort_values('timestamp'),\n",
        "            on='timestamp',\n",
        "            direction='backward',\n",
        "            tolerance=pd.Timedelta('150ms') # ä½¿ç”¨åŸå§‹æ•¸æ“šçš„å®¹å¿åº¦\n",
        "        ).dropna()\n",
        "\n",
        "        # æ•¸æ“šæ¸…ç†\n",
        "        merged_df = merged_df[\n",
        "            (merged_df['throughput_embb'] >= 0) & (merged_df['throughput_urllc'] >= 0) &\n",
        "            (merged_df['latency_embb'] >= 0) & (merged_df['latency_urllc'] >= 0)\n",
        "        ]\n",
        "        print(f\"[DataManager] å…¨å±€æ•¸æ“šè»Œè·¡åˆä½µå®Œæˆï¼Œå…± {len(merged_df)} å€‹æ™‚é–“æ­¥ã€‚\")\n",
        "        return merged_df.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "    def create_non_iid_partitions(self) -> Dict[int, np.ndarray]:\n",
        "        \"\"\"\n",
        "        (ä»»å‹™ 1 æ ¸å¿ƒå¯¦ç¾)\n",
        "        ä½¿ç”¨ Dirichlet åˆ†ä½ˆç”Ÿæˆ Non-IID çš„å®¢æˆ¶ç«¯æ•¸æ“šåˆ†å€ã€‚\n",
        "\n",
        "        Returns:\n",
        "            ä¸€å€‹å­—å…¸ï¼Œéµæ˜¯å®¢æˆ¶ç«¯ IDï¼Œå€¼æ˜¯å°æ‡‰çš„æ•¸æ“šè»Œè·¡ (numpy array)ã€‚\n",
        "        \"\"\"\n",
        "        print(f\"\\n[DataManager] æ­£åœ¨ç‚º {self.config.num_clients} å€‹å®¢æˆ¶ç«¯ç”Ÿæˆ Non-IID æ•¸æ“šåˆ†å€...\")\n",
        "        print(f\"   - Dirichlet Alpha (Î±): {self.config.dirichlet_alpha}\")\n",
        "\n",
        "        # 1. ç²å–åˆä½µå¾Œçš„å…¨å±€æ•¸æ“š\n",
        "        merged_df = self._get_merged_trajectory()\n",
        "        if merged_df.empty:\n",
        "            raise ValueError(\"åˆä½µå¾Œçš„å…¨å±€æ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œåˆ‡åˆ†ã€‚\")\n",
        "\n",
        "        # 2. ä½¿ç”¨ Dirichlet åˆ†ä½ˆç”Ÿæˆæ¯å€‹å®¢æˆ¶ç«¯çš„æ•¸æ“šæ¯”ä¾‹\n",
        "        # np.random.seed(self.config.random_seed) # ç¢ºä¿åˆ‡åˆ†å¯é‡ç¾\n",
        "        proportions = np.random.dirichlet(np.repeat(self.config.dirichlet_alpha, self.config.num_clients))\n",
        "\n",
        "        # 3. æ ¹æ“šæ¯”ä¾‹åˆ‡åˆ†æ•¸æ“šç´¢å¼•\n",
        "        total_samples = len(merged_df)\n",
        "        client_indices = {}\n",
        "        start_idx = 0\n",
        "        for i in range(self.config.num_clients):\n",
        "            num_samples = int(total_samples * proportions[i])\n",
        "            # ç¢ºä¿æ¯å€‹å®¢æˆ¶ç«¯éƒ½æœ‰æœ€å°‘çš„æ•¸æ“šé‡\n",
        "            if num_samples < self.config.min_samples_per_client:\n",
        "                # å¦‚æœåˆ†é…çš„å¤ªå°‘ï¼Œå‰‡å¾å…¶ä»–åœ°æ–¹\"å€Ÿ\"ä¸€äº›ï¼Œé€™æœƒç¨å¾®æ”¹è®Šåˆ†ä½ˆï¼Œä½†åœ¨å¯¦å‹™ä¸Šå¯æ¥å—\n",
        "                num_samples = self.config.min_samples_per_client\n",
        "\n",
        "            end_idx = min(start_idx + num_samples, total_samples)\n",
        "            client_indices[i] = merged_df.index[start_idx:end_idx]\n",
        "            start_idx = end_idx\n",
        "            if start_idx >= total_samples:\n",
        "                break # æ•¸æ“šå·²å…¨éƒ¨åˆ†é…å®Œç•¢\n",
        "\n",
        "        # å¦‚æœå› ç‚º min_samples_per_client çš„é™åˆ¶å°è‡´å®¢æˆ¶ç«¯æ•¸é‡ä¸è¶³ï¼Œéœ€è¦èª¿æ•´\n",
        "        num_created_clients = len(client_indices)\n",
        "        if num_created_clients < self.config.num_clients:\n",
        "            print(f\"ğŸŸ¡ è­¦å‘Š: ç”±æ–¼ min_samples_per_client çš„é™åˆ¶ï¼Œå¯¦éš›ç”Ÿæˆçš„å®¢æˆ¶ç«¯æ•¸é‡ç‚º {num_created_clients}\")\n",
        "            self.config.num_clients = num_created_clients # æ›´æ–°é…ç½®ä»¥åæ˜ å¯¦éš›æƒ…æ³\n",
        "\n",
        "        # 4. å‰µå»ºæœ€çµ‚çš„è»Œè·¡å­—å…¸\n",
        "        client_trajectories = {}\n",
        "        feature_cols = ['throughput_embb', 'latency_embb', 'throughput_urllc', 'latency_urllc']\n",
        "\n",
        "        for client_id, indices in tqdm(client_indices.items(), desc=\"å‰µå»ºå®¢æˆ¶ç«¯è»Œè·¡\"):\n",
        "            client_df = merged_df.loc[indices]\n",
        "            trajectory = client_df[feature_cols].to_numpy(dtype=np.float32)\n",
        "            client_trajectories[client_id] = trajectory\n",
        "            print(f\"   - å®¢æˆ¶ç«¯ {client_id}: {len(trajectory)} å€‹æ™‚é–“æ­¥\")\n",
        "\n",
        "        num_valid = sum(1 for traj in client_trajectories.values() if traj.size > 0)\n",
        "        print(f\"\\n[DataManager] Non-IID æ•¸æ“šè™•ç†å®Œæˆï¼æˆåŠŸç‚º {num_valid} / {self.config.num_clients} å€‹å®¢æˆ¶ç«¯å‰µå»ºäº†ç’°å¢ƒã€‚\")\n",
        "        return client_trajectories\n",
        "\n",
        "print(\"âœ… Cell 3: DataManagerï¼ˆNon-IID å°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "4F6yYVmKa-hN",
        "outputId": "36e753c3-375b-4320-db78-d89483c21f8a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 3: DataManagerï¼ˆNon-IID å°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 4: âš¡ RLç’°å¢ƒèˆ‡æ•¸æ“šè™•ç†ï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰\n",
        "import gc\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import contextlib\n",
        "from collections import deque\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "class PairedEnv:\n",
        "    \"\"\"\n",
        "    é…å°æœå‹™ (eMBB/URLLC) çš„å¼·åŒ–å­¸ç¿’ç’°å¢ƒã€‚\n",
        "    ä»£è¡¨å–®ä¸€å®¢æˆ¶ç«¯çš„æœ¬åœ°ç’°å¢ƒã€‚\n",
        "    \"\"\"\n",
        "    def __init__(self, trajectory: np.ndarray, config: TrainingConfig):\n",
        "        \"\"\"\n",
        "        åˆå§‹åŒ–ç’°å¢ƒã€‚\n",
        "\n",
        "        Args:\n",
        "            trajectory (np.ndarray): å®¢æˆ¶ç«¯çš„æ•¸æ“šè»Œè·¡ï¼Œå½¢ç‹€ç‚º (n_steps, 4)ã€‚\n",
        "            config (TrainingConfig): å¯¦é©—é…ç½®ã€‚\n",
        "        \"\"\"\n",
        "        self.trajectory = trajectory\n",
        "        self.config = config\n",
        "        # ç‹€æ…‹ç¶­åº¦ï¼š[throughput_embb, latency_embb, throughput_urllc, latency_urllc]\n",
        "        self.state_size = trajectory.shape[1] if trajectory.size > 0 else 4\n",
        "        # å‹•ä½œç©ºé–“ï¼š[0: åé‡eMBB, 1: å¹³è¡¡, 2: åé‡URLLC]\n",
        "        self.action_size = 3\n",
        "        self.cursor = 0\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        é‡ç½®ç’°å¢ƒåˆ°ä¸€å€‹æ–°çš„èµ·å§‹é»ã€‚\n",
        "\n",
        "        Returns:\n",
        "            åˆå§‹ç‹€æ…‹ã€‚\n",
        "        \"\"\"\n",
        "        if self.trajectory.size == 0:\n",
        "            return np.zeros(self.state_size, dtype=np.float32)\n",
        "\n",
        "        # ç‚ºäº†è®“æ¯å€‹ episode éƒ½æ˜¯å®Œæ•´çš„ï¼Œå¾è»Œè·¡çš„è¼ƒæ—©éƒ¨åˆ†é–‹å§‹\n",
        "        max_start = max(0, len(self.trajectory) - self.config.steps_per_episode)\n",
        "        # éš¨æ©Ÿé¸æ“‡èµ·å§‹é»ä»¥å¢åŠ å¤šæ¨£æ€§\n",
        "        if max_start > 0:\n",
        "            self.cursor = np.random.randint(0, max_start)\n",
        "        else:\n",
        "            self.cursor = 0\n",
        "        return self.trajectory[self.cursor]\n",
        "\n",
        "    def step(self, action_id: int) -> Tuple[np.ndarray, float, bool, dict]:\n",
        "        \"\"\"\n",
        "        åœ¨ç’°å¢ƒä¸­åŸ·è¡Œä¸€æ­¥ã€‚\n",
        "\n",
        "        Args:\n",
        "            action_id (int): é¸æ“‡çš„å‹•ä½œ IDã€‚\n",
        "\n",
        "        Returns:\n",
        "            ä¸€å€‹å…ƒçµ„ (next_state, reward, done, info)ã€‚\n",
        "        \"\"\"\n",
        "        if self.trajectory.size == 0 or self.cursor >= len(self.trajectory) - 1:\n",
        "            # å¦‚æœè»Œè·¡çµæŸæˆ–ç‚ºç©ºï¼Œè¿”å›çµ‚æ­¢ç‹€æ…‹\n",
        "            state = self.trajectory[-1] if self.trajectory.size > 0 else np.zeros(self.state_size, dtype=np.float32)\n",
        "            return state, 0.0, True, {}\n",
        "\n",
        "        self.cursor += 1\n",
        "        done = self.cursor >= (len(self.trajectory) - 1)\n",
        "        state = self.trajectory[self.cursor]\n",
        "        reward = self._compute_reward(state, action_id)\n",
        "        return state, reward, done, {}\n",
        "\n",
        "    def _compute_reward(self, state: np.ndarray, action_id: int) -> float:\n",
        "        \"\"\"\n",
        "        æ ¹æ“šç•¶å‰ç‹€æ…‹å’Œå‹•ä½œè¨ˆç®—çå‹µã€‚\n",
        "        çå‹µå‡½æ•¸æ—¨åœ¨æœ€å¤§åŒ–ååé‡ï¼ŒåŒæ™‚æœ€å°åŒ–å»¶é²æ‡²ç½°ã€‚\n",
        "\n",
        "        Args:\n",
        "            state (np.ndarray): ç•¶å‰ç‹€æ…‹ã€‚\n",
        "            action_id (int): åŸ·è¡Œçš„å‹•ä½œã€‚\n",
        "\n",
        "        Returns:\n",
        "            è¨ˆç®—å‡ºçš„çå‹µå€¼ã€‚\n",
        "        \"\"\"\n",
        "        tput_embb, lat_embb, tput_urllc, lat_urllc = state\n",
        "\n",
        "        # æ ¹æ“šå‹•ä½œ ID èª¿æ•´æ¬Šé‡\n",
        "        if action_id == 0:  # åé‡ eMBB\n",
        "            w_tput, w_lat = (0.7, 0.3)\n",
        "        elif action_id == 2:  # åé‡ URLLC\n",
        "            w_tput, w_lat = (0.3, 0.7)\n",
        "        else:  # å¹³è¡¡\n",
        "            w_tput, w_lat = (0.5, 0.5)\n",
        "\n",
        "        # ä½¿ç”¨ log1p è™•ç†ååé‡ï¼Œä½¿å…¶å°ºåº¦æ›´å¹³æ»‘\n",
        "        tput_reward = w_tput * (np.log1p(tput_embb) + 0.5 * np.log1p(tput_urllc))\n",
        "        # ä½¿ç”¨ tanh å°‡å»¶é²æ‡²ç½°é™åˆ¶åœ¨ [-1, 1] ç¯„åœå…§\n",
        "        lat_penalty = w_lat * (np.tanh(lat_urllc * 1e-6) + 0.3 * np.tanh(lat_embb * 1e-6))\n",
        "\n",
        "        reward_val = tput_reward - lat_penalty\n",
        "        # è™•ç†æ½›åœ¨çš„ NaN æˆ– inf å€¼\n",
        "        return float(np.nan_to_num(reward_val, nan=0.0, posinf=10.0, neginf=-10.0))\n",
        "\n",
        "class RLDataset(Dataset):\n",
        "    \"\"\"ç”¨æ–¼å¼·åŒ–å­¸ç¿’ç¶“é©—å›æ”¾çš„ PyTorch æ•¸æ“šé›†ã€‚\"\"\"\n",
        "    def __init__(self, memory_deque: deque):\n",
        "        self.data = list(memory_deque)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        state, action, reward, next_state, done = self.data[idx]\n",
        "        return (\n",
        "            torch.from_numpy(state).float(),\n",
        "            torch.tensor(action).long(),\n",
        "            torch.tensor(reward).float(),\n",
        "            torch.from_numpy(next_state).float(),\n",
        "            torch.tensor(done).bool()\n",
        "        )\n",
        "\n",
        "def get_data_loader(agent_memory: deque, batch_size: int, device: str) -> DataLoader:\n",
        "    \"\"\"\n",
        "    å‰µå»ºä¸€å€‹ç”¨æ–¼ RL è¨“ç·´çš„æ•¸æ“šåŠ è¼‰å™¨ã€‚\n",
        "    é‡å° GPU é€²è¡Œäº†å„ªåŒ–ï¼Œä¾‹å¦‚ä½¿ç”¨ pin_memoryã€‚\n",
        "    \"\"\"\n",
        "    if len(agent_memory) < batch_size:\n",
        "        return None\n",
        "\n",
        "    dataset = RLDataset(agent_memory)\n",
        "    # æ ¹æ“š CPU æ ¸å¿ƒæ•¸è‡ªå‹•èª¿æ•´ num_workers\n",
        "    num_workers = min(os.cpu_count() // 2, 4) if torch.cuda.is_available() else 0\n",
        "\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=(device == 'cuda'),\n",
        "        drop_last=True,\n",
        "        persistent_workers= (num_workers > 0)\n",
        "    )\n",
        "\n",
        "def setup_gpu_environment():\n",
        "    \"\"\"çµ±ä¸€çš„ GPU ç’°å¢ƒè¨­å®šå‡½æ•¸ã€‚\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"\\nğŸ® GPU æª¢æ¸¬: {gpu_name}\")\n",
        "        # å•Ÿç”¨ cudnn auto-tunerï¼Œé€™æœƒå°‹æ‰¾æœ€å„ªçš„å·ç©ç®—æ³•\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        # å…è¨± PyTorch ä½¿ç”¨ TF32 ä¾†åŠ é€ŸçŸ©é™£ä¹˜æ³•ï¼ˆåœ¨ Ampere æ¶æ§‹åŠæ›´æ–°çš„ GPU ä¸Šï¼‰\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "        # æ¸…ç†ç·©å­˜\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(f\"ğŸ§¹ GPU ç’°å¢ƒå·²è¨­å®šä¸¦å„ªåŒ–ã€‚\")\n",
        "    else:\n",
        "        print(\"âš ï¸ æœªæª¢æ¸¬åˆ° GPUï¼Œå°‡ä½¿ç”¨ CPU æ¨¡å¼é‹è¡Œã€‚\")\n",
        "\n",
        "\n",
        "print(\"âœ… Cell 4: RLç’°å¢ƒèˆ‡æ•¸æ“šè™•ç†ï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgzjWl9gbAcl",
        "outputId": "ae66ddfa-fef2-4ec4-85ff-0d94360902c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 4: RLç’°å¢ƒèˆ‡æ•¸æ“šè™•ç†ï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 5: ğŸ›¡ï¸ æ ¸å¿ƒå­¸ç¿’ä»£ç†ï¼ˆCQL & Adaptive Clipping å°ˆå®¶ä¿®æ­£ç‰ˆï¼‰\n",
        "import gc\n",
        "import time\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "from opacus.accountants.utils import get_noise_multiplier\n",
        "\n",
        "class AdaptiveClipper:\n",
        "    \"\"\"\n",
        "    (ä»»å‹™ 3 æ ¸å¿ƒé¡åˆ¥)\n",
        "    ä¸€å€‹è¼”åŠ©é¡ï¼Œç”¨æ–¼è¿½è¸ªæ¢¯åº¦ç¯„æ•¸ä¸¦å»ºè­°è‡ªé©æ‡‰çš„è£å‰ªå€¼ã€‚\n",
        "    \"\"\"\n",
        "    def __init__(self, percentile: float, window_size: int = 100):\n",
        "        \"\"\"\n",
        "        åˆå§‹åŒ–è‡ªé©æ‡‰è£å‰ªå™¨ã€‚\n",
        "\n",
        "        Args:\n",
        "            percentile (float): ç”¨æ–¼ç¢ºå®šè£å‰ªå€¼çš„æ¢¯åº¦ç¯„æ•¸ç™¾åˆ†ä½æ•¸ã€‚\n",
        "            window_size (int): ç”¨æ–¼è¨ˆç®—ç™¾åˆ†ä½æ•¸çš„ç§»å‹•çª—å£å¤§å°ã€‚\n",
        "        \"\"\"\n",
        "        self.percentile = percentile\n",
        "        self.grad_norm_history = deque(maxlen=window_size)\n",
        "        self.suggested_clip_norm = 1.0  # åˆå§‹é è¨­å€¼\n",
        "\n",
        "    def track_grad_norm(self, model: nn.Module):\n",
        "        \"\"\"\n",
        "        è¨ˆç®—ä¸¦è¿½è¸ªæ¨¡å‹åƒæ•¸çš„æ¢¯åº¦ç¸½ç¯„æ•¸ã€‚\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): æ­£åœ¨è¨“ç·´çš„æ¨¡å‹ã€‚\n",
        "        \"\"\"\n",
        "        total_norm = 0.0\n",
        "        # Opacus åŒ…è£çš„æ¨¡å‹ï¼Œåƒæ•¸åœ¨ _module ä¸­\n",
        "        params = model._module.parameters() if hasattr(model, '_module') else model.parameters()\n",
        "        for p in params:\n",
        "            if p.grad is not None:\n",
        "                param_norm = p.grad.data.norm(2)\n",
        "                total_norm += param_norm.item() ** 2\n",
        "        total_norm = total_norm ** 0.5\n",
        "        self.grad_norm_history.append(total_norm)\n",
        "\n",
        "    def update_clip_norm(self):\n",
        "        \"\"\"\n",
        "        æ ¹æ“šæ­·å²æ¢¯åº¦ç¯„æ•¸æ›´æ–°å»ºè­°çš„è£å‰ªå€¼ã€‚\n",
        "        \"\"\"\n",
        "        if len(self.grad_norm_history) > 20: # éœ€è¦è¶³å¤ çš„æ•¸æ“šé»\n",
        "            self.suggested_clip_norm = float(np.percentile(list(self.grad_norm_history), self.percentile * 100))\n",
        "\n",
        "class RLAgent:\n",
        "    \"\"\"\n",
        "    å¼·åŒ–å­¸ç¿’ä»£ç†ï¼Œå°è£äº† DQN æ¨¡å‹ã€è¨“ç·´é‚è¼¯å’Œå·®åˆ†éš±ç§ã€‚\n",
        "    \"\"\"\n",
        "    def __init__(self, state_size: int, action_size: int, config: TrainingConfig, client_id: int,\n",
        "                 dataset_size: int, is_eval_agent: bool = False):\n",
        "        self.state_size, self.action_size, self.config = state_size, action_size, config\n",
        "        self.client_id, self.dataset_size = client_id, dataset_size\n",
        "        self.device = torch.device(config.device)\n",
        "        self.mu = self.config.fedprox_mu\n",
        "        self.gamma, self.epsilon = config.gamma, config.epsilon_start\n",
        "        self.memory = deque(maxlen=config.memory_capacity)\n",
        "        self.global_params = None\n",
        "        self.is_eval_agent = is_eval_agent\n",
        "        self.privacy_engine = None\n",
        "        self.current_epsilon = 0.0\n",
        "\n",
        "        self.model = self._build_model()\n",
        "        self.target_model = self._build_model()\n",
        "        self.update_target_model()\n",
        "        self.target_model.eval()\n",
        "\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=config.lr)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        if self.config.enable_cql:\n",
        "            print(f\"[C-{self.client_id}] ğŸ§  CQL æ¨¡å¼å•Ÿç”¨ (alpha={self.config.cql_alpha})\")\n",
        "\n",
        "        if self.config.enable_dp and not self.is_eval_agent and self.config.mode != 'Centralized':\n",
        "            self._initialize_dp_engine()\n",
        "\n",
        "    def _build_model(self) -> nn.Module:\n",
        "        \"\"\"å»ºç«‹ DQN ç¥ç¶“ç¶²è·¯æ¨¡å‹ã€‚\"\"\"\n",
        "        model = nn.Sequential(\n",
        "            nn.Linear(self.state_size, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 64), nn.ReLU(),\n",
        "            nn.Linear(64, self.action_size)\n",
        "        ).to(self.device)\n",
        "        # å¦‚æœå•Ÿç”¨DPï¼Œé å…ˆä¿®å¾©æ¨¡å‹ä»¥ç¢ºä¿èˆ‡Opacuså…¼å®¹\n",
        "        if self.config.enable_dp and not ModuleValidator.is_valid(model):\n",
        "            model = ModuleValidator.fix(model)\n",
        "        return model\n",
        "\n",
        "    def _initialize_dp_engine(self):\n",
        "        \"\"\"åˆå§‹åŒ– Opacus çš„å·®åˆ†éš±ç§å¼•æ“ã€‚\"\"\"\n",
        "        print(f\"[C-{self.client_id}] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\")\n",
        "        try:\n",
        "            self.privacy_engine = PrivacyEngine(accountant=\"gdp\")\n",
        "            # å‰µå»ºä¸€å€‹å‡çš„ DataLoader ä¾†åˆå§‹åŒ– PrivacyEngine\n",
        "            dummy_dataset = RLDataset(deque([(\n",
        "                np.zeros(self.state_size, dtype=np.float32), 0, 0.0,\n",
        "                np.zeros(self.state_size, dtype=np.float32), False\n",
        "            )] * self.config.batch_size))\n",
        "            dummy_loader = DataLoader(dummy_dataset, batch_size=self.config.batch_size)\n",
        "\n",
        "            self.model, self.optimizer, _ = self.privacy_engine.make_private(\n",
        "                module=self.model,\n",
        "                optimizer=self.optimizer,\n",
        "                data_loader=dummy_loader, # é€™å€‹ loader åƒ…ç”¨æ–¼ç²å– sample_rate\n",
        "                noise_multiplier=self.config.dp_noise_multiplier,\n",
        "                max_grad_norm=self.config.dp_max_grad_norm,\n",
        "                poisson_sampling=True\n",
        "            )\n",
        "            print(f\"   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\")\n",
        "        except Exception as e:\n",
        "            print(f\"   - âŒ å·®åˆ†éš±ç§åˆå§‹åŒ–å¤±æ•—: {e}ã€‚å°‡åœ¨ééš±ç§æ¨¡å¼ä¸‹é‹è¡Œã€‚\")\n",
        "            self.privacy_engine = None\n",
        "            self.config.enable_dp = False\n",
        "\n",
        "    def act(self, state: np.ndarray) -> int:\n",
        "        \"\"\"æ ¹æ“šç•¶å‰ç‹€æ…‹å’Œ epsilon-greedy ç­–ç•¥é¸æ“‡ä¸€å€‹å‹•ä½œã€‚\"\"\"\n",
        "        if not self.is_eval_agent and np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        with torch.no_grad():\n",
        "            state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
        "            q_values = self.model(state_tensor)\n",
        "        return q_values.argmax().item()\n",
        "\n",
        "    def remember(self, *args):\n",
        "        \"\"\"å°‡ä¸€æ¢ç¶“é©—å­˜å…¥å›æ”¾ç·©è¡å€ã€‚\"\"\"\n",
        "        self.memory.append(args)\n",
        "\n",
        "    def replay(self, num_batches: int, clipper: AdaptiveClipper = None) -> float:\n",
        "        \"\"\"\n",
        "        å¾è¨˜æ†¶é«”ä¸­å–æ¨£ä¸¦è¨“ç·´æ¨¡å‹ã€‚\n",
        "        (ä»»å‹™ 2 å’Œ 3 çš„æ ¸å¿ƒå¯¦ç¾)\n",
        "        \"\"\"\n",
        "        if len(self.memory) < self.config.batch_size:\n",
        "            return 0.0\n",
        "\n",
        "        data_loader = get_data_loader(self.memory, self.config.batch_size, self.device)\n",
        "        if data_loader is None: return 0.0\n",
        "\n",
        "        total_loss, batches_processed = 0.0, 0\n",
        "        self.model.train()\n",
        "\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            if i >= num_batches: break\n",
        "\n",
        "            states, actions, rewards, next_states, dones = [item.to(self.device) for item in batch]\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # è¨ˆç®— Q å€¼\n",
        "            current_q_all = self.model(states)\n",
        "            current_q = current_q_all.gather(1, actions.unsqueeze(1))\n",
        "\n",
        "            # è¨ˆç®—ç›®æ¨™ Q å€¼ (Double DQN)\n",
        "            with torch.no_grad():\n",
        "                next_actions = self.model(next_states).argmax(dim=1, keepdim=True)\n",
        "                max_next_q = self.target_model(next_states).gather(1, next_actions)\n",
        "                target_q = rewards.unsqueeze(1) + (self.gamma * max_next_q * (~dones.unsqueeze(1)))\n",
        "\n",
        "            # è¨ˆç®—æ ¸å¿ƒæå¤±\n",
        "            loss = self.criterion(current_q, target_q)\n",
        "\n",
        "            # (ä»»å‹™ 2) æ·»åŠ  CQL æå¤±é …\n",
        "            if self.config.enable_cql:\n",
        "                logsumexp_q = torch.logsumexp(current_q_all / self.config.cql_temperature, dim=1).mean()\n",
        "                cql_loss = self.config.cql_alpha * (logsumexp_q - current_q.mean())\n",
        "                loss += cql_loss\n",
        "\n",
        "            # (ä»»å‹™ 3) FedProx æ­£å‰‡åŒ–é …\n",
        "            if self.config.mode in ['FedProx', 'ClusteredFL'] and self.mu > 0 and self.global_params:\n",
        "                proximal_term = 0.0\n",
        "                model_params = self.model._module.parameters() if hasattr(self.model, '_module') else self.model.parameters()\n",
        "                for local_param, global_param in zip(model_params, self.global_params):\n",
        "                    proximal_term += torch.sum((local_param - global_param.to(self.device))**2)\n",
        "                loss += (self.mu / 2) * proximal_term\n",
        "\n",
        "            if not torch.isfinite(loss): continue\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # (ä»»å‹™ 3) åœ¨å„ªåŒ–å™¨æ­¥é©Ÿå‰æ›´æ–°è‡ªé©æ‡‰è£å‰ªå™¨\n",
        "            if clipper and self.config.enable_adaptive_clipping:\n",
        "                clipper.track_grad_norm(self.model)\n",
        "                clipper.update_clip_norm() # é€™è£¡åªæ›´æ–°å»ºè­°å€¼ï¼Œå¯¦éš›å€¼åœ¨å¼•æ“åˆå§‹åŒ–æ™‚è¨­å®š\n",
        "\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            batches_processed += 1\n",
        "\n",
        "        return total_loss / batches_processed if batches_processed > 0 else 0.0\n",
        "\n",
        "    def get_privacy_cost(self) -> float:\n",
        "        \"\"\"ç²å–ç•¶å‰çš„éš±ç§æˆæœ¬ (epsilon)ã€‚\"\"\"\n",
        "        if not self.privacy_engine: return 0.0\n",
        "        try:\n",
        "            return self.privacy_engine.get_epsilon(delta=self.config.dp_target_delta)\n",
        "        except Exception as e:\n",
        "            # print(f\"Warning: Could not get epsilon: {e}\")\n",
        "            return self.current_epsilon # è¿”å›ä¸Šä¸€æ¬¡æˆåŠŸçš„å€¼\n",
        "\n",
        "    def set_global_params(self, state_dict: dict):\n",
        "        \"\"\"è¨­ç½®ç”¨æ–¼ FedProx è¨ˆç®—çš„å…¨å±€æ¨¡å‹åƒæ•¸ã€‚\"\"\"\n",
        "        with torch.no_grad():\n",
        "            self.global_params = [p.clone().detach().cpu() for p in state_dict.values()]\n",
        "\n",
        "    def update_target_model(self):\n",
        "        \"\"\"å°‡ä¸»æ¨¡å‹çš„æ¬Šé‡è¤‡è£½åˆ°ç›®æ¨™æ¨¡å‹ã€‚\"\"\"\n",
        "        self.target_model.load_state_dict(self.get_clean_state_dict())\n",
        "\n",
        "    def get_clean_state_dict(self) -> dict:\n",
        "        \"\"\"ç²å–æ¨¡å‹çš„ state_dictï¼Œå¦‚æœæ˜¯ DP æ¨¡å‹ï¼Œå‰‡å¾ _module ä¸­æå–ã€‚\"\"\"\n",
        "        return self.model._module.state_dict() if self.privacy_engine and hasattr(self.model, '_module') else self.model.state_dict()\n",
        "\n",
        "    def get_model_for_upload(self) -> dict:\n",
        "        \"\"\"æº–å‚™è¦ä¸Šå‚³åˆ°æœå‹™å™¨çš„æ¨¡å‹ï¼Œå¯é¸å£“ç¸®ã€‚\"\"\"\n",
        "        state_dict = self.get_clean_state_dict()\n",
        "        if self.config.enable_compression:\n",
        "            return {k: v.cpu().half() for k, v in state_dict.items()}\n",
        "        return {k: v.cpu() for k, v in state_dict.items()}\n",
        "\n",
        "    def get_model_weights_flat(self) -> np.ndarray:\n",
        "        \"\"\"å°‡æ¨¡å‹æ¬Šé‡å±•å¹³ç‚ºä¸€å€‹å‘é‡ï¼Œç”¨æ–¼èšé¡åˆ†æã€‚\"\"\"\n",
        "        with torch.no_grad():\n",
        "            params = self.model._module.parameters() if self.privacy_engine and hasattr(self.model, '_module') else self.model.parameters()\n",
        "            return torch.cat([p.view(-1) for p in params]).cpu().numpy()\n",
        "\n",
        "print(\"âœ… Cell 5: RLAgentï¼ˆCQL & Adaptive Clipping å°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9GxeCqObCNV",
        "outputId": "40446d16-6b65-48ea-ef94-a259008bf61a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 5: RLAgentï¼ˆCQL & Adaptive Clipping å°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 6: ğŸŒ è¯é‚¦å­¸ç¿’æœå‹™å™¨é¡åˆ¥ï¼ˆDP æ ¼å¼ä¿®æ­£ç‰ˆï¼‰\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import copy\n",
        "\n",
        "class FLServer:\n",
        "    \"\"\"\n",
        "    è¯é‚¦å­¸ç¿’æœå‹™å™¨ï¼Œè² è²¬æ¨¡å‹èšåˆã€å®¢æˆ¶ç«¯èšé¡å’Œæ¨¡å‹åˆ†ç™¼ã€‚\n",
        "    ã€éŒ¯èª¤ä¿®æ­£ã€‘æœ¬ç‰ˆæœ¬ç‰¹åˆ¥è™•ç†äº†å·®åˆ†éš±ç§æ¨¡å‹ï¼ˆGradSampleModuleï¼‰èˆ‡\n",
        "    æ¨™æº–æ¨¡å‹ä¹‹é–“ state_dict éµåä¸åŒ¹é…çš„å•é¡Œã€‚\n",
        "    \"\"\"\n",
        "    def __init__(self, config: TrainingConfig):\n",
        "        \"\"\"\n",
        "        åˆå§‹åŒ– FLServerã€‚\n",
        "\n",
        "        Args:\n",
        "            config (TrainingConfig): å¯¦é©—é…ç½®ã€‚\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.num_clusters = config.num_clusters\n",
        "        self.client_to_cluster: Dict[int, int] = {}\n",
        "        self.cluster_models: Dict[int, Dict[str, torch.Tensor]] = {\n",
        "            i: None for i in range(config.num_clusters)\n",
        "        }\n",
        "        print(f\"[FLServer] åˆå§‹åŒ–å®Œæˆ - æ¨¡å¼: {self.config.mode}, èšé¡æ•¸: {self.num_clusters}\")\n",
        "\n",
        "    def _is_dp_model(self, model: torch.nn.Module) -> bool:\n",
        "        \"\"\"æª¢æŸ¥æ¨¡å‹æ˜¯å¦ç‚º Opacus åŒ…è£çš„ GradSampleModuleã€‚\"\"\"\n",
        "        return \"GradSampleModule\" in str(type(model))\n",
        "\n",
        "    def _convert_state_dict_keys(self, state_dict: Dict, target_model_is_dp: bool) -> Dict:\n",
        "        \"\"\"\n",
        "        ã€é—œéµä¿®æ­£ã€‘æ ¹æ“šç›®æ¨™æ¨¡å‹æ˜¯å¦ç‚º DP æ¨¡å‹ï¼Œè‡ªå‹•è½‰æ› state_dict çš„éµã€‚\n",
        "        \"\"\"\n",
        "        if not state_dict: return {}\n",
        "\n",
        "        source_keys_have_prefix = any(k.startswith('_module.') for k in state_dict.keys())\n",
        "\n",
        "        # å¦‚æœæ ¼å¼å·²ç¶“åŒ¹é…ï¼Œå‰‡ç„¡éœ€è½‰æ›\n",
        "        if source_keys_have_prefix == target_model_is_dp:\n",
        "            return state_dict\n",
        "\n",
        "        new_dict = {}\n",
        "        if target_model_is_dp: # éœ€è¦æ·»åŠ å‰ç¶´\n",
        "            for key, value in state_dict.items():\n",
        "                new_dict[f\"_module.{key}\"] = value\n",
        "        else: # éœ€è¦ç§»é™¤å‰ç¶´\n",
        "            for key, value in state_dict.items():\n",
        "                if key.startswith('_module.'):\n",
        "                    new_dict[key[len(\"_module.\"):]] = value\n",
        "        return new_dict\n",
        "\n",
        "    def distribute_model(self, participating_agents: Dict[int, 'RLAgent'], global_model_state: Dict):\n",
        "        \"\"\"\n",
        "        å°‡é©ç•¶çš„æ¨¡å‹ï¼ˆå…¨å±€æˆ–èšé¡æ¨¡å‹ï¼‰åˆ†ç™¼çµ¦åƒèˆ‡çš„å®¢æˆ¶ç«¯ã€‚\n",
        "        ã€éŒ¯èª¤ä¿®æ­£ã€‘åˆ†ç™¼å‰æœƒè‡ªå‹•æ ¡æ­£ state_dict çš„éµã€‚\n",
        "        \"\"\"\n",
        "        if not global_model_state:\n",
        "            print(\"[FLServer] âš ï¸ å…¨å±€æ¨¡å‹ç‚ºç©ºï¼Œè·³éåˆ†ç™¼ã€‚\")\n",
        "            return\n",
        "\n",
        "        # å…¨å±€æ¨¡å‹æ˜¯ä¹¾æ·¨çš„ï¼ˆæ²’æœ‰ _module. å‰ç¶´ï¼‰\n",
        "        for client_id, agent in participating_agents.items():\n",
        "            model_to_send = global_model_state\n",
        "            if self.config.mode == 'ClusteredFL':\n",
        "                cluster_id = self.client_to_cluster.get(client_id, 0)\n",
        "                if self.cluster_models.get(cluster_id) is not None:\n",
        "                    model_to_send = self.cluster_models[cluster_id]\n",
        "\n",
        "            # æª¢æŸ¥ç›®æ¨™å®¢æˆ¶ç«¯æ¨¡å‹æ˜¯å¦ç‚º DP æ¨¡å‹\n",
        "            agent_is_dp = self._is_dp_model(agent.model)\n",
        "\n",
        "            # ã€é—œéµä¿®æ­£ã€‘è½‰æ› state_dict ä»¥åŒ¹é…ç›®æ¨™æ¨¡å‹\n",
        "            model_state_for_loading = self._convert_state_dict_keys(\n",
        "                model_to_send, target_model_is_dp=agent_is_dp\n",
        "            )\n",
        "\n",
        "            # å°‡æ¨¡å‹æ¬Šé‡è½‰åˆ° agent æ‰€åœ¨çš„ device\n",
        "            model_to_load = {k: v.to(agent.device).float() for k, v in model_state_for_loading.items()}\n",
        "\n",
        "            # ç¾åœ¨è¼‰å…¥ä¸æœƒå ±éŒ¯äº†\n",
        "            agent.model.load_state_dict(model_to_load)\n",
        "\n",
        "            # ç”¨æ–¼ FedProx çš„å…¨å±€åƒæ•¸æ‡‰å§‹çµ‚æ˜¯ä¹¾æ·¨çš„ state_dict\n",
        "            agent.set_global_params(model_to_send)\n",
        "\n",
        "    def aggregate_weighted(self, client_updates: List[Tuple[Dict, int]]) -> Dict:\n",
        "        \"\"\"\n",
        "        å°å®¢æˆ¶ç«¯ä¸Šå‚³çš„æ¨¡å‹æ›´æ–°é€²è¡ŒåŠ æ¬Šå¹³å‡èšåˆ (FedAvg)ã€‚\n",
        "        ã€éŒ¯èª¤ä¿®æ­£ã€‘ç¢ºä¿è¿”å›çš„èšåˆæ¨¡å‹æ˜¯\"ä¹¾æ·¨\"çš„ï¼ˆæ²’æœ‰ _module. å‰ç¶´ï¼‰ã€‚\n",
        "        \"\"\"\n",
        "        if not client_updates: return {}\n",
        "\n",
        "        total_samples = sum(num_samples for _, num_samples in client_updates if num_samples > 0)\n",
        "        if total_samples == 0: return self._convert_state_dict_keys(client_updates[0][0], target_model_is_dp=False)\n",
        "\n",
        "        # ä»¥ç¬¬ä¸€å€‹ä¹¾æ·¨çš„æ¨¡å‹ç‚ºåŸºæº–åˆå§‹åŒ–èšåˆæ¨¡å‹\n",
        "        first_clean_model = self._convert_state_dict_keys(client_updates[0][0], target_model_is_dp=False)\n",
        "        aggregated_model = {k: torch.zeros_like(v) for k, v in first_clean_model.items()}\n",
        "\n",
        "        for model_state, num_samples in client_updates:\n",
        "            if num_samples == 0: continue\n",
        "\n",
        "            weight = num_samples / total_samples\n",
        "\n",
        "            # å°‡æ¯å€‹ä¸Šå‚³çš„æ¨¡å‹éƒ½è½‰æ›ç‚ºä¹¾æ·¨çš„æ ¼å¼å†é€²è¡Œèšåˆ\n",
        "            clean_model_state = self._convert_state_dict_keys(model_state, target_model_is_dp=False)\n",
        "\n",
        "            for key in aggregated_model.keys():\n",
        "                if key in clean_model_state:\n",
        "                    aggregated_model[key] += weight * clean_model_state[key].to(aggregated_model[key].device)\n",
        "\n",
        "        return aggregated_model\n",
        "\n",
        "    def update_clusters(self, client_agents: Dict[int, 'RLAgent'], current_round: int):\n",
        "        \"\"\"\n",
        "        (ClusteredFL æ¨¡å¼) ä½¿ç”¨ K-Means æ ¹æ“šå®¢æˆ¶ç«¯æ¨¡å‹æ¬Šé‡å°å®¢æˆ¶ç«¯é€²è¡Œèšé¡ã€‚\n",
        "        \"\"\"\n",
        "        if len(client_agents) < self.num_clusters:\n",
        "            # print(\"[FLServer] å®¢æˆ¶ç«¯æ•¸é‡ä¸è¶³ä»¥é€²è¡Œæœ‰æ„ç¾©çš„èšé¡ã€‚\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n[FLServer] Round {current_round}: æ­£åœ¨æ›´æ–°å®¢æˆ¶ç«¯èšé¡...\")\n",
        "        try:\n",
        "            client_features, client_ids = [], []\n",
        "            for cid, agent in client_agents.items():\n",
        "                weights = agent.get_model_weights_flat()\n",
        "                if weights is not None and len(weights) > 0:\n",
        "                    client_features.append(weights)\n",
        "                    client_ids.append(cid)\n",
        "\n",
        "            if len(client_features) < self.num_clusters:\n",
        "                print(\"[FLServer] æœ‰æ•ˆç‰¹å¾µæ•¸é‡ä¸è¶³ä»¥èšé¡ã€‚\")\n",
        "                return\n",
        "\n",
        "            features_array = StandardScaler().fit_transform(np.vstack(client_features))\n",
        "\n",
        "            kmeans = KMeans(n_clusters=self.num_clusters, random_state=self.config.random_seed, n_init=10)\n",
        "            cluster_labels = kmeans.fit_predict(features_array)\n",
        "\n",
        "            self.client_to_cluster = {cid: label for cid, label in zip(client_ids, cluster_labels)}\n",
        "\n",
        "            print(\"[FLServer] èšé¡æ›´æ–°å®Œæˆ:\")\n",
        "            for i in range(self.num_clusters):\n",
        "                clients_in_cluster = [cid for cid, c_label in self.client_to_cluster.items() if c_label == i]\n",
        "                print(f\"  - èšé¡ {i}: {clients_in_cluster}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[FLServer] âŒ èšé¡æ›´æ–°å¤±æ•—: {e}ã€‚å°‡å›é€€åˆ°éš¨æ©Ÿåˆ†é…ã€‚\")\n",
        "            client_ids = list(client_agents.keys())\n",
        "            random.shuffle(client_ids)\n",
        "            for i, cid in enumerate(client_ids):\n",
        "                self.client_to_cluster[cid] = i % self.num_clusters\n",
        "\n",
        "print(\"âœ… Cell 6: FLServerï¼ˆDP æ ¼å¼ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "LHswkw7IbEh0",
        "outputId": "80b0f40d-a197-4bb2-80f5-af5667dff57d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 6: FLServerï¼ˆDP æ ¼å¼ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 7: ğŸš€ ExperimentRunnerï¼ˆéè¿´ä¿®æ­£ç‰ˆï¼‰\n",
        "import scipy.stats as stats\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class ExperimentRunner:\n",
        "    \"\"\"\n",
        "    å¯¦é©—åŸ·è¡Œå™¨ï¼Œè² è²¬å”èª¿æ•´å€‹è¯é‚¦å­¸ç¿’æµç¨‹ï¼ŒåŒ…æ‹¬å®¢æˆ¶ç«¯é¸æ“‡ã€\n",
        "    æœ¬åœ°è¨“ç·´ã€æ¨¡å‹èšåˆã€è©•ä¼°å’Œæ—¥èªŒè¨˜éŒ„ã€‚\n",
        "    (ä»»å‹™ 2, 4, 5, 6 çš„ä¸»è¦å¯¦ç¾)\n",
        "    \"\"\"\n",
        "    def __init__(self, config: TrainingConfig, data_manager: DataManager):\n",
        "        self.config = config\n",
        "        self.data_manager = data_manager\n",
        "        self._set_seeds() # (ä»»å‹™ 6)\n",
        "\n",
        "        # æ•¸æ“šèˆ‡å®¢æˆ¶ç«¯åˆå§‹åŒ–\n",
        "        self.all_trajectories = self.data_manager.create_non_iid_partitions()\n",
        "        self.client_envs = {cid: PairedEnv(traj, config) for cid, traj in self.all_trajectories.items() if traj.size > 0}\n",
        "        if not self.client_envs:\n",
        "            raise ValueError(\"æœªèƒ½ç‚ºä»»ä½•å®¢æˆ¶ç«¯å‰µå»ºæœ‰æ•ˆçš„ç’°å¢ƒã€‚\")\n",
        "\n",
        "        # æ›´æ–°é…ç½®ä»¥åŒ¹é…å¯¦éš›ç”Ÿæˆçš„å®¢æˆ¶ç«¯æ•¸é‡\n",
        "        self.config.num_clients = len(self.client_envs)\n",
        "        self.config.num_clients_to_select = min(self.config.num_clients_to_select, self.config.num_clients)\n",
        "\n",
        "        # --- ã€éè¿´ä¿®æ­£ã€‘èª¿æ•´åŸ·è¡Œé †åº ---\n",
        "        # 1. å¦‚æœå•Ÿç”¨ï¼Œå…ˆåŸ·è¡Œé è¨ˆç®—ï¼Œæ›´æ–° config\n",
        "        if self.config.enable_dp and self.config.enable_adaptive_clipping:\n",
        "            self._precompute_adaptive_grad_norm()\n",
        "\n",
        "        # 2. ä½¿ç”¨æ›´æ–°å¾Œçš„ config å‰µå»ºä»£ç†èˆ‡æœå‹™å™¨\n",
        "        self.server = FLServer(config)\n",
        "        self.client_agents = self._create_agents() # ç¾åœ¨é€™ä¸€æ­¥æ˜¯å®‰å…¨çš„\n",
        "        self.global_model_state = self.client_agents[next(iter(self.client_agents))].get_clean_state_dict() if self.client_agents else {}\n",
        "\n",
        "        # çµæœè¨˜éŒ„\n",
        "        self.training_history = []\n",
        "        self.evaluation_results = []\n",
        "        self.privacy_costs = []\n",
        "        self.latency_logs = [] # (ä»»å‹™ 5)\n",
        "\n",
        "        self.config.save()\n",
        "        print(\"\\n[ExperimentRunner] åˆå§‹åŒ–å®Œæˆã€‚\")\n",
        "\n",
        "    def _set_seeds(self):\n",
        "        \"\"\" (ä»»å‹™ 6) è¨­ç½®æ‰€æœ‰ç›¸é—œåº«çš„éš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿å¯é‡ç¾æ€§ã€‚\"\"\"\n",
        "        seed = self.config.random_seed\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(seed)\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "            # é—œéµçš„ç¢ºå®šæ€§è¨­å®š\n",
        "            torch.backends.cudnn.deterministic = True\n",
        "            torch.backends.cudnn.benchmark = False\n",
        "            # PyTorch 1.8+\n",
        "            try:\n",
        "                torch.use_deterministic_algorithms(True)\n",
        "                print(\"torch.use_deterministic_algorithms(True) å·²è¨­ç½®\")\n",
        "            except (AttributeError, RuntimeError): # RuntimeError å¯èƒ½åœ¨æŸäº› CUDA ç‰ˆæœ¬ä¸Šç™¼ç”Ÿ\n",
        "                print(\"ç•¶å‰ PyTorch/CUDA ç‰ˆæœ¬ä¸å®Œå…¨æ”¯æŒæˆ–å·²å•Ÿç”¨ç¢ºå®šæ€§æ¼”ç®—æ³•\")\n",
        "\n",
        "    def _create_agents(self) -> Dict[int, RLAgent]:\n",
        "        \"\"\"ã€éè¿´ä¿®æ­£ã€‘å‰µå»ºæ‰€æœ‰å®¢æˆ¶ç«¯çš„ RL ä»£ç†ã€‚ä¸å†å‘¼å«é è¨ˆç®—å‡½å¼ã€‚\"\"\"\n",
        "        print(\"\\n[ExperimentRunner] æ­£åœ¨åˆå§‹åŒ–æ‰€æœ‰å®¢æˆ¶ç«¯ä»£ç†...\")\n",
        "        agents = {}\n",
        "        for cid, env in self.client_envs.items():\n",
        "            dataset_size = len(env.trajectory) if env.trajectory.size > 0 else 1\n",
        "            # ä½¿ç”¨ self.config (å¯èƒ½å·²è¢«é è¨ˆç®—æ›´æ–°) ä¾†å‰µå»ºä»£ç†\n",
        "            agents[cid] = RLAgent(env.state_size, env.action_size, self.config, cid, dataset_size)\n",
        "        return agents\n",
        "\n",
        "    def _precompute_adaptive_grad_norm(self):\n",
        "        \"\"\"\n",
        "        ã€éè¿´ä¿®æ­£ã€‘\n",
        "        åœ¨è¨“ç·´å‰é‹è¡Œä¸€å€‹çŸ­æš«çš„é ç†±éšæ®µä¾†ä¼°ç®—ä¸€å€‹ç©©å¥çš„æ¢¯åº¦è£å‰ªç¯„æ•¸ã€‚\n",
        "        æ­¤å‡½å¼ç¾åœ¨ç›´æ¥å‰µå»ºä¸€å€‹ç¨ç«‹çš„è‡¨æ™‚ä»£ç†ï¼Œè€Œä¸æ˜¯å‘¼å« _create_agents()ã€‚\n",
        "        \"\"\"\n",
        "        print(\"\\n[Adaptive Clipper] æ­£åœ¨é è¨ˆç®—æ¢¯åº¦è£å‰ªç¯„æ•¸...\")\n",
        "        clipper = AdaptiveClipper(percentile=self.config.adaptive_clipping_percentile)\n",
        "\n",
        "        # --- ç›´æ¥å»ºç«‹ä¸€å€‹è¼•é‡ç´šçš„è‡¨æ™‚ä»£ç† ---\n",
        "        # é¸æ“‡ä¸€å€‹æœ‰ä»£è¡¨æ€§çš„å®¢æˆ¶ç«¯ç’°å¢ƒï¼ˆä¾‹å¦‚æ•¸æ“šé‡è¼ƒå¤šçš„ï¼‰\n",
        "        temp_env = next(iter(self.client_envs.values()))\n",
        "        # å‰µå»ºä¸€å€‹ä¸å•Ÿç”¨DPçš„è‡¨æ™‚configä¾†å»ºç«‹ä»£ç†ï¼Œé¿å…ä¸å¿…è¦çš„é–‹éŠ·\n",
        "        temp_config = copy.deepcopy(self.config)\n",
        "        temp_config.enable_dp = False\n",
        "        temp_agent = RLAgent(temp_env.state_size, temp_env.action_size, temp_config, -1, 1)\n",
        "        # --- --------------------------- ---\n",
        "\n",
        "        state = temp_env.reset()\n",
        "\n",
        "        # æ¨¡æ“¬ä¸€äº›åˆå§‹æ­¥é©Ÿä¾†æ”¶é›†æ¢¯åº¦\n",
        "        print(\"   - åŸ·è¡Œé ç†±æ­¥é©Ÿä»¥æ”¶é›†æ¢¯åº¦ç¯„æ•¸...\")\n",
        "        for _ in range(200): # é ç†±æ­¥æ•¸\n",
        "            action = temp_agent.act(state)\n",
        "            next_state, reward, done, _ = temp_env.step(action)\n",
        "            temp_agent.remember(state, action, reward, next_state, done)\n",
        "            state = next_state if not done else temp_env.reset()\n",
        "            if len(temp_agent.memory) > self.config.batch_size:\n",
        "                temp_agent.replay(num_batches=1, clipper=clipper)\n",
        "\n",
        "        # æ›´æ–°é…ç½®ä¸­çš„è£å‰ªå€¼\n",
        "        if clipper.suggested_clip_norm > 0:\n",
        "            new_clip_norm = round(clipper.suggested_clip_norm, 2)\n",
        "            print(f\"   - âœ… é è¨ˆç®—å®Œæˆã€‚å»ºè­°çš„è£å‰ªç¯„æ•¸ ({self.config.adaptive_clipping_percentile*100:.0f} ç™¾åˆ†ä½): {new_clip_norm}\")\n",
        "            # ç›´æ¥ä¿®æ”¹ self.config ç‰©ä»¶ï¼Œæ­¤ä¿®æ”¹å°‡åœ¨å¾ŒçºŒçš„ _create_agents ä¸­ç”Ÿæ•ˆ\n",
        "            self.config.dp_max_grad_norm = new_clip_norm\n",
        "        else:\n",
        "            print(f\"   - âš ï¸ é è¨ˆç®—æœªèƒ½æ‰¾åˆ°æœ‰æ•ˆçš„è£å‰ªå€¼ï¼Œå°‡ä½¿ç”¨é è¨­å€¼: {self.config.dp_max_grad_norm}\")\n",
        "\n",
        "        del temp_agent, temp_env, temp_config, clipper\n",
        "\n",
        "\n",
        "    def _run_federated_training(self):\n",
        "        \"\"\"é‹è¡Œä¸»è¯é‚¦å­¸ç¿’è¨“ç·´å¾ªç’°ã€‚\"\"\"\n",
        "        print(f\"\\n[æ¨¡å¼] é–‹å§‹è¯é‚¦å¼è¨“ç·´ ({self.config.mode})\")\n",
        "        progress_bar = tqdm(range(self.config.comm_rounds), desc=f\"{self.config.mode} Training\")\n",
        "\n",
        "        for comm_round in progress_bar:\n",
        "            round_start_time = time.time() # (ä»»å‹™ 5)\n",
        "            # --- 1. èšé¡æ›´æ–° (å¦‚æœé©ç”¨) ---\n",
        "            if self.config.mode == 'ClusteredFL' and comm_round > 0 and comm_round % self.config.cluster_update_freq == 0:\n",
        "                self.server.update_clusters(self.client_agents, comm_round)\n",
        "\n",
        "            # --- 2. å®¢æˆ¶ç«¯é¸æ“‡èˆ‡ç•°è³ªæ€§æ¨¡æ“¬ ---\n",
        "            available_ids = list(self.client_agents.keys())\n",
        "            num_to_select = min(self.config.num_clients_to_select, len(available_ids))\n",
        "            selected_ids = np.random.choice(available_ids, num_to_select, replace=False)\n",
        "\n",
        "            dropout_ids, straggler_ids = set(), set()\n",
        "            if self.config.enable_heterogeneity:\n",
        "                num_dropouts = int(self.config.dropout_ratio * num_to_select)\n",
        "                dropout_ids = set(np.random.choice(selected_ids, num_dropouts, replace=False))\n",
        "\n",
        "                remaining_ids = [cid for cid in selected_ids if cid not in dropout_ids]\n",
        "                num_stragglers = int(self.config.straggler_ratio * len(remaining_ids))\n",
        "                if num_stragglers > 0:\n",
        "                    straggler_ids = set(np.random.choice(remaining_ids, num_stragglers, replace=False))\n",
        "\n",
        "            participating_ids = [cid for cid in selected_ids if cid not in dropout_ids]\n",
        "            if not participating_ids:\n",
        "                print(f\"[Round {comm_round+1}] âš ï¸ æ‰€æœ‰é¸æ“‡çš„å®¢æˆ¶ç«¯å‡æ‰ç·šï¼Œè·³éæœ¬è¼ªã€‚\")\n",
        "                continue\n",
        "\n",
        "            # --- 3. æ¨¡å‹åˆ†ç™¼ ---\n",
        "            participating_agents = {cid: self.client_agents[cid] for cid in participating_ids}\n",
        "            self.server.distribute_model(participating_agents, self.global_model_state)\n",
        "\n",
        "            # --- 4. æœ¬åœ°è¨“ç·´ ---\n",
        "            client_updates, round_losses, round_rewards, round_epsilons = [], [], [], []\n",
        "            for cid in participating_ids:\n",
        "                agent, env = self.client_agents[cid], self.client_envs[cid]\n",
        "                # å»¶é²è€…è¨“ç·´çš„ episode è¼ƒå°‘\n",
        "                episodes = self.config.local_episodes_per_round // 2 if cid in straggler_ids else self.config.local_episodes_per_round\n",
        "                loss, reward, privacy_cost = self._train_agent_locally(agent, env, episodes)\n",
        "\n",
        "                client_updates.append((agent.get_model_for_upload(), len(env.trajectory)))\n",
        "                round_losses.append(loss)\n",
        "                round_rewards.append(reward)\n",
        "                if self.config.enable_dp:\n",
        "                    # æ›´æ–°æ¯å€‹ agent çš„ epsilon è¨˜éŒ„\n",
        "                    agent.current_epsilon = privacy_cost\n",
        "                    round_epsilons.append(privacy_cost)\n",
        "\n",
        "            # --- 5. å®¹éŒ¯èšåˆ (ä»»å‹™ 4) ---\n",
        "            num_successful = len(client_updates)\n",
        "            num_expected = len(selected_ids)\n",
        "            success_ratio = num_successful / num_expected if num_expected > 0 else 0\n",
        "\n",
        "            if success_ratio < (1 - self.config.async_threshold):\n",
        "                print(f\"\\n[Round {comm_round+1}] âš ï¸ å®¹éŒ¯èšåˆè§¸ç™¼ï¼æˆåŠŸå®¢æˆ¶ç«¯æ¯”ä¾‹ {success_ratio:.2f} ä½æ–¼é–¾å€¼ã€‚åƒ…èšåˆ {num_successful} å€‹æ¨¡å‹ã€‚\")\n",
        "\n",
        "            if not client_updates:\n",
        "                print(f\"[Round {comm_round+1}] âš ï¸ æ²’æœ‰å®¢æˆ¶ç«¯å›å‚³æ¨¡å‹ï¼Œè·³éèšåˆã€‚\")\n",
        "                continue\n",
        "\n",
        "            # --- 6. æ¨¡å‹èšåˆ ---\n",
        "            if self.config.mode == 'ClusteredFL':\n",
        "                # æŒ‰èšé¡é€²è¡Œèšåˆ\n",
        "                client_updates_by_cluster = {i: [] for i in range(self.config.num_clusters)}\n",
        "                for i, (model_update, num_points) in enumerate(client_updates):\n",
        "                    cid = participating_ids[i]\n",
        "                    cluster_id = self.server.client_to_cluster.get(cid, 0)\n",
        "                    client_updates_by_cluster[cluster_id].append((model_update, num_points))\n",
        "\n",
        "                new_cluster_models = []\n",
        "                for cluster_id, updates in client_updates_by_cluster.items():\n",
        "                    if updates:\n",
        "                        updated_model = self.server.aggregate_weighted(updates)\n",
        "                        self.server.cluster_models[cluster_id] = updated_model\n",
        "                        new_cluster_models.append((updated_model, sum(n for _, n in updates)))\n",
        "\n",
        "                if new_cluster_models:\n",
        "                    self.global_model_state = self.server.aggregate_weighted(new_cluster_models)\n",
        "            else: # FedAvg, FedProx, CQL\n",
        "                self.global_model_state = self.server.aggregate_weighted(client_updates)\n",
        "\n",
        "            # --- 7. æ—¥èªŒè¨˜éŒ„ ---\n",
        "            round_wall_time = time.time() - round_start_time # (ä»»å‹™ 5)\n",
        "            self.latency_logs.append(round_wall_time)\n",
        "            if round_wall_time > 1.0:\n",
        "                 print(f\"[Round {comm_round+1}] âš ï¸ è¿‘å³æ™‚å»¶é²è­¦å‘Š: æœ¬è¼ªè€—æ™‚ {round_wall_time:.2f} ç§’ > 1 ç§’ã€‚\")\n",
        "\n",
        "            avg_loss = np.mean(round_losses) if round_losses else 0\n",
        "            avg_reward = np.mean(round_rewards) if round_rewards else 0\n",
        "            avg_epsilon = np.mean(round_epsilons) if round_epsilons else 0.0\n",
        "\n",
        "            self.training_history.append({'round': comm_round, 'avg_reward': avg_reward, 'avg_loss': avg_loss})\n",
        "            self.privacy_costs.append({'round': comm_round, 'epsilon': avg_epsilon})\n",
        "\n",
        "            progress_bar.set_postfix(reward=f\"{avg_reward:.2f}\", loss=f\"{avg_loss:.4f}\", eps=f\"{avg_epsilon:.3f}\")\n",
        "\n",
        "    def _train_agent_locally(self, agent: RLAgent, env: PairedEnv, episodes: int):\n",
        "        \"\"\"å–®å€‹å®¢æˆ¶ç«¯çš„æœ¬åœ°è¨“ç·´é‚è¼¯ã€‚\"\"\"\n",
        "        agent.model.train()\n",
        "        total_loss, total_reward, episode_count = 0.0, 0.0, 0\n",
        "        if episodes == 0: return 0.0, 0.0, 0.0\n",
        "\n",
        "        for ep in range(episodes):\n",
        "            state, episode_reward, done = env.reset(), 0.0, False\n",
        "            for step in range(self.config.steps_per_episode):\n",
        "                action = agent.act(state)\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                agent.remember(state, action, reward, next_state, done)\n",
        "                state = next_state\n",
        "                episode_reward += reward\n",
        "\n",
        "                if len(agent.memory) > self.config.replay_start_size and step % self.config.replay_frequency == 0:\n",
        "                    loss = agent.replay(num_batches=self.config.replay_batches_per_call)\n",
        "                    total_loss += loss\n",
        "\n",
        "                if done: break\n",
        "\n",
        "            total_reward += episode_reward\n",
        "            episode_count += 1\n",
        "            if (ep + 1) % self.config.target_update_freq == 0:\n",
        "                agent.update_target_model()\n",
        "\n",
        "        # æ›´æ–° Epsilon\n",
        "        if not agent.is_eval_agent and agent.epsilon > self.config.epsilon_min:\n",
        "            agent.epsilon *= self.config.epsilon_decay ** episodes\n",
        "\n",
        "        avg_loss = total_loss / (episodes * self.config.steps_per_episode / self.config.replay_frequency) if total_loss > 0 else 0\n",
        "        avg_reward = total_reward / episode_count if episode_count > 0 else 0\n",
        "        privacy_cost = agent.get_privacy_cost()\n",
        "        return avg_loss, avg_reward, privacy_cost\n",
        "\n",
        "    def _run_final_evaluation(self):\n",
        "        \"\"\"åœ¨æ‰€æœ‰å®¢æˆ¶ç«¯ä¸Šé‹è¡Œæœ€çµ‚è©•ä¼°ã€‚\"\"\"\n",
        "        print(\"\\n[è©•ä¼°] æ­£åœ¨åŸ·è¡Œæœ€çµ‚è©•ä¼°...\")\n",
        "        for cid, env in tqdm(self.client_envs.items(), desc=\"æœ€çµ‚è©•ä¼°\"):\n",
        "            eval_row = {'client_id': cid}\n",
        "\n",
        "            base_model_state = self.global_model_state\n",
        "            # åœ¨ ClusteredFL ä¸­ï¼Œå€‹æ€§åŒ–æ¨¡å‹æ˜¯èšé¡æ¨¡å‹\n",
        "            if self.config.mode == 'ClusteredFL':\n",
        "                cluster_id = self.server.client_to_cluster.get(cid, 0)\n",
        "                personalized_model_state = self.server.cluster_models.get(cluster_id, base_model_state)\n",
        "            else:\n",
        "                personalized_model_state = base_model_state\n",
        "\n",
        "            eval_row['reward_global'] = self._evaluate_on_env(env, base_model_state)\n",
        "            eval_row['reward_personalized'] = self._evaluate_on_env(env, personalized_model_state)\n",
        "\n",
        "            if self.config.use_pfl_finetune:\n",
        "                eval_row['reward_pfl_finetuned'] = self._finetune_and_evaluate(env, personalized_model_state)\n",
        "            else:\n",
        "                eval_row['reward_pfl_finetuned'] = eval_row['reward_personalized']\n",
        "\n",
        "            self.evaluation_results.append(eval_row)\n",
        "\n",
        "    def _evaluate_on_env(self, env: PairedEnv, model_state: dict, num_episodes: int = 15) -> float:\n",
        "        \"\"\"åœ¨çµ¦å®šç’°å¢ƒä¸Šè©•ä¼°ç‰¹å®šæ¨¡å‹ã€‚\"\"\"\n",
        "        if env.trajectory.size == 0 or not model_state: return 0.0\n",
        "\n",
        "        eval_config = copy.deepcopy(self.config); eval_config.enable_dp = False\n",
        "        eval_agent = RLAgent(env.state_size, env.action_size, eval_config, -1, 1, True)\n",
        "\n",
        "        model_to_load = {k: v.to(eval_agent.device).float() for k, v in model_state.items()}\n",
        "        eval_agent.model.load_state_dict(model_to_load)\n",
        "        eval_agent.model.eval()\n",
        "        eval_agent.epsilon = 0.0\n",
        "\n",
        "        total_reward = 0\n",
        "        for _ in range(num_episodes):\n",
        "            state, ep_reward, done = env.reset(), 0, False\n",
        "            for _ in range(self.config.steps_per_episode):\n",
        "                action = eval_agent.act(state)\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                ep_reward += reward\n",
        "                state = next_state\n",
        "                if done: break\n",
        "            total_reward += ep_reward\n",
        "        return total_reward / num_episodes\n",
        "\n",
        "    def _finetune_and_evaluate(self, env: PairedEnv, model_state: dict) -> float:\n",
        "        \"\"\"å°æ¨¡å‹é€²è¡Œå€‹æ€§åŒ–å¾®èª¿ä¸¦è©•ä¼°ã€‚\"\"\"\n",
        "        if env.trajectory.size == 0 or not model_state: return 0.0\n",
        "\n",
        "        finetune_config = copy.deepcopy(self.config); finetune_config.enable_dp = False\n",
        "        finetune_agent = RLAgent(env.state_size, env.action_size, finetune_config, -1, 1, False)\n",
        "\n",
        "        model_to_load = {k: v.to(finetune_agent.device).float() for k, v in model_state.items()}\n",
        "        finetune_agent.model.load_state_dict(model_to_load)\n",
        "        finetune_agent.epsilon = 0.1 # å¾®èª¿æ™‚ä½¿ç”¨å°‘é‡æ¢ç´¢\n",
        "\n",
        "        self._train_agent_locally(finetune_agent, env, episodes=self.config.local_finetune_episodes)\n",
        "\n",
        "        return self._evaluate_on_env(env, finetune_agent.get_clean_state_dict())\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"å•Ÿå‹•ä¸¦é‹è¡Œæ•´å€‹å¯¦é©—æµç¨‹ã€‚\"\"\"\n",
        "        print(f\"\\n{'='*20} ğŸƒâ€â™‚ï¸ é–‹å§‹åŸ·è¡Œå¯¦é©—: {self.config.experiment_name} ({self.config.mode}) {'='*20}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # æ ¹æ“šæ¨¡å¼é¸æ“‡è¨“ç·´æµç¨‹\n",
        "        # ç›®å‰æ‰€æœ‰æ¨¡å¼éƒ½èµ° federated æµç¨‹ï¼ŒCentralized/Isolated å¯ä½œç‚ºæœªä¾†æ“´å±•\n",
        "        if self.config.mode in ['FedAvg', 'FedProx', 'ClusteredFL', 'CQL']:\n",
        "             self._run_federated_training()\n",
        "        else:\n",
        "            raise ValueError(f\"æœªçŸ¥çš„å¯¦é©—æ¨¡å¼: {self.config.mode}\")\n",
        "\n",
        "        self._run_final_evaluation()\n",
        "        total_time_minutes = (time.time() - start_time) / 60\n",
        "        print(f\"\\nâœ… å¯¦é©— {self.config.experiment_name} å®Œæˆï¼ç¸½è€—æ™‚: {total_time_minutes:.2f} åˆ†é˜\")\n",
        "\n",
        "        # --- æœ€çµ‚å ±å‘Š ---\n",
        "        # (ä»»å‹™ 5) å»¶é²å ±å‘Š\n",
        "        if self.latency_logs:\n",
        "            avg_latency = np.mean(self.latency_logs)\n",
        "            p95_latency = np.percentile(self.latency_logs, 95)\n",
        "            print(f\"â±ï¸  é€šä¿¡è¼ªå»¶é²å ±å‘Š: å¹³å‡ = {avg_latency:.3f} ç§’, 95ç™¾åˆ†ä½ = {p95_latency:.3f} ç§’\")\n",
        "\n",
        "        # (ä»»å‹™ 2) éš±ç§èˆ‡çå‹µå ±å‘Š\n",
        "        if self.training_history and self.privacy_costs:\n",
        "            history_df = pd.DataFrame(self.training_history)\n",
        "            privacy_df = pd.DataFrame(self.privacy_costs)\n",
        "            privacy_df['cumulative_epsilon'] = privacy_df['epsilon'].cumsum()\n",
        "\n",
        "            reward_vs_epsilon_df = pd.merge(history_df, privacy_df, on='round')\n",
        "            reward_vs_epsilon_path = os.path.join(self.config.output_dir, f'{self.config.experiment_name}_reward_vs_epsilon.csv')\n",
        "            reward_vs_epsilon_df.to_csv(reward_vs_epsilon_path, index=False)\n",
        "            print(f\"ğŸ’¾ çå‹µ vs. Epsilon æ›²ç·šæ•¸æ“šå·²ä¿å­˜è‡³: {reward_vs_epsilon_path}\")\n",
        "\n",
        "            final_epsilon = reward_vs_epsilon_df['cumulative_epsilon'].iloc[-1]\n",
        "            print(f\"ğŸ›¡ï¸  æœ€çµ‚ç¸½éš±ç§é ç®—æ¶ˆè€—: Îµ = {final_epsilon:.4f}\")\n",
        "\n",
        "        # ä¿å­˜å…¶ä»–çµæœ\n",
        "        pd.DataFrame(self.evaluation_results).to_csv(os.path.join(self.config.output_dir, f'{self.config.experiment_name}_evaluation_results.csv'), index=False)\n",
        "\n",
        "        return pd.DataFrame(self.evaluation_results), pd.DataFrame(self.training_history)\n",
        "\n",
        "\n",
        "print(\"âœ… Cell 7: ExperimentRunnerï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "GMmwa9gOi3_B",
        "outputId": "67cfe6c7-9ac9-4bbc-852d-b5f2f7a53e93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 7: ExperimentRunnerï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å®šç¾©å®Œæˆã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8A: ğŸ¬ å¯¦é©—åŸ·è¡Œä¸»å‡½æ•¸ï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰\n",
        "import time\n",
        "import gc\n",
        "from datetime import datetime\n",
        "\n",
        "def run_single_experiment(config_dict: dict, data_path: str):\n",
        "    \"\"\"\n",
        "    é‹è¡Œå–®æ¬¡ç«¯åˆ°ç«¯çš„è¯é‚¦å­¸ç¿’å¯¦é©—ã€‚\n",
        "\n",
        "    Args:\n",
        "        config_dict (dict): åŒ…å«å¯¦é©—åƒæ•¸çš„å­—å…¸ã€‚\n",
        "        data_path (str): æ•¸æ“šæ–‡ä»¶çš„è·¯å¾‘ã€‚\n",
        "\n",
        "    Returns:\n",
        "        ä¸€å€‹å…ƒçµ„ (success, results)ï¼Œå…¶ä¸­ results æ˜¯ä¸€å€‹åŒ…å«é—œéµæŒ‡æ¨™çš„å­—å…¸ã€‚\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    runner = None\n",
        "    results = {}\n",
        "\n",
        "    try:\n",
        "        # 1. åˆå§‹åŒ–é…ç½®å’Œæ•¸æ“šç®¡ç†å™¨\n",
        "        config = TrainingConfig(**config_dict)\n",
        "        print(f\"\\n{'='*20} æ­£åœ¨å•Ÿå‹•å¯¦é©—: {config.experiment_name} {'='*20}\")\n",
        "        data_manager = DataManager(data_path, config)\n",
        "\n",
        "        # 2. å‰µå»ºå¯¦é©—åŸ·è¡Œå™¨ (å…§éƒ¨æœƒè‡ªå‹•è™•ç†æ•¸æ“šåˆ‡åˆ†å’Œä»£ç†å‰µå»º)\n",
        "        runner = ExperimentRunner(config, data_manager)\n",
        "\n",
        "        # 3. é‹è¡Œå¯¦é©—\n",
        "        eval_res, _ = runner.run()\n",
        "\n",
        "        # 4. æ”¶é›†çµæœ\n",
        "        execution_time = (time.time() - start_time) / 60\n",
        "        results['execution_time'] = execution_time\n",
        "        print(f\"\\nâ±ï¸ å¯¦é©—åŸ·è¡Œæ™‚é–“: {execution_time:.2f} åˆ†é˜\")\n",
        "\n",
        "        if not eval_res.empty:\n",
        "            avg_rewards = {\n",
        "                'global': eval_res['reward_global'].mean(),\n",
        "                'personalized': eval_res['reward_personalized'].mean(),\n",
        "                'pfl': eval_res['reward_pfl_finetuned'].mean()\n",
        "            }\n",
        "            results['avg_rewards'] = avg_rewards\n",
        "            print(\"\\nâœ… å¯¦é©—çµæœæ‘˜è¦:\")\n",
        "            print(f\"   - å¹³å‡å…¨å±€çå‹µ: {avg_rewards['global']:.4f}\")\n",
        "            print(f\"   - å¹³å‡å€‹æ€§åŒ–çå‹µ: {avg_rewards['personalized']:.4f}\")\n",
        "            print(f\"   - å¹³å‡PFLå¾®èª¿çå‹µ: {avg_rewards['pfl']:.4f}\")\n",
        "\n",
        "        # æ”¶é›†éš±ç§æˆæœ¬\n",
        "        privacy_file = os.path.join(config.output_dir, f'{config.experiment_name}_reward_vs_epsilon.csv')\n",
        "        if os.path.exists(privacy_file):\n",
        "            privacy_df = pd.read_csv(privacy_file)\n",
        "            final_epsilon = privacy_df['cumulative_epsilon'].iloc[-1]\n",
        "            results['privacy_stats'] = {'consumed_epsilon': final_epsilon}\n",
        "            print(f\"   - æœ€çµ‚éš±ç§æ¶ˆè€— Îµ: {final_epsilon:.4f}\")\n",
        "\n",
        "        return True, results\n",
        "\n",
        "    except Exception as e:\n",
        "        execution_time = (time.time() - start_time) / 60\n",
        "        print(f\"\\nâŒ å¯¦é©— '{config_dict.get('experiment_name')}' å¤±æ•—ï¼ (è€—æ™‚: {execution_time:.2f} åˆ†é˜)\")\n",
        "        import traceback\n",
        "        print(f\"ğŸ” éŒ¯èª¤è©³æƒ…: {e}\")\n",
        "        print(f\"ğŸ“‹ éŒ¯èª¤å †ç–Š: {traceback.format_exc()}\")\n",
        "        return False, {'error': str(e)}\n",
        "\n",
        "    finally:\n",
        "        # æ¸…ç†è³‡æº\n",
        "        del runner\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "print(\"âœ… Cell 8A: å¯¦é©—åŸ·è¡Œä¸»å‡½æ•¸ï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å·²è¼‰å…¥ã€‚\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-FLqX0zbIdb",
        "outputId": "eee9b949-26c9-4353-f900-54c1c5e32c18"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cell 8A: å¯¦é©—åŸ·è¡Œä¸»å‡½æ•¸ï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å·²è¼‰å…¥ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8B: ğŸ”§ ç’°å¢ƒè¨­å®šèˆ‡åˆå§‹åŒ–ï¼ˆç¢ºå®šæ€§ä¿®æ­£ç‰ˆï¼‰\n",
        "import os\n",
        "import time\n",
        "\n",
        "# --- ã€éŒ¯èª¤ä¿®æ­£ã€‘ ---\n",
        "# (ä»»å‹™ 6 çš„è£œå¼·) æ ¹æ“š PyTorch éŒ¯èª¤æç¤ºï¼Œè¨­å®šæ­¤ç’°å¢ƒè®Šæ•¸ä»¥å•Ÿç”¨ CuBLAS çš„ç¢ºå®šæ€§æ¼”ç®—æ³•ã€‚\n",
        "# é€™å¿…é ˆåœ¨ä»»ä½• PyTorch/CUDA æ“ä½œä¹‹å‰å®Œæˆã€‚\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "# --- END ä¿®æ­£ ---\n",
        "\n",
        "# GPUç’°å¢ƒè¨­å®š\n",
        "setup_gpu_environment()\n",
        "\n",
        "# ç’°å¢ƒè·¯å¾‘è¨­å®š\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_WORK_DIR = \"/content/drive/MyDrive/FRL_Slicing_Sim\" # ä½¿ç”¨æ–°ç›®éŒ„\n",
        "    print(\"ğŸ”— Google Drive æ›è¼‰æˆåŠŸ\")\n",
        "except ImportError:\n",
        "    BASE_WORK_DIR = \"./FRL_Slicing_Sim\"\n",
        "    print(\"ğŸ’» æœ¬åœ°ç’°å¢ƒæ¨¡å¼\")\n",
        "\n",
        "# ç¢ºä¿è·¯å¾‘å­˜åœ¨\n",
        "os.makedirs(BASE_WORK_DIR, exist_ok=True)\n",
        "# æ³¨æ„: ç¢ºä¿æ‚¨çš„ kpi_traces_final_robust0.parquet æ–‡ä»¶ä½æ–¼ BASE_WORK_DIR ä¸­\n",
        "DATA_PATH = os.path.join(BASE_WORK_DIR, \"kpi_traces_final_robust0.parquet\")\n",
        "BASE_OUTPUT_DIR = os.path.join(BASE_WORK_DIR, \"outputs_expert\")\n",
        "os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    print(f\"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æ•¸æ“šæ–‡ä»¶ï¼è«‹å°‡ 'kpi_traces_final_robust0.parquet' ä¸Šå‚³åˆ° '{BASE_WORK_DIR}'\")\n",
        "else:\n",
        "    print(f\"ğŸ“ æ•¸æ“šè·¯å¾‘: {DATA_PATH}\")\n",
        "\n",
        "print(f\"ğŸ“ è¼¸å‡ºç›®éŒ„: {BASE_OUTPUT_DIR}\")\n",
        "\n",
        "# å¯¦é©—é…ç½®\n",
        "# æ–°å¢ CQL ä½œç‚ºå°æ¯”\n",
        "MODES_TO_RUN = [\"ClusteredFL\", \"FedProx\", \"FedAvg\", \"CQL\"]\n",
        "SEEDS = [42] # ç‚ºç¯€çœæ™‚é–“ï¼Œåƒ…ç”¨ä¸€å€‹ç¨®å­\n",
        "\n",
        "print(f\"\\nğŸ¯ å¯¦é©—è¨ˆåŠƒ:\")\n",
        "print(f\"   - æ¸¬è©¦æ¨¡å¼: {MODES_TO_RUN}\")\n",
        "print(f\"   - éš¨æ©Ÿç¨®å­: {SEEDS}\")\n",
        "print(f\"   - ç¸½å¯¦é©—æ•¸: {len(MODES_TO_RUN) * len(SEEDS)}\")\n",
        "\n",
        "# å…¨å±€çµæœå­˜å„²\n",
        "master_results_log = []\n",
        "\n",
        "print(\"\\nâœ… ç’°å¢ƒè¨­å®šå®Œæˆï¼Œæº–å‚™åŸ·è¡Œå¯¦é©—ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "XV-f8JLAbKMS",
        "outputId": "c04c8e9e-60c3-4ec6-b54c-f882bcc4b88e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ® GPU æª¢æ¸¬: Tesla T4\n",
            "ğŸ§¹ GPU ç’°å¢ƒå·²è¨­å®šä¸¦å„ªåŒ–ã€‚\n",
            "Mounted at /content/drive\n",
            "ğŸ”— Google Drive æ›è¼‰æˆåŠŸ\n",
            "ğŸ“ æ•¸æ“šè·¯å¾‘: /content/drive/MyDrive/FRL_Slicing_Sim/kpi_traces_final_robust0.parquet\n",
            "ğŸ“ è¼¸å‡ºç›®éŒ„: /content/drive/MyDrive/FRL_Slicing_Sim/outputs_expert\n",
            "\n",
            "ğŸ¯ å¯¦é©—è¨ˆåŠƒ:\n",
            "   - æ¸¬è©¦æ¨¡å¼: ['ClusteredFL', 'FedProx', 'FedAvg', 'CQL']\n",
            "   - éš¨æ©Ÿç¨®å­: [42]\n",
            "   - ç¸½å¯¦é©—æ•¸: 4\n",
            "\n",
            "âœ… ç’°å¢ƒè¨­å®šå®Œæˆï¼Œæº–å‚™åŸ·è¡Œå¯¦é©—ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8C: ğŸš€ å¯¦é©— 1 - ClusteredFLï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰\n",
        "# ç¢ºä¿ç’°å¢ƒå·²æº–å‚™å°±ç·’\n",
        "if 'BASE_OUTPUT_DIR' not in locals():\n",
        "    print(\"è«‹å…ˆé‹è¡Œ Cell 8B é€²è¡Œç’°å¢ƒè¨­å®šï¼\")\n",
        "else:\n",
        "    mode = \"ClusteredFL\"\n",
        "    for seed in SEEDS:\n",
        "        exp_name = f\"{mode}_expert_s{seed}\"\n",
        "        output_dir = os.path.join(BASE_OUTPUT_DIR, f\"seed_{seed}\", mode)\n",
        "\n",
        "        # ClusteredFL å°ˆç”¨é…ç½®\n",
        "        config = {\n",
        "            \"experiment_name\": exp_name,\n",
        "            \"output_dir\": output_dir,\n",
        "            \"mode\": mode,\n",
        "            \"random_seed\": seed,\n",
        "            \"comm_rounds\": 5, # ç¤ºä¾‹è¨“ç·´è¼ªæ•¸\n",
        "\n",
        "            \"num_clients\": 15,\n",
        "            \"dirichlet_alpha\": 0.4,\n",
        "            \"num_clients_to_select\": 8,\n",
        "\n",
        "            \"local_episodes_per_round\": 4,\n",
        "            \"batch_size\": 128,\n",
        "\n",
        "            # æ¨¡å¼ç‰¹å®šåƒæ•¸\n",
        "            \"fedprox_mu\": 0.1, # åœ¨ ClusteredFL ä¸­ä¹Ÿå¯ç”¨æ–¼æ‡²ç½°èˆ‡èšé¡ä¸­å¿ƒçš„è·é›¢\n",
        "            \"num_clusters\": 3,\n",
        "            \"cluster_update_freq\": 3,\n",
        "\n",
        "            \"enable_dp\": True,\n",
        "            \"dp_target_epsilon\": 8.0,\n",
        "            \"dp_noise_multiplier\": 0.6,\n",
        "            \"dp_max_grad_norm\": 1.5, # å‡è¨­ä¸€å€‹åˆå§‹å€¼ï¼Œå¦‚æœå•Ÿç”¨è‡ªé©æ‡‰æœƒè¢«è¦†è“‹\n",
        "            \"enable_adaptive_clipping\": True,\n",
        "            \"adaptive_clipping_percentile\": 0.8,\n",
        "\n",
        "            \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        }\n",
        "\n",
        "        # åŸ·è¡Œå¯¦é©—\n",
        "        success, result_info = run_single_experiment(config, DATA_PATH)\n",
        "\n",
        "        # è¨˜éŒ„çµæœ\n",
        "        master_results_log.append({\n",
        "            'seed': seed, 'mode': mode, 'success': success, 'result_info': result_info\n",
        "        })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d4e62175267b4b0d9f823ed94693fb6b",
            "4eae03b77833490c901481782ada898c",
            "d12be659f2dd43198d43b879434ee8d7",
            "6ebcb5e03a8d4d35b1388dad65f3a62e",
            "926879cf15a7449485f67b4c8b5af75d",
            "05ac3b5efef344548d590367e90b77d3",
            "2ad37512e9c04ef8b4df55b8bb31c116",
            "62eeb1961b3c450f8bb98e973ea301bd",
            "1bae2a1144f749a18716174d3490edba",
            "27635c9a414b473aaf618309ccac42f8",
            "1d1bcc4ce3804e8c9da04843c4c0b057",
            "c4b8984c33384cf5a94326c18b4950a4",
            "e9bc722af3e24624911a4ad3187446ca",
            "c0cefb7c0a924650acd3263f35eab243",
            "8920d9e4c8bf48fd85f6951fd063038d",
            "939ec7c7559b41069189bd0b34855ff4",
            "01a6787e2ba74c828e0ecc6e6d3ee084",
            "54363bf8e7204c59bcb465a503a3d519",
            "80417484270e4fedbc5aacf357d34574",
            "5ea5e63c4f654e1b9ba7a630c94a9a32",
            "212d572aa4c449039faecc8d23ed08fd",
            "74b8cafd5303482493b357a610f2da0c"
          ]
        },
        "cellView": "form",
        "id": "hqcSUEPXbLWB",
        "outputId": "9fef76dc-5ecd-4ec5-9b71-fa691dffffd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ GPU ç’°å¢ƒæª¢æ¸¬åˆ°: Tesla T4\n",
            "\n",
            "--- æ ¸å¿ƒå¯¦é©—é…ç½® ---\n",
            "æ¨¡å¼: ClusteredFL | å®¢æˆ¶ç«¯æ•¸: 15 (Non-IID, Î±=0.4)\n",
            "æ¯è¼ªåƒèˆ‡: 8 | é€šä¿¡è¼ªæ•¸: 5\n",
            "ğŸ›¡ï¸  å·®åˆ†éš±ç§ (DP): å•Ÿç”¨\n",
            "   - ç›®æ¨™é ç®—: Îµ=8.0, Î´=1e-05\n",
            "   - å™ªè²ä¹˜æ•¸: 0.6\n",
            "   - æ¢¯åº¦è£å‰ª: è‡ªé©æ‡‰\n",
            "   - é ç®—é‡è¨­: å•Ÿç”¨\n",
            "\n",
            "==================== æ­£åœ¨å•Ÿå‹•å¯¦é©—: ClusteredFL_expert_s42 ====================\n",
            "\n",
            "[DataManager] æ­£åœ¨å¾ /content/drive/MyDrive/FRL_Slicing_Sim/kpi_traces_final_robust0.parquet è®€å–æ•¸æ“š...\n",
            "\n",
            "==================== DataManager å•Ÿå‹•å‰é æª¢æŸ¥ ====================\n",
            "âœ… æ¸…ç†å¾Œçš„æ¬„ä½åˆ—è¡¨ (å…± 38 å€‹)\n",
            "   - ååé‡æ¬„ä½æˆåŠŸåŒ¹é…: 'throughput_dl_mbps'\n",
            "   - å»¶é²/ç·©è¡å€æ¬„ä½æˆåŠŸåŒ¹é…: 'buffer_occupancy_dl_bytes'\n",
            "=================================================================\n",
            "\n",
            "torch.use_deterministic_algorithms(True) å·²è¨­ç½®\n",
            "\n",
            "[DataManager] æ­£åœ¨ç‚º 15 å€‹å®¢æˆ¶ç«¯ç”Ÿæˆ Non-IID æ•¸æ“šåˆ†å€...\n",
            "   - Dirichlet Alpha (Î±): 0.4\n",
            "[DataManager] æ­£åœ¨åˆä½µ eMBB å’Œ URLLC çš„æ•¸æ“šè»Œè·¡...\n",
            "[DataManager] å…¨å±€æ•¸æ“šè»Œè·¡åˆä½µå®Œæˆï¼Œå…± 196183 å€‹æ™‚é–“æ­¥ã€‚\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "å‰µå»ºå®¢æˆ¶ç«¯è»Œè·¡:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4e62175267b4b0d9f823ed94693fb6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   - å®¢æˆ¶ç«¯ 0: 3180 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 1: 18666 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 2: 500 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 3: 500 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 4: 10379 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 5: 500 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 6: 32423 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 7: 522 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 8: 1891 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 9: 4542 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 10: 1709 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 11: 5204 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 12: 660 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 13: 500 å€‹æ™‚é–“æ­¥\n",
            "   - å®¢æˆ¶ç«¯ 14: 115007 å€‹æ™‚é–“æ­¥\n",
            "\n",
            "[DataManager] Non-IID æ•¸æ“šè™•ç†å®Œæˆï¼æˆåŠŸç‚º 15 / 15 å€‹å®¢æˆ¶ç«¯å‰µå»ºäº†ç’°å¢ƒã€‚\n",
            "\n",
            "[Adaptive Clipper] æ­£åœ¨é è¨ˆç®—æ¢¯åº¦è£å‰ªç¯„æ•¸...\n",
            "   - åŸ·è¡Œé ç†±æ­¥é©Ÿä»¥æ”¶é›†æ¢¯åº¦ç¯„æ•¸...\n",
            "   - âœ… é è¨ˆç®—å®Œæˆã€‚å»ºè­°çš„è£å‰ªç¯„æ•¸ (80 ç™¾åˆ†ä½): 1661435.57\n",
            "[FLServer] åˆå§‹åŒ–å®Œæˆ - æ¨¡å¼: ClusteredFL, èšé¡æ•¸: 3\n",
            "\n",
            "[ExperimentRunner] æ­£åœ¨åˆå§‹åŒ–æ‰€æœ‰å®¢æˆ¶ç«¯ä»£ç†...\n",
            "[C-0] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-1] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-2] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-3] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-4] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-5] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-6] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-7] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-8] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-9] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-10] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-11] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-12] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-13] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "[C-14] ğŸ›¡ï¸ æ­£åœ¨åˆå§‹åŒ–å·®åˆ†éš±ç§å¼•æ“...\n",
            "   - âœ… å·®åˆ†éš±ç§å¼•æ“åˆå§‹åŒ–æˆåŠŸ (GradSampleModule)\n",
            "âœ… é…ç½®å·²ä¿å­˜è‡³: /content/drive/MyDrive/FRL_Slicing_Sim/outputs_expert/seed_42/ClusteredFL/ClusteredFL_expert_s42_config.json\n",
            "\n",
            "[ExperimentRunner] åˆå§‹åŒ–å®Œæˆã€‚\n",
            "\n",
            "==================== ğŸƒâ€â™‚ï¸ é–‹å§‹åŸ·è¡Œå¯¦é©—: ClusteredFL_expert_s42 (ClusteredFL) ====================\n",
            "\n",
            "[æ¨¡å¼] é–‹å§‹è¯é‚¦å¼è¨“ç·´ (ClusteredFL)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ClusteredFL Training:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4b8984c33384cf5a94326c18b4950a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 1] âš ï¸ è¿‘å³æ™‚å»¶é²è­¦å‘Š: æœ¬è¼ªè€—æ™‚ 1022.09 ç§’ > 1 ç§’ã€‚\n",
            "[Round 2] âš ï¸ è¿‘å³æ™‚å»¶é²è­¦å‘Š: æœ¬è¼ªè€—æ™‚ 1984.96 ç§’ > 1 ç§’ã€‚\n",
            "[Round 3] âš ï¸ è¿‘å³æ™‚å»¶é²è­¦å‘Š: æœ¬è¼ªè€—æ™‚ 2238.01 ç§’ > 1 ç§’ã€‚\n",
            "\n",
            "[FLServer] Round 3: æ­£åœ¨æ›´æ–°å®¢æˆ¶ç«¯èšé¡...\n",
            "[FLServer] èšé¡æ›´æ–°å®Œæˆ:\n",
            "  - èšé¡ 0: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14]\n",
            "  - èšé¡ 1: [13]\n",
            "  - èšé¡ 2: [6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8D: ğŸš€ å¯¦é©— 2 - FedProx & FedAvgï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰\n",
        "if 'BASE_OUTPUT_DIR' not in locals():\n",
        "    print(\"è«‹å…ˆé‹è¡Œ Cell 8B é€²è¡Œç’°å¢ƒè¨­å®šï¼\")\n",
        "else:\n",
        "    for mode in [\"FedProx\", \"FedAvg\"]:\n",
        "        for seed in SEEDS:\n",
        "            exp_name = f\"{mode}_expert_s{seed}\"\n",
        "            output_dir = os.path.join(BASE_OUTPUT_DIR, f\"seed_{seed}\", mode)\n",
        "\n",
        "            config = {\n",
        "                \"experiment_name\": exp_name,\n",
        "                \"output_dir\": output_dir,\n",
        "                \"mode\": mode,\n",
        "                \"random_seed\": seed,\n",
        "                \"comm_rounds\": 5,\n",
        "\n",
        "                \"num_clients\": 15,\n",
        "                \"dirichlet_alpha\": 0.4,\n",
        "                \"num_clients_to_select\": 8,\n",
        "\n",
        "                \"local_episodes_per_round\": 4,\n",
        "                \"batch_size\": 128,\n",
        "\n",
        "                # FedProx çš„ mu å€¼ï¼Œåœ¨ FedAvg æ¨¡å¼ä¸‹æœƒè¢«è‡ªå‹•è¨­ç‚º 0\n",
        "                \"fedprox_mu\": 0.1,\n",
        "\n",
        "                \"enable_dp\": True,\n",
        "                \"dp_target_epsilon\": 8.0,\n",
        "                \"dp_noise_multiplier\": 0.6,\n",
        "                \"dp_max_grad_norm\": 1.5,\n",
        "                \"enable_adaptive_clipping\": True,\n",
        "                \"adaptive_clipping_percentile\": 0.8,\n",
        "\n",
        "                \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            }\n",
        "\n",
        "            # åŸ·è¡Œå¯¦é©—\n",
        "            success, result_info = run_single_experiment(config, DATA_PATH)\n",
        "\n",
        "            # è¨˜éŒ„çµæœ\n",
        "            master_results_log.append({\n",
        "                'seed': seed, 'mode': mode, 'success': success, 'result_info': result_info\n",
        "            })"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1ouEe1u-bMmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8E: ğŸš€ å¯¦é©— 3 - CQL Baselineï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰\n",
        "if 'BASE_OUTPUT_DIR' not in locals():\n",
        "    print(\"è«‹å…ˆé‹è¡Œ Cell 8B é€²è¡Œç’°å¢ƒè¨­å®šï¼\")\n",
        "else:\n",
        "    mode = \"CQL\"\n",
        "    for seed in SEEDS:\n",
        "        exp_name = f\"{mode}_expert_s{seed}\"\n",
        "        output_dir = os.path.join(BASE_OUTPUT_DIR, f\"seed_{seed}\", mode)\n",
        "\n",
        "        config = {\n",
        "            \"experiment_name\": exp_name,\n",
        "            \"output_dir\": output_dir,\n",
        "            \"mode\": mode,\n",
        "            \"random_seed\": seed,\n",
        "            \"comm_rounds\": 5,\n",
        "\n",
        "            \"num_clients\": 15,\n",
        "            \"dirichlet_alpha\": 0.4,\n",
        "            \"num_clients_to_select\": 8,\n",
        "\n",
        "            \"local_episodes_per_round\": 4,\n",
        "            \"batch_size\": 128,\n",
        "\n",
        "            # CQL ç‰¹å®šåƒæ•¸\n",
        "            \"enable_cql\": True,\n",
        "            \"cql_alpha\": 7.5,\n",
        "            \"cql_temperature\": 1.0,\n",
        "\n",
        "            # CQL æ˜¯ä¸€ç¨®éè¯é‚¦çš„èšåˆæ–¹æ³•ï¼Œä½†æˆ‘å€‘é€™è£¡æ¨¡æ“¬åœ¨ FL è¨­å®šä¸‹çš„è¡¨ç¾\n",
        "            # å› æ­¤ fedprox_mu è¨­ç‚º 0\n",
        "            \"fedprox_mu\": 0.0,\n",
        "\n",
        "            \"enable_dp\": True,\n",
        "            \"dp_target_epsilon\": 8.0,\n",
        "            \"dp_noise_multiplier\": 0.6,\n",
        "            \"dp_max_grad_norm\": 1.5,\n",
        "            \"enable_adaptive_clipping\": True,\n",
        "            \"adaptive_clipping_percentile\": 0.8,\n",
        "\n",
        "            \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        }\n",
        "\n",
        "        # åŸ·è¡Œå¯¦é©—\n",
        "        success, result_info = run_single_experiment(config, DATA_PATH)\n",
        "\n",
        "        # è¨˜éŒ„çµæœ\n",
        "        master_results_log.append({\n",
        "            'seed': seed, 'mode': mode, 'success': success, 'result_info': result_info\n",
        "        })"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2x7606tsbN6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8F: ğŸ“Š å¯¦é©—ç¸½çµï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ‰ æ‰€æœ‰å¯¦é©—åŸ·è¡Œå®Œæˆï¼\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# çµ±è¨ˆæˆåŠŸç‡\n",
        "successful_experiments = sum(1 for r in master_results_log if r['success'])\n",
        "total_experiments = len(master_results_log)\n",
        "success_rate = (successful_experiments / total_experiments) * 100 if total_experiments > 0 else 0\n",
        "\n",
        "print(f\"\\nğŸ“Š å¯¦é©—çµ±è¨ˆ:\")\n",
        "print(f\"   - ç¸½å¯¦é©—æ•¸: {total_experiments}\")\n",
        "print(f\"   - æˆåŠŸæ•¸: {successful_experiments}\")\n",
        "print(f\"   - æˆåŠŸç‡: {success_rate:.1f}%\\n\")\n",
        "\n",
        "# æˆåŠŸå¯¦é©—çš„è©³ç´°çµ±è¨ˆ\n",
        "summary_data = []\n",
        "for result in master_results_log:\n",
        "    if result['success']:\n",
        "        mode = result['mode']\n",
        "        info = result['result_info']\n",
        "        if info and 'avg_rewards' in info:\n",
        "            rewards = info['avg_rewards']\n",
        "            privacy = info.get('privacy_stats', {'consumed_epsilon': 0})\n",
        "\n",
        "            summary_data.append({\n",
        "                'Mode': mode,\n",
        "                'Global Reward': rewards.get('global', 0),\n",
        "                'Personalized Reward': rewards.get('personalized', 0),\n",
        "                'PFL Reward': rewards.get('pfl', 0),\n",
        "                'Epsilon': privacy.get('consumed_epsilon', 0),\n",
        "                'Time (min)': info.get('execution_time', 0)\n",
        "            })\n",
        "\n",
        "if summary_data:\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    summary_df = summary_df.round(4)\n",
        "\n",
        "    # è¨ˆç®—æå‡ç‡å’Œéš±ç§æ•ˆç‡\n",
        "    best_global_reward = summary_df.loc[summary_df['Mode'] != 'CQL', 'Global Reward'].max()\n",
        "    summary_df['PFL Improvement (%)'] = (summary_df['PFL Reward'] / summary_df['Global Reward'] - 1) * 100\n",
        "    summary_df['Privacy-Utility'] = summary_df['PFL Reward'] / summary_df['Epsilon'].replace(0, 1e-9)\n",
        "\n",
        "    summary_df = summary_df.round(2)\n",
        "\n",
        "    print(\"ğŸ“ˆ æˆåŠŸå¯¦é©—è©³ç´°çµæœ:\")\n",
        "    print(summary_df.to_markdown(index=False))\n",
        "\n",
        "    # æ¯”è¼ƒä¸åŒæ–¹æ³•\n",
        "    if len(summary_df) > 1:\n",
        "        best_pfl = summary_df.loc[summary_df['PFL Reward'].idxmax()]\n",
        "        best_privacy_utility = summary_df.loc[summary_df['Privacy-Utility'].idxmax()]\n",
        "\n",
        "        print(f\"\\nğŸ† æœ€ä½³è¡¨ç¾:\")\n",
        "        print(f\"   - æœ€ä½³ PFL çå‹µ: {best_pfl['Mode']} ({best_pfl['PFL Reward']:.4f})\")\n",
        "        print(f\"   - æœ€ä½³éš±ç§æ•ˆç”¨æ¬Šè¡¡: {best_privacy_utility['Mode']} ({best_privacy_utility['Privacy-Utility']:.4f} Reward/Îµ)\")\n",
        "\n",
        "# ä¿å­˜å¯¦é©—ç¸½çµ\n",
        "summary_path = os.path.join(BASE_OUTPUT_DIR, \"experiment_summary.json\")\n",
        "with open(summary_path, 'w') as f:\n",
        "    # å‰µå»ºä¸€å€‹å¯åºåˆ—åŒ–çš„ç‰ˆæœ¬\n",
        "    serializable_log = []\n",
        "    for log in master_results_log:\n",
        "        new_log = log.copy()\n",
        "        if isinstance(new_log.get('result_info'), dict):\n",
        "             new_log['result_info'].pop('error', None) # ç§»é™¤ä¸å¯åºåˆ—åŒ–çš„ Error å°è±¡\n",
        "        serializable_log.append(new_log)\n",
        "    json.dump(serializable_log, f, indent=4)\n",
        "print(f\"\\nğŸ“„ å¯¦é©—ç¸½çµå·²ä¿å­˜è‡³: {summary_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q3sFkjTjbPGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 9: ğŸ“Š çµæœè¦–è¦ºåŒ–ï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def load_all_expert_results(base_output_dir):\n",
        "    \"\"\"\n",
        "    å¾æŒ‡å®šçš„è¼¸å‡ºç›®éŒ„åŠ è¼‰æ‰€æœ‰å°ˆå®¶å¯¦é©—çš„ reward_vs_epsilon.csv å’Œ evaluation_results.csv æ–‡ä»¶ã€‚\n",
        "    \"\"\"\n",
        "    all_evals, all_reward_vs_eps = [], []\n",
        "\n",
        "    if not os.path.exists(base_output_dir):\n",
        "        print(f\"âŒ çµæœç›®éŒ„æœªæ‰¾åˆ°: {base_output_dir}\")\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    eval_files = glob.glob(os.path.join(base_output_dir, '**', '*_evaluation_results.csv'), recursive=True)\n",
        "    reward_eps_files = glob.glob(os.path.join(base_output_dir, '**', '*_reward_vs_epsilon.csv'), recursive=True)\n",
        "\n",
        "    def extract_info_from_path(path):\n",
        "        parts = path.split(os.sep)\n",
        "        # é æœŸè·¯å¾‘çµæ§‹: .../seed_XX/MODE/...\n",
        "        mode = parts[-2]\n",
        "        seed_str = [p for p in parts if p.startswith('seed_')][0]\n",
        "        seed = int(seed_str.split('_')[1])\n",
        "        return mode, seed\n",
        "\n",
        "    for f in eval_files:\n",
        "        try:\n",
        "            df = pd.read_csv(f)\n",
        "            mode, seed = extract_info_from_path(f)\n",
        "            df['mode'] = mode\n",
        "            df['seed'] = seed\n",
        "            all_evals.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"ğŸŸ¡ è­¦å‘Š: è®€å–è©•ä¼°æ–‡ä»¶å¤±æ•—: {f}, {e}\")\n",
        "\n",
        "    for f in reward_eps_files:\n",
        "        try:\n",
        "            df = pd.read_csv(f)\n",
        "            mode, seed = extract_info_from_path(f)\n",
        "            df['mode'] = mode\n",
        "            df['seed'] = seed\n",
        "            all_reward_vs_eps.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"ğŸŸ¡ è­¦å‘Š: è®€å–çå‹µæ–‡ä»¶å¤±æ•—: {f}, {e}\")\n",
        "\n",
        "    return (pd.concat(all_evals, ignore_index=True) if all_evals else pd.DataFrame()), \\\n",
        "           (pd.concat(all_reward_vs_eps, ignore_index=True) if all_reward_vs_eps else pd.DataFrame())\n",
        "\n",
        "# --- è¦–è¦ºåŒ–è¨­å®š ---\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
        "FIGURES_OUTPUT_DIR = os.path.join(BASE_OUTPUT_DIR, \"figures\")\n",
        "os.makedirs(FIGURES_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ” æ­£åœ¨å¾ä»¥ä¸‹è·¯å¾‘åŠ è¼‰çµæœ: {BASE_OUTPUT_DIR}\")\n",
        "eval_df, reward_vs_eps_df = load_all_expert_results(BASE_OUTPUT_DIR)\n",
        "\n",
        "if eval_df.empty or reward_vs_eps_df.empty:\n",
        "    print(\"âŒ æœªæ‰¾åˆ°ä»»ä½•çµæœæ–‡ä»¶ï¼Œç„¡æ³•ç”Ÿæˆåœ–è¡¨ã€‚è«‹ç¢ºä¿ Cell 8 çš„å¯¦é©—å·²æˆåŠŸå®Œæˆã€‚\")\n",
        "else:\n",
        "    mode_order = [\"FedAvg\", \"FedProx\", \"ClusteredFL\", \"CQL\"]\n",
        "    print(f\"âœ… æˆåŠŸåŠ è¼‰äº† {len(eval_df['seed'].unique())} æ¬¡é‹è¡Œçš„çµæœã€‚\")\n",
        "    print(f\"ğŸ“Š æ‰¾åˆ°çš„æ¨¡å¼: {sorted(eval_df['mode'].unique())}\")\n",
        "\n",
        "    # --- åœ– 1: è¨“ç·´æ­·å²ï¼ˆçå‹µ vs. é€šä¿¡è¼ªï¼‰ ---\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    sns.lineplot(data=reward_vs_eps_df, x='round', y='avg_reward', hue='mode',\n",
        "                 hue_order=[m for m in mode_order if m in reward_vs_eps_df['mode'].unique()],\n",
        "                 errorbar='sd', linewidth=2.5)\n",
        "    plt.title('Training Performance Comparison', fontsize=18, weight='bold')\n",
        "    plt.xlabel('Communication Round', fontsize=14)\n",
        "    plt.ylabel('Average Episodic Reward', fontsize=14)\n",
        "    plt.legend(title='Training Mode', fontsize=12)\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'expert_training_history.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # --- åœ– 2: æœ€çµ‚æ€§èƒ½æ¯”è¼ƒ (PFL Reward) ---\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    sns.boxplot(data=eval_df, x='mode', y='reward_pfl_finetuned',\n",
        "                order=[m for m in mode_order if m in eval_df['mode'].unique()])\n",
        "    plt.title('Final Performance After PFL Fine-tuning', fontsize=18, weight='bold')\n",
        "    plt.xlabel('Experiment Mode', fontsize=14)\n",
        "    plt.ylabel('Final Reward Score', fontsize=14)\n",
        "    plt.xticks(rotation=10)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'expert_final_performance.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # --- åœ– 3: éš±ç§-æ•ˆç”¨æ¬Šè¡¡æ›²ç·š ---\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    sns.lineplot(data=reward_vs_eps_df, x='cumulative_epsilon', y='avg_reward', hue='mode',\n",
        "                 hue_order=[m for m in mode_order if m in reward_vs_eps_df['mode'].unique()],\n",
        "                 errorbar='sd', linewidth=2.5, marker='o', markersize=5, markevery=1)\n",
        "    plt.title('Privacy-Utility Trade-off Curve', fontsize=18, weight='bold')\n",
        "    plt.xlabel('Cumulative Privacy Loss Îµ (Epsilon)', fontsize=14)\n",
        "    plt.ylabel('Average Episodic Reward', fontsize=14)\n",
        "    plt.legend(title='Training Mode')\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'expert_privacy_utility_tradeoff.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # --- åœ– 4: å€‹æ€§åŒ–æ•ˆç›Šåˆ†æ (ä»¥ ClusteredFL ç‚ºä¾‹) ---\n",
        "    if 'ClusteredFL' in eval_df['mode'].unique():\n",
        "        target_eval = eval_df[eval_df['mode'] == 'ClusteredFL']\n",
        "        target_melted = target_eval.melt(\n",
        "            id_vars=['client_id'],\n",
        "            value_vars=['reward_global', 'reward_personalized', 'reward_pfl_finetuned'],\n",
        "            var_name='Model Type', value_name='Average Reward'\n",
        "        ).replace({\n",
        "            'reward_global': 'Global', 'reward_personalized': 'Clustered', 'reward_pfl_finetuned': 'PFL-Finetuned'\n",
        "        })\n",
        "\n",
        "        plt.figure(figsize=(15, 7))\n",
        "        sns.barplot(data=target_melted, x='client_id', y='Average Reward', hue='Model Type', palette='viridis')\n",
        "        plt.title('Personalization Benefits in ClusteredFL', fontsize=16, weight='bold')\n",
        "        plt.xlabel('Client ID', fontsize=14)\n",
        "        plt.ylabel('Average Reward', fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'expert_personalization_benefit.png'), dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "print(f\"âœ… Cell 9: çµæœè¦–è¦ºåŒ–ï¼ˆå°ˆå®¶ä¿®æ­£ç‰ˆï¼‰å·²å®Œæˆã€‚\")\n",
        "print(f\"ğŸ“ æ‰€æœ‰åœ–è¡¨å·²ä¿å­˜è‡³: {FIGURES_OUTPUT_DIR}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LVRV21G5bQeZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d4e62175267b4b0d9f823ed94693fb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eae03b77833490c901481782ada898c",
              "IPY_MODEL_d12be659f2dd43198d43b879434ee8d7",
              "IPY_MODEL_6ebcb5e03a8d4d35b1388dad65f3a62e"
            ],
            "layout": "IPY_MODEL_926879cf15a7449485f67b4c8b5af75d"
          }
        },
        "4eae03b77833490c901481782ada898c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ac3b5efef344548d590367e90b77d3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2ad37512e9c04ef8b4df55b8bb31c116",
            "value": "å‰µå»ºå®¢æˆ¶ç«¯è»Œè·¡:â€‡100%"
          }
        },
        "d12be659f2dd43198d43b879434ee8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62eeb1961b3c450f8bb98e973ea301bd",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bae2a1144f749a18716174d3490edba",
            "value": 15
          }
        },
        "6ebcb5e03a8d4d35b1388dad65f3a62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27635c9a414b473aaf618309ccac42f8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1d1bcc4ce3804e8c9da04843c4c0b057",
            "value": "â€‡15/15â€‡[00:00&lt;00:00,â€‡328.84it/s]"
          }
        },
        "926879cf15a7449485f67b4c8b5af75d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ac3b5efef344548d590367e90b77d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ad37512e9c04ef8b4df55b8bb31c116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62eeb1961b3c450f8bb98e973ea301bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bae2a1144f749a18716174d3490edba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27635c9a414b473aaf618309ccac42f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1bcc4ce3804e8c9da04843c4c0b057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4b8984c33384cf5a94326c18b4950a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9bc722af3e24624911a4ad3187446ca",
              "IPY_MODEL_c0cefb7c0a924650acd3263f35eab243",
              "IPY_MODEL_8920d9e4c8bf48fd85f6951fd063038d"
            ],
            "layout": "IPY_MODEL_939ec7c7559b41069189bd0b34855ff4"
          }
        },
        "e9bc722af3e24624911a4ad3187446ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01a6787e2ba74c828e0ecc6e6d3ee084",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_54363bf8e7204c59bcb465a503a3d519",
            "value": "ClusteredFLâ€‡Training:â€‡â€‡60%"
          }
        },
        "c0cefb7c0a924650acd3263f35eab243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80417484270e4fedbc5aacf357d34574",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ea5e63c4f654e1b9ba7a630c94a9a32",
            "value": 3
          }
        },
        "8920d9e4c8bf48fd85f6951fd063038d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_212d572aa4c449039faecc8d23ed08fd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_74b8cafd5303482493b357a610f2da0c",
            "value": "â€‡3/5â€‡[1:27:25&lt;1:02:50,â€‡1885.08s/it,â€‡eps=0.000,â€‡loss=47339296.9048,â€‡reward=272.60]"
          }
        },
        "939ec7c7559b41069189bd0b34855ff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01a6787e2ba74c828e0ecc6e6d3ee084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54363bf8e7204c59bcb465a503a3d519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80417484270e4fedbc5aacf357d34574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ea5e63c4f654e1b9ba7a630c94a9a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "212d572aa4c449039faecc8d23ed08fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b8cafd5303482493b357a610f2da0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}