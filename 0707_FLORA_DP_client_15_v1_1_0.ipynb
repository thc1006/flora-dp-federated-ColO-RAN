{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thc1006/flora-dp-federated-ColO-RAN/blob/main/0707_FLORA_DP_client_15_v1_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 1: 環境設定與函式庫匯入（修正版）\n",
        "!pip install --upgrade opacus -q\n",
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np, pandas as pd, random, copy, json, os, time, warnings, math, re, contextlib\n",
        "from collections import deque\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from dataclasses import dataclass, asdict\n",
        "from sklearn.cluster import KMeans\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "from opacus.data_loader import DPDataLoader\n",
        "\n",
        "# --- 環境設定 ---\n",
        "try: torch._dynamo.disable()\n",
        "except Exception: pass\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=\".*overflow encountered.*\", category=RuntimeWarning)\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "print(\"✅ Cell 1: 環境與函式庫準備就緒。\")\n",
        "import opacus\n",
        "print(f\"PyTorch/Opacus 版本: {torch.__version__} / {opacus.__version__}\")\n",
        "print(f\"CUDA 是否可用: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8scIko-a3n-",
        "outputId": "dd8f1d50-63dd-4a1e-bfdf-d800cf839ae0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 1: 環境與函式庫準備就緒。\n",
            "PyTorch/Opacus 版本: 2.6.0+cu124 / 1.5.4\n",
            "CUDA 是否可用: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 2: 🎓 實驗參數設定（專家修正版）\n",
        "from dataclasses import dataclass, field\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    \"\"\"\n",
        "    儲存所有實驗的超參數與設定。\n",
        "\n",
        "    Attributes:\n",
        "        # 實驗基本設定\n",
        "        experiment_name (str): 實驗的唯一名稱。\n",
        "        output_dir (str): 儲存結果與模型的目錄。\n",
        "        mode (str): 訓練模式，例如 \"ClusteredFL\", \"FedProx\", \"FedAvg\", \"CQL\"。\n",
        "        random_seed (int): 用於可重現性的隨機種子。\n",
        "        comm_rounds (int): 聯邦學習的總通信輪數。\n",
        "\n",
        "        # Non-IID 客戶端生成 (任務 1)\n",
        "        num_clients (int): 要生成的總客戶端數量。\n",
        "        dirichlet_alpha (float): Dirichlet 分佈的 alpha 參數，用於控制 Non-IID 程度。alpha 越小，異質性越高。\n",
        "        min_samples_per_client (int): 確保每個客戶端至少擁有的樣本數。\n",
        "\n",
        "        # 聯邦學習設定\n",
        "        num_clients_to_select (int): 每輪隨機選擇參與訓練的客戶端數量。\n",
        "        fedprox_mu (float): FedProx 的近端項係數 mu。設為 0 等同於 FedAvg。\n",
        "        num_clusters (int): 在 ClusteredFL 模式下的聚類數量。\n",
        "        cluster_update_freq (int): ClusteredFL 模式下更新聚類的頻率（單位：輪）。\n",
        "\n",
        "        # 半非同步/容錯聚合 (任務 4)\n",
        "        async_threshold (float): 觸發非同步式聚合的客戶端超時/掉線比例閾值。\n",
        "\n",
        "        # RL 訓練參數\n",
        "        local_episodes_per_round (int): 每輪中，每個客戶端本地訓練的 episode 數量。\n",
        "        steps_per_episode (int): 每個 episode 的最大步數。\n",
        "        batch_size (int): 訓練時的批次大小。\n",
        "        gamma (float): RL 中的折扣因子。\n",
        "        lr (float): 學習率。\n",
        "        target_update_freq (int): 目標網路更新的頻率（單位：episode）。\n",
        "\n",
        "        # RL 探索參數\n",
        "        epsilon_start (float): Epsilon-greedy 策略的初始探索率。\n",
        "        epsilon_decay (float): Epsilon 的衰減率。\n",
        "        epsilon_min (float): Epsilon 的最小值。\n",
        "\n",
        "        # 記憶體與回放\n",
        "        memory_capacity (int): 經驗回放緩衝區的大小。\n",
        "        replay_start_size (int): 開始進行經驗回放所需的最小樣本數。\n",
        "        replay_frequency (int): 進行經驗回放的頻率（單位：步）。\n",
        "        replay_batches_per_call (int): 每次調用 replay 時訓練的批次數量。\n",
        "\n",
        "        # 離線 RL 偏差校正 (任務 2)\n",
        "        enable_cql (bool): 是否啟用 Conservative Q-Learning (CQL)。\n",
        "        cql_alpha (float): CQL 損失的權重。\n",
        "        cql_temperature (float): CQL 中用於 log-sum-exp 的溫度參數。\n",
        "\n",
        "        # 差分隱私 (DP) 設定\n",
        "        enable_dp (bool): 是否啟用差分隱私。\n",
        "        dp_target_epsilon (float): 目標的總隱私預算 epsilon。\n",
        "        dp_target_delta (float): 目標的 delta 值，通常為 1/dataset_size。\n",
        "        dp_max_grad_norm (float): 每個樣本梯度的裁剪範數 (clipping bound)。\n",
        "        dp_noise_multiplier (float): 添加到梯度中的噪聲乘數。\n",
        "\n",
        "        # Adaptive Clipping (任務 3)\n",
        "        enable_adaptive_clipping (bool): 是否啟用自適應梯度裁剪預計算。\n",
        "        adaptive_clipping_percentile (float): 用於預計算的梯度範數百分位數。\n",
        "\n",
        "        # DP 重設機制\n",
        "        enable_dp_reset (bool): 是否允許在隱私預算超支時重設隱私會計。\n",
        "        dp_reset_threshold_multiplier (float): 觸發重設的閾值 (相對於 target_epsilon)。\n",
        "\n",
        "        # 系統與異質性設定\n",
        "        enable_heterogeneity (bool): 是否模擬客戶端掉線 (dropout) 和延遲 (straggler)。\n",
        "        straggler_ratio (float): 延遲客戶端的比例。\n",
        "        dropout_ratio (float): 掉線客戶端的比例。\n",
        "        enable_compression (bool): 是否啟用模型壓縮 (quantize_fp16)。\n",
        "        use_pfl_finetune (bool): 是否在評估時執行個性化微調 (PFL)。\n",
        "        local_finetune_episodes (int): PFL 微調的 episode 數量。\n",
        "        device (str): 訓練設備 (\"cuda\" 或 \"cpu\")。\n",
        "    \"\"\"\n",
        "    # 實驗基本設定\n",
        "    experiment_name: str = \"DFRL_Experiment\"\n",
        "    output_dir: str = \"outputs\"\n",
        "    mode: str = \"ClusteredFL\"\n",
        "    random_seed: int = 42\n",
        "    comm_rounds: int = 20\n",
        "\n",
        "    # Non-IID 客戶端生成 (任務 1)\n",
        "    num_clients: int = 15\n",
        "    dirichlet_alpha: float = 0.4\n",
        "    min_samples_per_client: int = 500\n",
        "\n",
        "    # 聯邦學習設定\n",
        "    num_clients_to_select: int = 8\n",
        "    fedprox_mu: float = 0.01\n",
        "    num_clusters: int = 3\n",
        "    cluster_update_freq: int = 8\n",
        "\n",
        "    # 半非同步/容錯聚合 (任務 4)\n",
        "    async_threshold: float = 0.3\n",
        "\n",
        "    # RL 訓練參數\n",
        "    local_episodes_per_round: int = 5\n",
        "    steps_per_episode: int = 500\n",
        "    batch_size: int = 128\n",
        "    gamma: float = 0.99\n",
        "    lr: float = 1e-4\n",
        "    target_update_freq: int = 15\n",
        "\n",
        "    # RL 探索參數\n",
        "    epsilon_start: float = 1.0\n",
        "    epsilon_decay: float = 0.9995\n",
        "    epsilon_min: float = 0.05\n",
        "\n",
        "    # 記憶體與回放\n",
        "    memory_capacity: int = 50000\n",
        "    replay_start_size: int = 1000\n",
        "    replay_frequency: int = 2\n",
        "    replay_batches_per_call: int = 2\n",
        "\n",
        "    # 離線 RL 偏差校正 (任務 2)\n",
        "    enable_cql: bool = False\n",
        "    cql_alpha: float = 5.0\n",
        "    cql_temperature: float = 1.0\n",
        "\n",
        "    # 差分隱私 (DP) 設定\n",
        "    enable_dp: bool = True\n",
        "    dp_target_epsilon: float = 8.0\n",
        "    dp_target_delta: float = 1e-5\n",
        "    dp_max_grad_norm: float = 1.0\n",
        "    dp_noise_multiplier: float = 0.5\n",
        "\n",
        "    # Adaptive Clipping (任務 3)\n",
        "    enable_adaptive_clipping: bool = False\n",
        "    adaptive_clipping_percentile: float = 0.75\n",
        "\n",
        "    # DP 重設機制\n",
        "    enable_dp_reset: bool = True\n",
        "    dp_reset_threshold_multiplier: float = 1.5\n",
        "\n",
        "    # 系統與異質性設定\n",
        "    enable_heterogeneity: bool = True\n",
        "    straggler_ratio: float = 0.1\n",
        "    dropout_ratio: float = 0.05\n",
        "    enable_compression: bool = True\n",
        "    compression_type: str = \"quantize_fp16\" # 保持此參數以兼容\n",
        "    use_pfl_finetune: bool = True\n",
        "    local_finetune_episodes: int = 15\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"後處理設定，進行動態檢查與配置。\"\"\"\n",
        "        # GPU 環境檢測\n",
        "        if self.device == \"cuda\" and torch.cuda.is_available():\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            print(f\"🚀 GPU 環境檢測到: {gpu_name}\")\n",
        "        else:\n",
        "            self.device = \"cpu\"\n",
        "            print(\"💻 使用 CPU 模式\")\n",
        "\n",
        "        # 模式特定設定\n",
        "        if self.mode == 'Centralized':\n",
        "            self.enable_dp = False\n",
        "            self.enable_heterogeneity = False\n",
        "            print(\"🔹 集中式訓練模式，已自動禁用 DP 和異質性模擬。\")\n",
        "\n",
        "        if self.mode == \"FedAvg\":\n",
        "            self.fedprox_mu = 0.0\n",
        "            print(\"🔹 FedAvg 模式，fedprox_mu 已設為 0。\")\n",
        "\n",
        "        if self.mode == \"CQL\":\n",
        "            self.enable_cql = True\n",
        "            print(\"🔹 CQL 模式，已啟用 Conservative Q-Learning。\")\n",
        "\n",
        "        # 顯示核心配置\n",
        "        print(f\"\\n--- 核心實驗配置 ---\")\n",
        "        print(f\"模式: {self.mode} | 客戶端數: {self.num_clients} (Non-IID, α={self.dirichlet_alpha})\")\n",
        "        print(f\"每輪參與: {self.num_clients_to_select} | 通信輪數: {self.comm_rounds}\")\n",
        "\n",
        "        if self.enable_dp and self.mode != 'Centralized':\n",
        "            print(f\"🛡️  差分隱私 (DP): 啟用\")\n",
        "            print(f\"   - 目標預算: ε={self.dp_target_epsilon}, δ={self.dp_target_delta}\")\n",
        "            print(f\"   - 噪聲乘數: {self.dp_noise_multiplier}\")\n",
        "            print(f\"   - 梯度裁剪: {'自適應' if self.enable_adaptive_clipping else f'固定({self.dp_max_grad_norm})'}\")\n",
        "            print(f\"   - 預算重設: {'啟用' if self.enable_dp_reset else '禁用'}\")\n",
        "        else:\n",
        "            print(f\"🛡️  差分隱私 (DP): 禁用\")\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\"將當前配置以 JSON 格式保存到輸出目錄。\"\"\"\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        path = os.path.join(self.output_dir, f'{self.experiment_name}_config.json')\n",
        "        # 將 dataclass 轉換為可序列化的字典\n",
        "        config_dict = asdict(self)\n",
        "        with open(path, 'w') as f:\n",
        "            json.dump(config_dict, f, indent=4)\n",
        "        print(f\"✅ 配置已保存至: {path}\")\n",
        "\n",
        "print(\"✅ Cell 2: TrainingConfig（專家修正版）定義完成。\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPCaXasOa6sn",
        "outputId": "684b4832-20a7-48bc-ef36-5a1013f44f6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 2: TrainingConfig（專家修正版）定義完成。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 3: 🧩 數據與環境準備（Non-IID 專家修正版）\n",
        "from typing import Dict # <--- 修正：加入此行匯入語句\n",
        "\n",
        "class DataManager:\n",
        "    \"\"\"\n",
        "    負責數據的讀取、預處理、以及 Non-IID 客戶端數據切分。\n",
        "    任務 1 的主要實作在此類別中。\n",
        "    \"\"\"\n",
        "    def __init__(self, data_path: str, config: 'TrainingConfig'):\n",
        "        \"\"\"\n",
        "        初始化 DataManager。\n",
        "\n",
        "        Args:\n",
        "            data_path (str): Parquet 數據文件的路徑。\n",
        "            config (TrainingConfig): 實驗配置對象。\n",
        "        \"\"\"\n",
        "        print(f\"\\n[DataManager] 正在從 {data_path} 讀取數據...\")\n",
        "        self.df_kpi = pd.read_parquet(data_path)\n",
        "        self.config = config\n",
        "        self.tput_col = None\n",
        "        self.lat_col = None\n",
        "        self._sanitize_column_names()\n",
        "        self._preflight_check()\n",
        "\n",
        "    def _sanitize_column_names(self):\n",
        "        \"\"\"清理 DataFrame 的欄位名稱，使其更易於使用。\"\"\"\n",
        "        sanitized_columns = [re.sub(r'[\\\\[\\\\]\\\\(\\\\)%\\\\s\\\\.-]+', '_', col.strip().lower()).strip('_')\n",
        "                           for col in self.df_kpi.columns]\n",
        "        self.df_kpi.columns = sanitized_columns\n",
        "\n",
        "    def _preflight_check(self):\n",
        "        \"\"\"\n",
        "        執行啟動前的數據預檢查，確保必要欄位存在。\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*20 + \" DataManager 啟動前預檢查 \" + \"=\"*20)\n",
        "        cols = self.df_kpi.columns.tolist()\n",
        "        tput_cand = ['throughput_dl_mbps', 'tx_brate_downlink_mbps']\n",
        "        lat_cand = ['buffer_occupancy_dl_bytes', 'dl_buffer_bytes']\n",
        "\n",
        "        self.tput_col = next((c for c in tput_cand if c in cols), None)\n",
        "        self.lat_col = next((c for c in lat_cand if c in cols), None)\n",
        "\n",
        "        print(f\"✅ 清理後的欄位列表 (共 {len(cols)} 個)\")\n",
        "        if not self.tput_col or not self.lat_col:\n",
        "            raise ValueError(\"預檢查失敗: 找不到必要的吞吐量或延遲數據欄位。\")\n",
        "\n",
        "        print(f\"   - 吞吐量欄位成功匹配: '{self.tput_col}'\")\n",
        "        print(f\"   - 延遲/緩衝區欄位成功匹配: '{self.lat_col}'\")\n",
        "        print(\"=\"*65 + \"\\n\")\n",
        "\n",
        "    def _get_merged_trajectory(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        將不同基站和切片的數據合併成一個統一的時間序列 DataFrame。\n",
        "        這是 Non-IID 切分的基礎。\n",
        "        \"\"\"\n",
        "        print(\"[DataManager] 正在合併 eMBB 和 URLLC 的數據軌跡...\")\n",
        "        available_bs = sorted(self.df_kpi['bs_id'].unique())\n",
        "        all_merged_dfs = []\n",
        "\n",
        "        # 我們需要一個參考BS來進行合併，這裡選擇第一個可用的BS\n",
        "        # 但實際上，我們應該將所有BS的數據都視為一個大的數據池\n",
        "        # 這裡我們簡化處理，將所有數據合併\n",
        "        df_embb = self.df_kpi[self.df_kpi['slice_id'] == 0]\n",
        "        df_urllc = self.df_kpi[self.df_kpi['slice_id'] == 2]\n",
        "\n",
        "        # 重命名以避免合併衝突\n",
        "        df_embb = df_embb[['timestamp', self.tput_col, self.lat_col]].rename(\n",
        "            columns={self.tput_col: 'throughput_embb', self.lat_col: 'latency_embb'}\n",
        "        ).dropna()\n",
        "        df_urllc = df_urllc[['timestamp', self.tput_col, self.lat_col]].rename(\n",
        "            columns={self.tput_col: 'throughput_urllc', self.lat_col: 'latency_urllc'}\n",
        "        ).dropna()\n",
        "\n",
        "        # 使用 merge_asof 將兩個切片的數據按時間對齊\n",
        "        merged_df = pd.merge_asof(\n",
        "            df_embb.sort_values('timestamp'),\n",
        "            df_urllc.sort_values('timestamp'),\n",
        "            on='timestamp',\n",
        "            direction='backward',\n",
        "            tolerance=pd.Timedelta('150ms') # 使用原始數據的容忍度\n",
        "        ).dropna()\n",
        "\n",
        "        # 數據清理\n",
        "        merged_df = merged_df[\n",
        "            (merged_df['throughput_embb'] >= 0) & (merged_df['throughput_urllc'] >= 0) &\n",
        "            (merged_df['latency_embb'] >= 0) & (merged_df['latency_urllc'] >= 0)\n",
        "        ]\n",
        "        print(f\"[DataManager] 全局數據軌跡合併完成，共 {len(merged_df)} 個時間步。\")\n",
        "        return merged_df.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "    def create_non_iid_partitions(self) -> Dict[int, np.ndarray]:\n",
        "        \"\"\"\n",
        "        (任務 1 核心實現)\n",
        "        使用 Dirichlet 分佈生成 Non-IID 的客戶端數據分區。\n",
        "\n",
        "        Returns:\n",
        "            一個字典，鍵是客戶端 ID，值是對應的數據軌跡 (numpy array)。\n",
        "        \"\"\"\n",
        "        print(f\"\\n[DataManager] 正在為 {self.config.num_clients} 個客戶端生成 Non-IID 數據分區...\")\n",
        "        print(f\"   - Dirichlet Alpha (α): {self.config.dirichlet_alpha}\")\n",
        "\n",
        "        # 1. 獲取合併後的全局數據\n",
        "        merged_df = self._get_merged_trajectory()\n",
        "        if merged_df.empty:\n",
        "            raise ValueError(\"合併後的全局數據為空，無法進行切分。\")\n",
        "\n",
        "        # 2. 使用 Dirichlet 分佈生成每個客戶端的數據比例\n",
        "        # np.random.seed(self.config.random_seed) # 確保切分可重現\n",
        "        proportions = np.random.dirichlet(np.repeat(self.config.dirichlet_alpha, self.config.num_clients))\n",
        "\n",
        "        # 3. 根據比例切分數據索引\n",
        "        total_samples = len(merged_df)\n",
        "        client_indices = {}\n",
        "        start_idx = 0\n",
        "        for i in range(self.config.num_clients):\n",
        "            num_samples = int(total_samples * proportions[i])\n",
        "            # 確保每個客戶端都有最少的數據量\n",
        "            if num_samples < self.config.min_samples_per_client:\n",
        "                # 如果分配的太少，則從其他地方\"借\"一些，這會稍微改變分佈，但在實務上可接受\n",
        "                num_samples = self.config.min_samples_per_client\n",
        "\n",
        "            end_idx = min(start_idx + num_samples, total_samples)\n",
        "            client_indices[i] = merged_df.index[start_idx:end_idx]\n",
        "            start_idx = end_idx\n",
        "            if start_idx >= total_samples:\n",
        "                break # 數據已全部分配完畢\n",
        "\n",
        "        # 如果因為 min_samples_per_client 的限制導致客戶端數量不足，需要調整\n",
        "        num_created_clients = len(client_indices)\n",
        "        if num_created_clients < self.config.num_clients:\n",
        "            print(f\"🟡 警告: 由於 min_samples_per_client 的限制，實際生成的客戶端數量為 {num_created_clients}\")\n",
        "            self.config.num_clients = num_created_clients # 更新配置以反映實際情況\n",
        "\n",
        "        # 4. 創建最終的軌跡字典\n",
        "        client_trajectories = {}\n",
        "        feature_cols = ['throughput_embb', 'latency_embb', 'throughput_urllc', 'latency_urllc']\n",
        "\n",
        "        for client_id, indices in tqdm(client_indices.items(), desc=\"創建客戶端軌跡\"):\n",
        "            client_df = merged_df.loc[indices]\n",
        "            trajectory = client_df[feature_cols].to_numpy(dtype=np.float32)\n",
        "            client_trajectories[client_id] = trajectory\n",
        "            print(f\"   - 客戶端 {client_id}: {len(trajectory)} 個時間步\")\n",
        "\n",
        "        num_valid = sum(1 for traj in client_trajectories.values() if traj.size > 0)\n",
        "        print(f\"\\n[DataManager] Non-IID 數據處理完成！成功為 {num_valid} / {self.config.num_clients} 個客戶端創建了環境。\")\n",
        "        return client_trajectories\n",
        "\n",
        "print(\"✅ Cell 3: DataManager（Non-IID 專家修正版）定義完成。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "4F6yYVmKa-hN",
        "outputId": "36e753c3-375b-4320-db78-d89483c21f8a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 3: DataManager（Non-IID 專家修正版）定義完成。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 4: ⚡ RL環境與數據處理（專家修正版）\n",
        "import gc\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import contextlib\n",
        "from collections import deque\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "class PairedEnv:\n",
        "    \"\"\"\n",
        "    配對服務 (eMBB/URLLC) 的強化學習環境。\n",
        "    代表單一客戶端的本地環境。\n",
        "    \"\"\"\n",
        "    def __init__(self, trajectory: np.ndarray, config: TrainingConfig):\n",
        "        \"\"\"\n",
        "        初始化環境。\n",
        "\n",
        "        Args:\n",
        "            trajectory (np.ndarray): 客戶端的數據軌跡，形狀為 (n_steps, 4)。\n",
        "            config (TrainingConfig): 實驗配置。\n",
        "        \"\"\"\n",
        "        self.trajectory = trajectory\n",
        "        self.config = config\n",
        "        # 狀態維度：[throughput_embb, latency_embb, throughput_urllc, latency_urllc]\n",
        "        self.state_size = trajectory.shape[1] if trajectory.size > 0 else 4\n",
        "        # 動作空間：[0: 偏重eMBB, 1: 平衡, 2: 偏重URLLC]\n",
        "        self.action_size = 3\n",
        "        self.cursor = 0\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        重置環境到一個新的起始點。\n",
        "\n",
        "        Returns:\n",
        "            初始狀態。\n",
        "        \"\"\"\n",
        "        if self.trajectory.size == 0:\n",
        "            return np.zeros(self.state_size, dtype=np.float32)\n",
        "\n",
        "        # 為了讓每個 episode 都是完整的，從軌跡的較早部分開始\n",
        "        max_start = max(0, len(self.trajectory) - self.config.steps_per_episode)\n",
        "        # 隨機選擇起始點以增加多樣性\n",
        "        if max_start > 0:\n",
        "            self.cursor = np.random.randint(0, max_start)\n",
        "        else:\n",
        "            self.cursor = 0\n",
        "        return self.trajectory[self.cursor]\n",
        "\n",
        "    def step(self, action_id: int) -> Tuple[np.ndarray, float, bool, dict]:\n",
        "        \"\"\"\n",
        "        在環境中執行一步。\n",
        "\n",
        "        Args:\n",
        "            action_id (int): 選擇的動作 ID。\n",
        "\n",
        "        Returns:\n",
        "            一個元組 (next_state, reward, done, info)。\n",
        "        \"\"\"\n",
        "        if self.trajectory.size == 0 or self.cursor >= len(self.trajectory) - 1:\n",
        "            # 如果軌跡結束或為空，返回終止狀態\n",
        "            state = self.trajectory[-1] if self.trajectory.size > 0 else np.zeros(self.state_size, dtype=np.float32)\n",
        "            return state, 0.0, True, {}\n",
        "\n",
        "        self.cursor += 1\n",
        "        done = self.cursor >= (len(self.trajectory) - 1)\n",
        "        state = self.trajectory[self.cursor]\n",
        "        reward = self._compute_reward(state, action_id)\n",
        "        return state, reward, done, {}\n",
        "\n",
        "    def _compute_reward(self, state: np.ndarray, action_id: int) -> float:\n",
        "        \"\"\"\n",
        "        根據當前狀態和動作計算獎勵。\n",
        "        獎勵函數旨在最大化吞吐量，同時最小化延遲懲罰。\n",
        "\n",
        "        Args:\n",
        "            state (np.ndarray): 當前狀態。\n",
        "            action_id (int): 執行的動作。\n",
        "\n",
        "        Returns:\n",
        "            計算出的獎勵值。\n",
        "        \"\"\"\n",
        "        tput_embb, lat_embb, tput_urllc, lat_urllc = state\n",
        "\n",
        "        # 根據動作 ID 調整權重\n",
        "        if action_id == 0:  # 偏重 eMBB\n",
        "            w_tput, w_lat = (0.7, 0.3)\n",
        "        elif action_id == 2:  # 偏重 URLLC\n",
        "            w_tput, w_lat = (0.3, 0.7)\n",
        "        else:  # 平衡\n",
        "            w_tput, w_lat = (0.5, 0.5)\n",
        "\n",
        "        # 使用 log1p 處理吞吐量，使其尺度更平滑\n",
        "        tput_reward = w_tput * (np.log1p(tput_embb) + 0.5 * np.log1p(tput_urllc))\n",
        "        # 使用 tanh 將延遲懲罰限制在 [-1, 1] 範圍內\n",
        "        lat_penalty = w_lat * (np.tanh(lat_urllc * 1e-6) + 0.3 * np.tanh(lat_embb * 1e-6))\n",
        "\n",
        "        reward_val = tput_reward - lat_penalty\n",
        "        # 處理潛在的 NaN 或 inf 值\n",
        "        return float(np.nan_to_num(reward_val, nan=0.0, posinf=10.0, neginf=-10.0))\n",
        "\n",
        "class RLDataset(Dataset):\n",
        "    \"\"\"用於強化學習經驗回放的 PyTorch 數據集。\"\"\"\n",
        "    def __init__(self, memory_deque: deque):\n",
        "        self.data = list(memory_deque)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        state, action, reward, next_state, done = self.data[idx]\n",
        "        return (\n",
        "            torch.from_numpy(state).float(),\n",
        "            torch.tensor(action).long(),\n",
        "            torch.tensor(reward).float(),\n",
        "            torch.from_numpy(next_state).float(),\n",
        "            torch.tensor(done).bool()\n",
        "        )\n",
        "\n",
        "def get_data_loader(agent_memory: deque, batch_size: int, device: str) -> DataLoader:\n",
        "    \"\"\"\n",
        "    創建一個用於 RL 訓練的數據加載器。\n",
        "    針對 GPU 進行了優化，例如使用 pin_memory。\n",
        "    \"\"\"\n",
        "    if len(agent_memory) < batch_size:\n",
        "        return None\n",
        "\n",
        "    dataset = RLDataset(agent_memory)\n",
        "    # 根據 CPU 核心數自動調整 num_workers\n",
        "    num_workers = min(os.cpu_count() // 2, 4) if torch.cuda.is_available() else 0\n",
        "\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=(device == 'cuda'),\n",
        "        drop_last=True,\n",
        "        persistent_workers= (num_workers > 0)\n",
        "    )\n",
        "\n",
        "def setup_gpu_environment():\n",
        "    \"\"\"統一的 GPU 環境設定函數。\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"\\n🎮 GPU 檢測: {gpu_name}\")\n",
        "        # 啟用 cudnn auto-tuner，這會尋找最優的卷積算法\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        # 允許 PyTorch 使用 TF32 來加速矩陣乘法（在 Ampere 架構及更新的 GPU 上）\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "        # 清理緩存\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(f\"🧹 GPU 環境已設定並優化。\")\n",
        "    else:\n",
        "        print(\"⚠️ 未檢測到 GPU，將使用 CPU 模式運行。\")\n",
        "\n",
        "\n",
        "print(\"✅ Cell 4: RL環境與數據處理（專家修正版）定義完成。\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgzjWl9gbAcl",
        "outputId": "ae66ddfa-fef2-4ec4-85ff-0d94360902c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 4: RL環境與數據處理（專家修正版）定義完成。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 5: 🛡️ 核心學習代理（CQL & Adaptive Clipping 專家修正版）\n",
        "import gc\n",
        "import time\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "from opacus.accountants.utils import get_noise_multiplier\n",
        "\n",
        "class AdaptiveClipper:\n",
        "    \"\"\"\n",
        "    (任務 3 核心類別)\n",
        "    一個輔助類，用於追踪梯度範數並建議自適應的裁剪值。\n",
        "    \"\"\"\n",
        "    def __init__(self, percentile: float, window_size: int = 100):\n",
        "        \"\"\"\n",
        "        初始化自適應裁剪器。\n",
        "\n",
        "        Args:\n",
        "            percentile (float): 用於確定裁剪值的梯度範數百分位數。\n",
        "            window_size (int): 用於計算百分位數的移動窗口大小。\n",
        "        \"\"\"\n",
        "        self.percentile = percentile\n",
        "        self.grad_norm_history = deque(maxlen=window_size)\n",
        "        self.suggested_clip_norm = 1.0  # 初始預設值\n",
        "\n",
        "    def track_grad_norm(self, model: nn.Module):\n",
        "        \"\"\"\n",
        "        計算並追踪模型參數的梯度總範數。\n",
        "\n",
        "        Args:\n",
        "            model (nn.Module): 正在訓練的模型。\n",
        "        \"\"\"\n",
        "        total_norm = 0.0\n",
        "        # Opacus 包裝的模型，參數在 _module 中\n",
        "        params = model._module.parameters() if hasattr(model, '_module') else model.parameters()\n",
        "        for p in params:\n",
        "            if p.grad is not None:\n",
        "                param_norm = p.grad.data.norm(2)\n",
        "                total_norm += param_norm.item() ** 2\n",
        "        total_norm = total_norm ** 0.5\n",
        "        self.grad_norm_history.append(total_norm)\n",
        "\n",
        "    def update_clip_norm(self):\n",
        "        \"\"\"\n",
        "        根據歷史梯度範數更新建議的裁剪值。\n",
        "        \"\"\"\n",
        "        if len(self.grad_norm_history) > 20: # 需要足夠的數據點\n",
        "            self.suggested_clip_norm = float(np.percentile(list(self.grad_norm_history), self.percentile * 100))\n",
        "\n",
        "class RLAgent:\n",
        "    \"\"\"\n",
        "    強化學習代理，封裝了 DQN 模型、訓練邏輯和差分隱私。\n",
        "    \"\"\"\n",
        "    def __init__(self, state_size: int, action_size: int, config: TrainingConfig, client_id: int,\n",
        "                 dataset_size: int, is_eval_agent: bool = False):\n",
        "        self.state_size, self.action_size, self.config = state_size, action_size, config\n",
        "        self.client_id, self.dataset_size = client_id, dataset_size\n",
        "        self.device = torch.device(config.device)\n",
        "        self.mu = self.config.fedprox_mu\n",
        "        self.gamma, self.epsilon = config.gamma, config.epsilon_start\n",
        "        self.memory = deque(maxlen=config.memory_capacity)\n",
        "        self.global_params = None\n",
        "        self.is_eval_agent = is_eval_agent\n",
        "        self.privacy_engine = None\n",
        "        self.current_epsilon = 0.0\n",
        "\n",
        "        self.model = self._build_model()\n",
        "        self.target_model = self._build_model()\n",
        "        self.update_target_model()\n",
        "        self.target_model.eval()\n",
        "\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=config.lr)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        if self.config.enable_cql:\n",
        "            print(f\"[C-{self.client_id}] 🧠 CQL 模式啟用 (alpha={self.config.cql_alpha})\")\n",
        "\n",
        "        if self.config.enable_dp and not self.is_eval_agent and self.config.mode != 'Centralized':\n",
        "            self._initialize_dp_engine()\n",
        "\n",
        "    def _build_model(self) -> nn.Module:\n",
        "        \"\"\"建立 DQN 神經網路模型。\"\"\"\n",
        "        model = nn.Sequential(\n",
        "            nn.Linear(self.state_size, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 64), nn.ReLU(),\n",
        "            nn.Linear(64, self.action_size)\n",
        "        ).to(self.device)\n",
        "        # 如果啟用DP，預先修復模型以確保與Opacus兼容\n",
        "        if self.config.enable_dp and not ModuleValidator.is_valid(model):\n",
        "            model = ModuleValidator.fix(model)\n",
        "        return model\n",
        "\n",
        "    def _initialize_dp_engine(self):\n",
        "        \"\"\"初始化 Opacus 的差分隱私引擎。\"\"\"\n",
        "        print(f\"[C-{self.client_id}] 🛡️ 正在初始化差分隱私引擎...\")\n",
        "        try:\n",
        "            self.privacy_engine = PrivacyEngine(accountant=\"gdp\")\n",
        "            # 創建一個假的 DataLoader 來初始化 PrivacyEngine\n",
        "            dummy_dataset = RLDataset(deque([(\n",
        "                np.zeros(self.state_size, dtype=np.float32), 0, 0.0,\n",
        "                np.zeros(self.state_size, dtype=np.float32), False\n",
        "            )] * self.config.batch_size))\n",
        "            dummy_loader = DataLoader(dummy_dataset, batch_size=self.config.batch_size)\n",
        "\n",
        "            self.model, self.optimizer, _ = self.privacy_engine.make_private(\n",
        "                module=self.model,\n",
        "                optimizer=self.optimizer,\n",
        "                data_loader=dummy_loader, # 這個 loader 僅用於獲取 sample_rate\n",
        "                noise_multiplier=self.config.dp_noise_multiplier,\n",
        "                max_grad_norm=self.config.dp_max_grad_norm,\n",
        "                poisson_sampling=True\n",
        "            )\n",
        "            print(f\"   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\")\n",
        "        except Exception as e:\n",
        "            print(f\"   - ❌ 差分隱私初始化失敗: {e}。將在非隱私模式下運行。\")\n",
        "            self.privacy_engine = None\n",
        "            self.config.enable_dp = False\n",
        "\n",
        "    def act(self, state: np.ndarray) -> int:\n",
        "        \"\"\"根據當前狀態和 epsilon-greedy 策略選擇一個動作。\"\"\"\n",
        "        if not self.is_eval_agent and np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        with torch.no_grad():\n",
        "            state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
        "            q_values = self.model(state_tensor)\n",
        "        return q_values.argmax().item()\n",
        "\n",
        "    def remember(self, *args):\n",
        "        \"\"\"將一條經驗存入回放緩衝區。\"\"\"\n",
        "        self.memory.append(args)\n",
        "\n",
        "    def replay(self, num_batches: int, clipper: AdaptiveClipper = None) -> float:\n",
        "        \"\"\"\n",
        "        從記憶體中取樣並訓練模型。\n",
        "        (任務 2 和 3 的核心實現)\n",
        "        \"\"\"\n",
        "        if len(self.memory) < self.config.batch_size:\n",
        "            return 0.0\n",
        "\n",
        "        data_loader = get_data_loader(self.memory, self.config.batch_size, self.device)\n",
        "        if data_loader is None: return 0.0\n",
        "\n",
        "        total_loss, batches_processed = 0.0, 0\n",
        "        self.model.train()\n",
        "\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            if i >= num_batches: break\n",
        "\n",
        "            states, actions, rewards, next_states, dones = [item.to(self.device) for item in batch]\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # 計算 Q 值\n",
        "            current_q_all = self.model(states)\n",
        "            current_q = current_q_all.gather(1, actions.unsqueeze(1))\n",
        "\n",
        "            # 計算目標 Q 值 (Double DQN)\n",
        "            with torch.no_grad():\n",
        "                next_actions = self.model(next_states).argmax(dim=1, keepdim=True)\n",
        "                max_next_q = self.target_model(next_states).gather(1, next_actions)\n",
        "                target_q = rewards.unsqueeze(1) + (self.gamma * max_next_q * (~dones.unsqueeze(1)))\n",
        "\n",
        "            # 計算核心損失\n",
        "            loss = self.criterion(current_q, target_q)\n",
        "\n",
        "            # (任務 2) 添加 CQL 損失項\n",
        "            if self.config.enable_cql:\n",
        "                logsumexp_q = torch.logsumexp(current_q_all / self.config.cql_temperature, dim=1).mean()\n",
        "                cql_loss = self.config.cql_alpha * (logsumexp_q - current_q.mean())\n",
        "                loss += cql_loss\n",
        "\n",
        "            # (任務 3) FedProx 正則化項\n",
        "            if self.config.mode in ['FedProx', 'ClusteredFL'] and self.mu > 0 and self.global_params:\n",
        "                proximal_term = 0.0\n",
        "                model_params = self.model._module.parameters() if hasattr(self.model, '_module') else self.model.parameters()\n",
        "                for local_param, global_param in zip(model_params, self.global_params):\n",
        "                    proximal_term += torch.sum((local_param - global_param.to(self.device))**2)\n",
        "                loss += (self.mu / 2) * proximal_term\n",
        "\n",
        "            if not torch.isfinite(loss): continue\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # (任務 3) 在優化器步驟前更新自適應裁剪器\n",
        "            if clipper and self.config.enable_adaptive_clipping:\n",
        "                clipper.track_grad_norm(self.model)\n",
        "                clipper.update_clip_norm() # 這裡只更新建議值，實際值在引擎初始化時設定\n",
        "\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            batches_processed += 1\n",
        "\n",
        "        return total_loss / batches_processed if batches_processed > 0 else 0.0\n",
        "\n",
        "    def get_privacy_cost(self) -> float:\n",
        "        \"\"\"獲取當前的隱私成本 (epsilon)。\"\"\"\n",
        "        if not self.privacy_engine: return 0.0\n",
        "        try:\n",
        "            return self.privacy_engine.get_epsilon(delta=self.config.dp_target_delta)\n",
        "        except Exception as e:\n",
        "            # print(f\"Warning: Could not get epsilon: {e}\")\n",
        "            return self.current_epsilon # 返回上一次成功的值\n",
        "\n",
        "    def set_global_params(self, state_dict: dict):\n",
        "        \"\"\"設置用於 FedProx 計算的全局模型參數。\"\"\"\n",
        "        with torch.no_grad():\n",
        "            self.global_params = [p.clone().detach().cpu() for p in state_dict.values()]\n",
        "\n",
        "    def update_target_model(self):\n",
        "        \"\"\"將主模型的權重複製到目標模型。\"\"\"\n",
        "        self.target_model.load_state_dict(self.get_clean_state_dict())\n",
        "\n",
        "    def get_clean_state_dict(self) -> dict:\n",
        "        \"\"\"獲取模型的 state_dict，如果是 DP 模型，則從 _module 中提取。\"\"\"\n",
        "        return self.model._module.state_dict() if self.privacy_engine and hasattr(self.model, '_module') else self.model.state_dict()\n",
        "\n",
        "    def get_model_for_upload(self) -> dict:\n",
        "        \"\"\"準備要上傳到服務器的模型，可選壓縮。\"\"\"\n",
        "        state_dict = self.get_clean_state_dict()\n",
        "        if self.config.enable_compression:\n",
        "            return {k: v.cpu().half() for k, v in state_dict.items()}\n",
        "        return {k: v.cpu() for k, v in state_dict.items()}\n",
        "\n",
        "    def get_model_weights_flat(self) -> np.ndarray:\n",
        "        \"\"\"將模型權重展平為一個向量，用於聚類分析。\"\"\"\n",
        "        with torch.no_grad():\n",
        "            params = self.model._module.parameters() if self.privacy_engine and hasattr(self.model, '_module') else self.model.parameters()\n",
        "            return torch.cat([p.view(-1) for p in params]).cpu().numpy()\n",
        "\n",
        "print(\"✅ Cell 5: RLAgent（CQL & Adaptive Clipping 專家修正版）定義完成。\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9GxeCqObCNV",
        "outputId": "40446d16-6b65-48ea-ef94-a259008bf61a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 5: RLAgent（CQL & Adaptive Clipping 專家修正版）定義完成。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 6: 🌐 聯邦學習服務器類別（DP 格式修正版）\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import copy\n",
        "\n",
        "class FLServer:\n",
        "    \"\"\"\n",
        "    聯邦學習服務器，負責模型聚合、客戶端聚類和模型分發。\n",
        "    【錯誤修正】本版本特別處理了差分隱私模型（GradSampleModule）與\n",
        "    標準模型之間 state_dict 鍵名不匹配的問題。\n",
        "    \"\"\"\n",
        "    def __init__(self, config: TrainingConfig):\n",
        "        \"\"\"\n",
        "        初始化 FLServer。\n",
        "\n",
        "        Args:\n",
        "            config (TrainingConfig): 實驗配置。\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.num_clusters = config.num_clusters\n",
        "        self.client_to_cluster: Dict[int, int] = {}\n",
        "        self.cluster_models: Dict[int, Dict[str, torch.Tensor]] = {\n",
        "            i: None for i in range(config.num_clusters)\n",
        "        }\n",
        "        print(f\"[FLServer] 初始化完成 - 模式: {self.config.mode}, 聚類數: {self.num_clusters}\")\n",
        "\n",
        "    def _is_dp_model(self, model: torch.nn.Module) -> bool:\n",
        "        \"\"\"檢查模型是否為 Opacus 包裝的 GradSampleModule。\"\"\"\n",
        "        return \"GradSampleModule\" in str(type(model))\n",
        "\n",
        "    def _convert_state_dict_keys(self, state_dict: Dict, target_model_is_dp: bool) -> Dict:\n",
        "        \"\"\"\n",
        "        【關鍵修正】根據目標模型是否為 DP 模型，自動轉換 state_dict 的鍵。\n",
        "        \"\"\"\n",
        "        if not state_dict: return {}\n",
        "\n",
        "        source_keys_have_prefix = any(k.startswith('_module.') for k in state_dict.keys())\n",
        "\n",
        "        # 如果格式已經匹配，則無需轉換\n",
        "        if source_keys_have_prefix == target_model_is_dp:\n",
        "            return state_dict\n",
        "\n",
        "        new_dict = {}\n",
        "        if target_model_is_dp: # 需要添加前綴\n",
        "            for key, value in state_dict.items():\n",
        "                new_dict[f\"_module.{key}\"] = value\n",
        "        else: # 需要移除前綴\n",
        "            for key, value in state_dict.items():\n",
        "                if key.startswith('_module.'):\n",
        "                    new_dict[key[len(\"_module.\"):]] = value\n",
        "        return new_dict\n",
        "\n",
        "    def distribute_model(self, participating_agents: Dict[int, 'RLAgent'], global_model_state: Dict):\n",
        "        \"\"\"\n",
        "        將適當的模型（全局或聚類模型）分發給參與的客戶端。\n",
        "        【錯誤修正】分發前會自動校正 state_dict 的鍵。\n",
        "        \"\"\"\n",
        "        if not global_model_state:\n",
        "            print(\"[FLServer] ⚠️ 全局模型為空，跳過分發。\")\n",
        "            return\n",
        "\n",
        "        # 全局模型是乾淨的（沒有 _module. 前綴）\n",
        "        for client_id, agent in participating_agents.items():\n",
        "            model_to_send = global_model_state\n",
        "            if self.config.mode == 'ClusteredFL':\n",
        "                cluster_id = self.client_to_cluster.get(client_id, 0)\n",
        "                if self.cluster_models.get(cluster_id) is not None:\n",
        "                    model_to_send = self.cluster_models[cluster_id]\n",
        "\n",
        "            # 檢查目標客戶端模型是否為 DP 模型\n",
        "            agent_is_dp = self._is_dp_model(agent.model)\n",
        "\n",
        "            # 【關鍵修正】轉換 state_dict 以匹配目標模型\n",
        "            model_state_for_loading = self._convert_state_dict_keys(\n",
        "                model_to_send, target_model_is_dp=agent_is_dp\n",
        "            )\n",
        "\n",
        "            # 將模型權重轉到 agent 所在的 device\n",
        "            model_to_load = {k: v.to(agent.device).float() for k, v in model_state_for_loading.items()}\n",
        "\n",
        "            # 現在載入不會報錯了\n",
        "            agent.model.load_state_dict(model_to_load)\n",
        "\n",
        "            # 用於 FedProx 的全局參數應始終是乾淨的 state_dict\n",
        "            agent.set_global_params(model_to_send)\n",
        "\n",
        "    def aggregate_weighted(self, client_updates: List[Tuple[Dict, int]]) -> Dict:\n",
        "        \"\"\"\n",
        "        對客戶端上傳的模型更新進行加權平均聚合 (FedAvg)。\n",
        "        【錯誤修正】確保返回的聚合模型是\"乾淨\"的（沒有 _module. 前綴）。\n",
        "        \"\"\"\n",
        "        if not client_updates: return {}\n",
        "\n",
        "        total_samples = sum(num_samples for _, num_samples in client_updates if num_samples > 0)\n",
        "        if total_samples == 0: return self._convert_state_dict_keys(client_updates[0][0], target_model_is_dp=False)\n",
        "\n",
        "        # 以第一個乾淨的模型為基準初始化聚合模型\n",
        "        first_clean_model = self._convert_state_dict_keys(client_updates[0][0], target_model_is_dp=False)\n",
        "        aggregated_model = {k: torch.zeros_like(v) for k, v in first_clean_model.items()}\n",
        "\n",
        "        for model_state, num_samples in client_updates:\n",
        "            if num_samples == 0: continue\n",
        "\n",
        "            weight = num_samples / total_samples\n",
        "\n",
        "            # 將每個上傳的模型都轉換為乾淨的格式再進行聚合\n",
        "            clean_model_state = self._convert_state_dict_keys(model_state, target_model_is_dp=False)\n",
        "\n",
        "            for key in aggregated_model.keys():\n",
        "                if key in clean_model_state:\n",
        "                    aggregated_model[key] += weight * clean_model_state[key].to(aggregated_model[key].device)\n",
        "\n",
        "        return aggregated_model\n",
        "\n",
        "    def update_clusters(self, client_agents: Dict[int, 'RLAgent'], current_round: int):\n",
        "        \"\"\"\n",
        "        (ClusteredFL 模式) 使用 K-Means 根據客戶端模型權重對客戶端進行聚類。\n",
        "        \"\"\"\n",
        "        if len(client_agents) < self.num_clusters:\n",
        "            # print(\"[FLServer] 客戶端數量不足以進行有意義的聚類。\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n[FLServer] Round {current_round}: 正在更新客戶端聚類...\")\n",
        "        try:\n",
        "            client_features, client_ids = [], []\n",
        "            for cid, agent in client_agents.items():\n",
        "                weights = agent.get_model_weights_flat()\n",
        "                if weights is not None and len(weights) > 0:\n",
        "                    client_features.append(weights)\n",
        "                    client_ids.append(cid)\n",
        "\n",
        "            if len(client_features) < self.num_clusters:\n",
        "                print(\"[FLServer] 有效特徵數量不足以聚類。\")\n",
        "                return\n",
        "\n",
        "            features_array = StandardScaler().fit_transform(np.vstack(client_features))\n",
        "\n",
        "            kmeans = KMeans(n_clusters=self.num_clusters, random_state=self.config.random_seed, n_init=10)\n",
        "            cluster_labels = kmeans.fit_predict(features_array)\n",
        "\n",
        "            self.client_to_cluster = {cid: label for cid, label in zip(client_ids, cluster_labels)}\n",
        "\n",
        "            print(\"[FLServer] 聚類更新完成:\")\n",
        "            for i in range(self.num_clusters):\n",
        "                clients_in_cluster = [cid for cid, c_label in self.client_to_cluster.items() if c_label == i]\n",
        "                print(f\"  - 聚類 {i}: {clients_in_cluster}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[FLServer] ❌ 聚類更新失敗: {e}。將回退到隨機分配。\")\n",
        "            client_ids = list(client_agents.keys())\n",
        "            random.shuffle(client_ids)\n",
        "            for i, cid in enumerate(client_ids):\n",
        "                self.client_to_cluster[cid] = i % self.num_clusters\n",
        "\n",
        "print(\"✅ Cell 6: FLServer（DP 格式修正版）定義完成。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "LHswkw7IbEh0",
        "outputId": "80b0f40d-a197-4bb2-80f5-af5667dff57d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 6: FLServer（DP 格式修正版）定義完成。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 7: 🚀 ExperimentRunner（遞迴修正版）\n",
        "import scipy.stats as stats\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class ExperimentRunner:\n",
        "    \"\"\"\n",
        "    實驗執行器，負責協調整個聯邦學習流程，包括客戶端選擇、\n",
        "    本地訓練、模型聚合、評估和日誌記錄。\n",
        "    (任務 2, 4, 5, 6 的主要實現)\n",
        "    \"\"\"\n",
        "    def __init__(self, config: TrainingConfig, data_manager: DataManager):\n",
        "        self.config = config\n",
        "        self.data_manager = data_manager\n",
        "        self._set_seeds() # (任務 6)\n",
        "\n",
        "        # 數據與客戶端初始化\n",
        "        self.all_trajectories = self.data_manager.create_non_iid_partitions()\n",
        "        self.client_envs = {cid: PairedEnv(traj, config) for cid, traj in self.all_trajectories.items() if traj.size > 0}\n",
        "        if not self.client_envs:\n",
        "            raise ValueError(\"未能為任何客戶端創建有效的環境。\")\n",
        "\n",
        "        # 更新配置以匹配實際生成的客戶端數量\n",
        "        self.config.num_clients = len(self.client_envs)\n",
        "        self.config.num_clients_to_select = min(self.config.num_clients_to_select, self.config.num_clients)\n",
        "\n",
        "        # --- 【遞迴修正】調整執行順序 ---\n",
        "        # 1. 如果啟用，先執行預計算，更新 config\n",
        "        if self.config.enable_dp and self.config.enable_adaptive_clipping:\n",
        "            self._precompute_adaptive_grad_norm()\n",
        "\n",
        "        # 2. 使用更新後的 config 創建代理與服務器\n",
        "        self.server = FLServer(config)\n",
        "        self.client_agents = self._create_agents() # 現在這一步是安全的\n",
        "        self.global_model_state = self.client_agents[next(iter(self.client_agents))].get_clean_state_dict() if self.client_agents else {}\n",
        "\n",
        "        # 結果記錄\n",
        "        self.training_history = []\n",
        "        self.evaluation_results = []\n",
        "        self.privacy_costs = []\n",
        "        self.latency_logs = [] # (任務 5)\n",
        "\n",
        "        self.config.save()\n",
        "        print(\"\\n[ExperimentRunner] 初始化完成。\")\n",
        "\n",
        "    def _set_seeds(self):\n",
        "        \"\"\" (任務 6) 設置所有相關庫的隨機種子以確保可重現性。\"\"\"\n",
        "        seed = self.config.random_seed\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(seed)\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "            # 關鍵的確定性設定\n",
        "            torch.backends.cudnn.deterministic = True\n",
        "            torch.backends.cudnn.benchmark = False\n",
        "            # PyTorch 1.8+\n",
        "            try:\n",
        "                torch.use_deterministic_algorithms(True)\n",
        "                print(\"torch.use_deterministic_algorithms(True) 已設置\")\n",
        "            except (AttributeError, RuntimeError): # RuntimeError 可能在某些 CUDA 版本上發生\n",
        "                print(\"當前 PyTorch/CUDA 版本不完全支持或已啟用確定性演算法\")\n",
        "\n",
        "    def _create_agents(self) -> Dict[int, RLAgent]:\n",
        "        \"\"\"【遞迴修正】創建所有客戶端的 RL 代理。不再呼叫預計算函式。\"\"\"\n",
        "        print(\"\\n[ExperimentRunner] 正在初始化所有客戶端代理...\")\n",
        "        agents = {}\n",
        "        for cid, env in self.client_envs.items():\n",
        "            dataset_size = len(env.trajectory) if env.trajectory.size > 0 else 1\n",
        "            # 使用 self.config (可能已被預計算更新) 來創建代理\n",
        "            agents[cid] = RLAgent(env.state_size, env.action_size, self.config, cid, dataset_size)\n",
        "        return agents\n",
        "\n",
        "    def _precompute_adaptive_grad_norm(self):\n",
        "        \"\"\"\n",
        "        【遞迴修正】\n",
        "        在訓練前運行一個短暫的預熱階段來估算一個穩健的梯度裁剪範數。\n",
        "        此函式現在直接創建一個獨立的臨時代理，而不是呼叫 _create_agents()。\n",
        "        \"\"\"\n",
        "        print(\"\\n[Adaptive Clipper] 正在預計算梯度裁剪範數...\")\n",
        "        clipper = AdaptiveClipper(percentile=self.config.adaptive_clipping_percentile)\n",
        "\n",
        "        # --- 直接建立一個輕量級的臨時代理 ---\n",
        "        # 選擇一個有代表性的客戶端環境（例如數據量較多的）\n",
        "        temp_env = next(iter(self.client_envs.values()))\n",
        "        # 創建一個不啟用DP的臨時config來建立代理，避免不必要的開銷\n",
        "        temp_config = copy.deepcopy(self.config)\n",
        "        temp_config.enable_dp = False\n",
        "        temp_agent = RLAgent(temp_env.state_size, temp_env.action_size, temp_config, -1, 1)\n",
        "        # --- --------------------------- ---\n",
        "\n",
        "        state = temp_env.reset()\n",
        "\n",
        "        # 模擬一些初始步驟來收集梯度\n",
        "        print(\"   - 執行預熱步驟以收集梯度範數...\")\n",
        "        for _ in range(200): # 預熱步數\n",
        "            action = temp_agent.act(state)\n",
        "            next_state, reward, done, _ = temp_env.step(action)\n",
        "            temp_agent.remember(state, action, reward, next_state, done)\n",
        "            state = next_state if not done else temp_env.reset()\n",
        "            if len(temp_agent.memory) > self.config.batch_size:\n",
        "                temp_agent.replay(num_batches=1, clipper=clipper)\n",
        "\n",
        "        # 更新配置中的裁剪值\n",
        "        if clipper.suggested_clip_norm > 0:\n",
        "            new_clip_norm = round(clipper.suggested_clip_norm, 2)\n",
        "            print(f\"   - ✅ 預計算完成。建議的裁剪範數 ({self.config.adaptive_clipping_percentile*100:.0f} 百分位): {new_clip_norm}\")\n",
        "            # 直接修改 self.config 物件，此修改將在後續的 _create_agents 中生效\n",
        "            self.config.dp_max_grad_norm = new_clip_norm\n",
        "        else:\n",
        "            print(f\"   - ⚠️ 預計算未能找到有效的裁剪值，將使用預設值: {self.config.dp_max_grad_norm}\")\n",
        "\n",
        "        del temp_agent, temp_env, temp_config, clipper\n",
        "\n",
        "\n",
        "    def _run_federated_training(self):\n",
        "        \"\"\"運行主聯邦學習訓練循環。\"\"\"\n",
        "        print(f\"\\n[模式] 開始聯邦式訓練 ({self.config.mode})\")\n",
        "        progress_bar = tqdm(range(self.config.comm_rounds), desc=f\"{self.config.mode} Training\")\n",
        "\n",
        "        for comm_round in progress_bar:\n",
        "            round_start_time = time.time() # (任務 5)\n",
        "            # --- 1. 聚類更新 (如果適用) ---\n",
        "            if self.config.mode == 'ClusteredFL' and comm_round > 0 and comm_round % self.config.cluster_update_freq == 0:\n",
        "                self.server.update_clusters(self.client_agents, comm_round)\n",
        "\n",
        "            # --- 2. 客戶端選擇與異質性模擬 ---\n",
        "            available_ids = list(self.client_agents.keys())\n",
        "            num_to_select = min(self.config.num_clients_to_select, len(available_ids))\n",
        "            selected_ids = np.random.choice(available_ids, num_to_select, replace=False)\n",
        "\n",
        "            dropout_ids, straggler_ids = set(), set()\n",
        "            if self.config.enable_heterogeneity:\n",
        "                num_dropouts = int(self.config.dropout_ratio * num_to_select)\n",
        "                dropout_ids = set(np.random.choice(selected_ids, num_dropouts, replace=False))\n",
        "\n",
        "                remaining_ids = [cid for cid in selected_ids if cid not in dropout_ids]\n",
        "                num_stragglers = int(self.config.straggler_ratio * len(remaining_ids))\n",
        "                if num_stragglers > 0:\n",
        "                    straggler_ids = set(np.random.choice(remaining_ids, num_stragglers, replace=False))\n",
        "\n",
        "            participating_ids = [cid for cid in selected_ids if cid not in dropout_ids]\n",
        "            if not participating_ids:\n",
        "                print(f\"[Round {comm_round+1}] ⚠️ 所有選擇的客戶端均掉線，跳過本輪。\")\n",
        "                continue\n",
        "\n",
        "            # --- 3. 模型分發 ---\n",
        "            participating_agents = {cid: self.client_agents[cid] for cid in participating_ids}\n",
        "            self.server.distribute_model(participating_agents, self.global_model_state)\n",
        "\n",
        "            # --- 4. 本地訓練 ---\n",
        "            client_updates, round_losses, round_rewards, round_epsilons = [], [], [], []\n",
        "            for cid in participating_ids:\n",
        "                agent, env = self.client_agents[cid], self.client_envs[cid]\n",
        "                # 延遲者訓練的 episode 較少\n",
        "                episodes = self.config.local_episodes_per_round // 2 if cid in straggler_ids else self.config.local_episodes_per_round\n",
        "                loss, reward, privacy_cost = self._train_agent_locally(agent, env, episodes)\n",
        "\n",
        "                client_updates.append((agent.get_model_for_upload(), len(env.trajectory)))\n",
        "                round_losses.append(loss)\n",
        "                round_rewards.append(reward)\n",
        "                if self.config.enable_dp:\n",
        "                    # 更新每個 agent 的 epsilon 記錄\n",
        "                    agent.current_epsilon = privacy_cost\n",
        "                    round_epsilons.append(privacy_cost)\n",
        "\n",
        "            # --- 5. 容錯聚合 (任務 4) ---\n",
        "            num_successful = len(client_updates)\n",
        "            num_expected = len(selected_ids)\n",
        "            success_ratio = num_successful / num_expected if num_expected > 0 else 0\n",
        "\n",
        "            if success_ratio < (1 - self.config.async_threshold):\n",
        "                print(f\"\\n[Round {comm_round+1}] ⚠️ 容錯聚合觸發！成功客戶端比例 {success_ratio:.2f} 低於閾值。僅聚合 {num_successful} 個模型。\")\n",
        "\n",
        "            if not client_updates:\n",
        "                print(f\"[Round {comm_round+1}] ⚠️ 沒有客戶端回傳模型，跳過聚合。\")\n",
        "                continue\n",
        "\n",
        "            # --- 6. 模型聚合 ---\n",
        "            if self.config.mode == 'ClusteredFL':\n",
        "                # 按聚類進行聚合\n",
        "                client_updates_by_cluster = {i: [] for i in range(self.config.num_clusters)}\n",
        "                for i, (model_update, num_points) in enumerate(client_updates):\n",
        "                    cid = participating_ids[i]\n",
        "                    cluster_id = self.server.client_to_cluster.get(cid, 0)\n",
        "                    client_updates_by_cluster[cluster_id].append((model_update, num_points))\n",
        "\n",
        "                new_cluster_models = []\n",
        "                for cluster_id, updates in client_updates_by_cluster.items():\n",
        "                    if updates:\n",
        "                        updated_model = self.server.aggregate_weighted(updates)\n",
        "                        self.server.cluster_models[cluster_id] = updated_model\n",
        "                        new_cluster_models.append((updated_model, sum(n for _, n in updates)))\n",
        "\n",
        "                if new_cluster_models:\n",
        "                    self.global_model_state = self.server.aggregate_weighted(new_cluster_models)\n",
        "            else: # FedAvg, FedProx, CQL\n",
        "                self.global_model_state = self.server.aggregate_weighted(client_updates)\n",
        "\n",
        "            # --- 7. 日誌記錄 ---\n",
        "            round_wall_time = time.time() - round_start_time # (任務 5)\n",
        "            self.latency_logs.append(round_wall_time)\n",
        "            if round_wall_time > 1.0:\n",
        "                 print(f\"[Round {comm_round+1}] ⚠️ 近即時延遲警告: 本輪耗時 {round_wall_time:.2f} 秒 > 1 秒。\")\n",
        "\n",
        "            avg_loss = np.mean(round_losses) if round_losses else 0\n",
        "            avg_reward = np.mean(round_rewards) if round_rewards else 0\n",
        "            avg_epsilon = np.mean(round_epsilons) if round_epsilons else 0.0\n",
        "\n",
        "            self.training_history.append({'round': comm_round, 'avg_reward': avg_reward, 'avg_loss': avg_loss})\n",
        "            self.privacy_costs.append({'round': comm_round, 'epsilon': avg_epsilon})\n",
        "\n",
        "            progress_bar.set_postfix(reward=f\"{avg_reward:.2f}\", loss=f\"{avg_loss:.4f}\", eps=f\"{avg_epsilon:.3f}\")\n",
        "\n",
        "    def _train_agent_locally(self, agent: RLAgent, env: PairedEnv, episodes: int):\n",
        "        \"\"\"單個客戶端的本地訓練邏輯。\"\"\"\n",
        "        agent.model.train()\n",
        "        total_loss, total_reward, episode_count = 0.0, 0.0, 0\n",
        "        if episodes == 0: return 0.0, 0.0, 0.0\n",
        "\n",
        "        for ep in range(episodes):\n",
        "            state, episode_reward, done = env.reset(), 0.0, False\n",
        "            for step in range(self.config.steps_per_episode):\n",
        "                action = agent.act(state)\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                agent.remember(state, action, reward, next_state, done)\n",
        "                state = next_state\n",
        "                episode_reward += reward\n",
        "\n",
        "                if len(agent.memory) > self.config.replay_start_size and step % self.config.replay_frequency == 0:\n",
        "                    loss = agent.replay(num_batches=self.config.replay_batches_per_call)\n",
        "                    total_loss += loss\n",
        "\n",
        "                if done: break\n",
        "\n",
        "            total_reward += episode_reward\n",
        "            episode_count += 1\n",
        "            if (ep + 1) % self.config.target_update_freq == 0:\n",
        "                agent.update_target_model()\n",
        "\n",
        "        # 更新 Epsilon\n",
        "        if not agent.is_eval_agent and agent.epsilon > self.config.epsilon_min:\n",
        "            agent.epsilon *= self.config.epsilon_decay ** episodes\n",
        "\n",
        "        avg_loss = total_loss / (episodes * self.config.steps_per_episode / self.config.replay_frequency) if total_loss > 0 else 0\n",
        "        avg_reward = total_reward / episode_count if episode_count > 0 else 0\n",
        "        privacy_cost = agent.get_privacy_cost()\n",
        "        return avg_loss, avg_reward, privacy_cost\n",
        "\n",
        "    def _run_final_evaluation(self):\n",
        "        \"\"\"在所有客戶端上運行最終評估。\"\"\"\n",
        "        print(\"\\n[評估] 正在執行最終評估...\")\n",
        "        for cid, env in tqdm(self.client_envs.items(), desc=\"最終評估\"):\n",
        "            eval_row = {'client_id': cid}\n",
        "\n",
        "            base_model_state = self.global_model_state\n",
        "            # 在 ClusteredFL 中，個性化模型是聚類模型\n",
        "            if self.config.mode == 'ClusteredFL':\n",
        "                cluster_id = self.server.client_to_cluster.get(cid, 0)\n",
        "                personalized_model_state = self.server.cluster_models.get(cluster_id, base_model_state)\n",
        "            else:\n",
        "                personalized_model_state = base_model_state\n",
        "\n",
        "            eval_row['reward_global'] = self._evaluate_on_env(env, base_model_state)\n",
        "            eval_row['reward_personalized'] = self._evaluate_on_env(env, personalized_model_state)\n",
        "\n",
        "            if self.config.use_pfl_finetune:\n",
        "                eval_row['reward_pfl_finetuned'] = self._finetune_and_evaluate(env, personalized_model_state)\n",
        "            else:\n",
        "                eval_row['reward_pfl_finetuned'] = eval_row['reward_personalized']\n",
        "\n",
        "            self.evaluation_results.append(eval_row)\n",
        "\n",
        "    def _evaluate_on_env(self, env: PairedEnv, model_state: dict, num_episodes: int = 15) -> float:\n",
        "        \"\"\"在給定環境上評估特定模型。\"\"\"\n",
        "        if env.trajectory.size == 0 or not model_state: return 0.0\n",
        "\n",
        "        eval_config = copy.deepcopy(self.config); eval_config.enable_dp = False\n",
        "        eval_agent = RLAgent(env.state_size, env.action_size, eval_config, -1, 1, True)\n",
        "\n",
        "        model_to_load = {k: v.to(eval_agent.device).float() for k, v in model_state.items()}\n",
        "        eval_agent.model.load_state_dict(model_to_load)\n",
        "        eval_agent.model.eval()\n",
        "        eval_agent.epsilon = 0.0\n",
        "\n",
        "        total_reward = 0\n",
        "        for _ in range(num_episodes):\n",
        "            state, ep_reward, done = env.reset(), 0, False\n",
        "            for _ in range(self.config.steps_per_episode):\n",
        "                action = eval_agent.act(state)\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                ep_reward += reward\n",
        "                state = next_state\n",
        "                if done: break\n",
        "            total_reward += ep_reward\n",
        "        return total_reward / num_episodes\n",
        "\n",
        "    def _finetune_and_evaluate(self, env: PairedEnv, model_state: dict) -> float:\n",
        "        \"\"\"對模型進行個性化微調並評估。\"\"\"\n",
        "        if env.trajectory.size == 0 or not model_state: return 0.0\n",
        "\n",
        "        finetune_config = copy.deepcopy(self.config); finetune_config.enable_dp = False\n",
        "        finetune_agent = RLAgent(env.state_size, env.action_size, finetune_config, -1, 1, False)\n",
        "\n",
        "        model_to_load = {k: v.to(finetune_agent.device).float() for k, v in model_state.items()}\n",
        "        finetune_agent.model.load_state_dict(model_to_load)\n",
        "        finetune_agent.epsilon = 0.1 # 微調時使用少量探索\n",
        "\n",
        "        self._train_agent_locally(finetune_agent, env, episodes=self.config.local_finetune_episodes)\n",
        "\n",
        "        return self._evaluate_on_env(env, finetune_agent.get_clean_state_dict())\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"啟動並運行整個實驗流程。\"\"\"\n",
        "        print(f\"\\n{'='*20} 🏃‍♂️ 開始執行實驗: {self.config.experiment_name} ({self.config.mode}) {'='*20}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # 根據模式選擇訓練流程\n",
        "        # 目前所有模式都走 federated 流程，Centralized/Isolated 可作為未來擴展\n",
        "        if self.config.mode in ['FedAvg', 'FedProx', 'ClusteredFL', 'CQL']:\n",
        "             self._run_federated_training()\n",
        "        else:\n",
        "            raise ValueError(f\"未知的實驗模式: {self.config.mode}\")\n",
        "\n",
        "        self._run_final_evaluation()\n",
        "        total_time_minutes = (time.time() - start_time) / 60\n",
        "        print(f\"\\n✅ 實驗 {self.config.experiment_name} 完成！總耗時: {total_time_minutes:.2f} 分鐘\")\n",
        "\n",
        "        # --- 最終報告 ---\n",
        "        # (任務 5) 延遲報告\n",
        "        if self.latency_logs:\n",
        "            avg_latency = np.mean(self.latency_logs)\n",
        "            p95_latency = np.percentile(self.latency_logs, 95)\n",
        "            print(f\"⏱️  通信輪延遲報告: 平均 = {avg_latency:.3f} 秒, 95百分位 = {p95_latency:.3f} 秒\")\n",
        "\n",
        "        # (任務 2) 隱私與獎勵報告\n",
        "        if self.training_history and self.privacy_costs:\n",
        "            history_df = pd.DataFrame(self.training_history)\n",
        "            privacy_df = pd.DataFrame(self.privacy_costs)\n",
        "            privacy_df['cumulative_epsilon'] = privacy_df['epsilon'].cumsum()\n",
        "\n",
        "            reward_vs_epsilon_df = pd.merge(history_df, privacy_df, on='round')\n",
        "            reward_vs_epsilon_path = os.path.join(self.config.output_dir, f'{self.config.experiment_name}_reward_vs_epsilon.csv')\n",
        "            reward_vs_epsilon_df.to_csv(reward_vs_epsilon_path, index=False)\n",
        "            print(f\"💾 獎勵 vs. Epsilon 曲線數據已保存至: {reward_vs_epsilon_path}\")\n",
        "\n",
        "            final_epsilon = reward_vs_epsilon_df['cumulative_epsilon'].iloc[-1]\n",
        "            print(f\"🛡️  最終總隱私預算消耗: ε = {final_epsilon:.4f}\")\n",
        "\n",
        "        # 保存其他結果\n",
        "        pd.DataFrame(self.evaluation_results).to_csv(os.path.join(self.config.output_dir, f'{self.config.experiment_name}_evaluation_results.csv'), index=False)\n",
        "\n",
        "        return pd.DataFrame(self.evaluation_results), pd.DataFrame(self.training_history)\n",
        "\n",
        "\n",
        "print(\"✅ Cell 7: ExperimentRunner（專家修正版）定義完成。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "GMmwa9gOi3_B",
        "outputId": "67cfe6c7-9ac9-4bbc-852d-b5f2f7a53e93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 7: ExperimentRunner（專家修正版）定義完成。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8A: 🎬 實驗執行主函數（專家修正版）\n",
        "import time\n",
        "import gc\n",
        "from datetime import datetime\n",
        "\n",
        "def run_single_experiment(config_dict: dict, data_path: str):\n",
        "    \"\"\"\n",
        "    運行單次端到端的聯邦學習實驗。\n",
        "\n",
        "    Args:\n",
        "        config_dict (dict): 包含實驗參數的字典。\n",
        "        data_path (str): 數據文件的路徑。\n",
        "\n",
        "    Returns:\n",
        "        一個元組 (success, results)，其中 results 是一個包含關鍵指標的字典。\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    runner = None\n",
        "    results = {}\n",
        "\n",
        "    try:\n",
        "        # 1. 初始化配置和數據管理器\n",
        "        config = TrainingConfig(**config_dict)\n",
        "        print(f\"\\n{'='*20} 正在啟動實驗: {config.experiment_name} {'='*20}\")\n",
        "        data_manager = DataManager(data_path, config)\n",
        "\n",
        "        # 2. 創建實驗執行器 (內部會自動處理數據切分和代理創建)\n",
        "        runner = ExperimentRunner(config, data_manager)\n",
        "\n",
        "        # 3. 運行實驗\n",
        "        eval_res, _ = runner.run()\n",
        "\n",
        "        # 4. 收集結果\n",
        "        execution_time = (time.time() - start_time) / 60\n",
        "        results['execution_time'] = execution_time\n",
        "        print(f\"\\n⏱️ 實驗執行時間: {execution_time:.2f} 分鐘\")\n",
        "\n",
        "        if not eval_res.empty:\n",
        "            avg_rewards = {\n",
        "                'global': eval_res['reward_global'].mean(),\n",
        "                'personalized': eval_res['reward_personalized'].mean(),\n",
        "                'pfl': eval_res['reward_pfl_finetuned'].mean()\n",
        "            }\n",
        "            results['avg_rewards'] = avg_rewards\n",
        "            print(\"\\n✅ 實驗結果摘要:\")\n",
        "            print(f\"   - 平均全局獎勵: {avg_rewards['global']:.4f}\")\n",
        "            print(f\"   - 平均個性化獎勵: {avg_rewards['personalized']:.4f}\")\n",
        "            print(f\"   - 平均PFL微調獎勵: {avg_rewards['pfl']:.4f}\")\n",
        "\n",
        "        # 收集隱私成本\n",
        "        privacy_file = os.path.join(config.output_dir, f'{config.experiment_name}_reward_vs_epsilon.csv')\n",
        "        if os.path.exists(privacy_file):\n",
        "            privacy_df = pd.read_csv(privacy_file)\n",
        "            final_epsilon = privacy_df['cumulative_epsilon'].iloc[-1]\n",
        "            results['privacy_stats'] = {'consumed_epsilon': final_epsilon}\n",
        "            print(f\"   - 最終隱私消耗 ε: {final_epsilon:.4f}\")\n",
        "\n",
        "        return True, results\n",
        "\n",
        "    except Exception as e:\n",
        "        execution_time = (time.time() - start_time) / 60\n",
        "        print(f\"\\n❌ 實驗 '{config_dict.get('experiment_name')}' 失敗！ (耗時: {execution_time:.2f} 分鐘)\")\n",
        "        import traceback\n",
        "        print(f\"🔍 錯誤詳情: {e}\")\n",
        "        print(f\"📋 錯誤堆疊: {traceback.format_exc()}\")\n",
        "        return False, {'error': str(e)}\n",
        "\n",
        "    finally:\n",
        "        # 清理資源\n",
        "        del runner\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "print(\"✅ Cell 8A: 實驗執行主函數（專家修正版）已載入。\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-FLqX0zbIdb",
        "outputId": "eee9b949-26c9-4353-f900-54c1c5e32c18"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 8A: 實驗執行主函數（專家修正版）已載入。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8B: 🔧 環境設定與初始化（確定性修正版）\n",
        "import os\n",
        "import time\n",
        "\n",
        "# --- 【錯誤修正】 ---\n",
        "# (任務 6 的補強) 根據 PyTorch 錯誤提示，設定此環境變數以啟用 CuBLAS 的確定性演算法。\n",
        "# 這必須在任何 PyTorch/CUDA 操作之前完成。\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "# --- END 修正 ---\n",
        "\n",
        "# GPU環境設定\n",
        "setup_gpu_environment()\n",
        "\n",
        "# 環境路徑設定\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_WORK_DIR = \"/content/drive/MyDrive/FRL_Slicing_Sim\" # 使用新目錄\n",
        "    print(\"🔗 Google Drive 掛載成功\")\n",
        "except ImportError:\n",
        "    BASE_WORK_DIR = \"./FRL_Slicing_Sim\"\n",
        "    print(\"💻 本地環境模式\")\n",
        "\n",
        "# 確保路徑存在\n",
        "os.makedirs(BASE_WORK_DIR, exist_ok=True)\n",
        "# 注意: 確保您的 kpi_traces_final_robust0.parquet 文件位於 BASE_WORK_DIR 中\n",
        "DATA_PATH = os.path.join(BASE_WORK_DIR, \"kpi_traces_final_robust0.parquet\")\n",
        "BASE_OUTPUT_DIR = os.path.join(BASE_WORK_DIR, \"outputs_expert\")\n",
        "os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    print(f\"❌ 錯誤: 找不到數據文件！請將 'kpi_traces_final_robust0.parquet' 上傳到 '{BASE_WORK_DIR}'\")\n",
        "else:\n",
        "    print(f\"📁 數據路徑: {DATA_PATH}\")\n",
        "\n",
        "print(f\"📁 輸出目錄: {BASE_OUTPUT_DIR}\")\n",
        "\n",
        "# 實驗配置\n",
        "# 新增 CQL 作為對比\n",
        "MODES_TO_RUN = [\"ClusteredFL\", \"FedProx\", \"FedAvg\", \"CQL\"]\n",
        "SEEDS = [42] # 為節省時間，僅用一個種子\n",
        "\n",
        "print(f\"\\n🎯 實驗計劃:\")\n",
        "print(f\"   - 測試模式: {MODES_TO_RUN}\")\n",
        "print(f\"   - 隨機種子: {SEEDS}\")\n",
        "print(f\"   - 總實驗數: {len(MODES_TO_RUN) * len(SEEDS)}\")\n",
        "\n",
        "# 全局結果存儲\n",
        "master_results_log = []\n",
        "\n",
        "print(\"\\n✅ 環境設定完成，準備執行實驗。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "XV-f8JLAbKMS",
        "outputId": "c04c8e9e-60c3-4ec6-b54c-f882bcc4b88e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎮 GPU 檢測: Tesla T4\n",
            "🧹 GPU 環境已設定並優化。\n",
            "Mounted at /content/drive\n",
            "🔗 Google Drive 掛載成功\n",
            "📁 數據路徑: /content/drive/MyDrive/FRL_Slicing_Sim/kpi_traces_final_robust0.parquet\n",
            "📁 輸出目錄: /content/drive/MyDrive/FRL_Slicing_Sim/outputs_expert\n",
            "\n",
            "🎯 實驗計劃:\n",
            "   - 測試模式: ['ClusteredFL', 'FedProx', 'FedAvg', 'CQL']\n",
            "   - 隨機種子: [42]\n",
            "   - 總實驗數: 4\n",
            "\n",
            "✅ 環境設定完成，準備執行實驗。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8C: 🚀 實驗 1 - ClusteredFL（專家修正版）\n",
        "# 確保環境已準備就緒\n",
        "if 'BASE_OUTPUT_DIR' not in locals():\n",
        "    print(\"請先運行 Cell 8B 進行環境設定！\")\n",
        "else:\n",
        "    mode = \"ClusteredFL\"\n",
        "    for seed in SEEDS:\n",
        "        exp_name = f\"{mode}_expert_s{seed}\"\n",
        "        output_dir = os.path.join(BASE_OUTPUT_DIR, f\"seed_{seed}\", mode)\n",
        "\n",
        "        # ClusteredFL 專用配置\n",
        "        config = {\n",
        "            \"experiment_name\": exp_name,\n",
        "            \"output_dir\": output_dir,\n",
        "            \"mode\": mode,\n",
        "            \"random_seed\": seed,\n",
        "            \"comm_rounds\": 5, # 示例訓練輪數\n",
        "\n",
        "            \"num_clients\": 15,\n",
        "            \"dirichlet_alpha\": 0.4,\n",
        "            \"num_clients_to_select\": 8,\n",
        "\n",
        "            \"local_episodes_per_round\": 4,\n",
        "            \"batch_size\": 128,\n",
        "\n",
        "            # 模式特定參數\n",
        "            \"fedprox_mu\": 0.1, # 在 ClusteredFL 中也可用於懲罰與聚類中心的距離\n",
        "            \"num_clusters\": 3,\n",
        "            \"cluster_update_freq\": 3,\n",
        "\n",
        "            \"enable_dp\": True,\n",
        "            \"dp_target_epsilon\": 8.0,\n",
        "            \"dp_noise_multiplier\": 0.6,\n",
        "            \"dp_max_grad_norm\": 1.5, # 假設一個初始值，如果啟用自適應會被覆蓋\n",
        "            \"enable_adaptive_clipping\": True,\n",
        "            \"adaptive_clipping_percentile\": 0.8,\n",
        "\n",
        "            \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        }\n",
        "\n",
        "        # 執行實驗\n",
        "        success, result_info = run_single_experiment(config, DATA_PATH)\n",
        "\n",
        "        # 記錄結果\n",
        "        master_results_log.append({\n",
        "            'seed': seed, 'mode': mode, 'success': success, 'result_info': result_info\n",
        "        })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d4e62175267b4b0d9f823ed94693fb6b",
            "4eae03b77833490c901481782ada898c",
            "d12be659f2dd43198d43b879434ee8d7",
            "6ebcb5e03a8d4d35b1388dad65f3a62e",
            "926879cf15a7449485f67b4c8b5af75d",
            "05ac3b5efef344548d590367e90b77d3",
            "2ad37512e9c04ef8b4df55b8bb31c116",
            "62eeb1961b3c450f8bb98e973ea301bd",
            "1bae2a1144f749a18716174d3490edba",
            "27635c9a414b473aaf618309ccac42f8",
            "1d1bcc4ce3804e8c9da04843c4c0b057",
            "c4b8984c33384cf5a94326c18b4950a4",
            "e9bc722af3e24624911a4ad3187446ca",
            "c0cefb7c0a924650acd3263f35eab243",
            "8920d9e4c8bf48fd85f6951fd063038d",
            "939ec7c7559b41069189bd0b34855ff4",
            "01a6787e2ba74c828e0ecc6e6d3ee084",
            "54363bf8e7204c59bcb465a503a3d519",
            "80417484270e4fedbc5aacf357d34574",
            "5ea5e63c4f654e1b9ba7a630c94a9a32",
            "212d572aa4c449039faecc8d23ed08fd",
            "74b8cafd5303482493b357a610f2da0c"
          ]
        },
        "cellView": "form",
        "id": "hqcSUEPXbLWB",
        "outputId": "9fef76dc-5ecd-4ec5-9b71-fa691dffffd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 GPU 環境檢測到: Tesla T4\n",
            "\n",
            "--- 核心實驗配置 ---\n",
            "模式: ClusteredFL | 客戶端數: 15 (Non-IID, α=0.4)\n",
            "每輪參與: 8 | 通信輪數: 5\n",
            "🛡️  差分隱私 (DP): 啟用\n",
            "   - 目標預算: ε=8.0, δ=1e-05\n",
            "   - 噪聲乘數: 0.6\n",
            "   - 梯度裁剪: 自適應\n",
            "   - 預算重設: 啟用\n",
            "\n",
            "==================== 正在啟動實驗: ClusteredFL_expert_s42 ====================\n",
            "\n",
            "[DataManager] 正在從 /content/drive/MyDrive/FRL_Slicing_Sim/kpi_traces_final_robust0.parquet 讀取數據...\n",
            "\n",
            "==================== DataManager 啟動前預檢查 ====================\n",
            "✅ 清理後的欄位列表 (共 38 個)\n",
            "   - 吞吐量欄位成功匹配: 'throughput_dl_mbps'\n",
            "   - 延遲/緩衝區欄位成功匹配: 'buffer_occupancy_dl_bytes'\n",
            "=================================================================\n",
            "\n",
            "torch.use_deterministic_algorithms(True) 已設置\n",
            "\n",
            "[DataManager] 正在為 15 個客戶端生成 Non-IID 數據分區...\n",
            "   - Dirichlet Alpha (α): 0.4\n",
            "[DataManager] 正在合併 eMBB 和 URLLC 的數據軌跡...\n",
            "[DataManager] 全局數據軌跡合併完成，共 196183 個時間步。\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "創建客戶端軌跡:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4e62175267b4b0d9f823ed94693fb6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   - 客戶端 0: 3180 個時間步\n",
            "   - 客戶端 1: 18666 個時間步\n",
            "   - 客戶端 2: 500 個時間步\n",
            "   - 客戶端 3: 500 個時間步\n",
            "   - 客戶端 4: 10379 個時間步\n",
            "   - 客戶端 5: 500 個時間步\n",
            "   - 客戶端 6: 32423 個時間步\n",
            "   - 客戶端 7: 522 個時間步\n",
            "   - 客戶端 8: 1891 個時間步\n",
            "   - 客戶端 9: 4542 個時間步\n",
            "   - 客戶端 10: 1709 個時間步\n",
            "   - 客戶端 11: 5204 個時間步\n",
            "   - 客戶端 12: 660 個時間步\n",
            "   - 客戶端 13: 500 個時間步\n",
            "   - 客戶端 14: 115007 個時間步\n",
            "\n",
            "[DataManager] Non-IID 數據處理完成！成功為 15 / 15 個客戶端創建了環境。\n",
            "\n",
            "[Adaptive Clipper] 正在預計算梯度裁剪範數...\n",
            "   - 執行預熱步驟以收集梯度範數...\n",
            "   - ✅ 預計算完成。建議的裁剪範數 (80 百分位): 1661435.57\n",
            "[FLServer] 初始化完成 - 模式: ClusteredFL, 聚類數: 3\n",
            "\n",
            "[ExperimentRunner] 正在初始化所有客戶端代理...\n",
            "[C-0] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-1] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-2] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-3] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-4] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-5] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-6] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-7] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-8] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-9] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-10] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-11] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-12] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-13] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "[C-14] 🛡️ 正在初始化差分隱私引擎...\n",
            "   - ✅ 差分隱私引擎初始化成功 (GradSampleModule)\n",
            "✅ 配置已保存至: /content/drive/MyDrive/FRL_Slicing_Sim/outputs_expert/seed_42/ClusteredFL/ClusteredFL_expert_s42_config.json\n",
            "\n",
            "[ExperimentRunner] 初始化完成。\n",
            "\n",
            "==================== 🏃‍♂️ 開始執行實驗: ClusteredFL_expert_s42 (ClusteredFL) ====================\n",
            "\n",
            "[模式] 開始聯邦式訓練 (ClusteredFL)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ClusteredFL Training:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4b8984c33384cf5a94326c18b4950a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Round 1] ⚠️ 近即時延遲警告: 本輪耗時 1022.09 秒 > 1 秒。\n",
            "[Round 2] ⚠️ 近即時延遲警告: 本輪耗時 1984.96 秒 > 1 秒。\n",
            "[Round 3] ⚠️ 近即時延遲警告: 本輪耗時 2238.01 秒 > 1 秒。\n",
            "\n",
            "[FLServer] Round 3: 正在更新客戶端聚類...\n",
            "[FLServer] 聚類更新完成:\n",
            "  - 聚類 0: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14]\n",
            "  - 聚類 1: [13]\n",
            "  - 聚類 2: [6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8D: 🚀 實驗 2 - FedProx & FedAvg（專家修正版）\n",
        "if 'BASE_OUTPUT_DIR' not in locals():\n",
        "    print(\"請先運行 Cell 8B 進行環境設定！\")\n",
        "else:\n",
        "    for mode in [\"FedProx\", \"FedAvg\"]:\n",
        "        for seed in SEEDS:\n",
        "            exp_name = f\"{mode}_expert_s{seed}\"\n",
        "            output_dir = os.path.join(BASE_OUTPUT_DIR, f\"seed_{seed}\", mode)\n",
        "\n",
        "            config = {\n",
        "                \"experiment_name\": exp_name,\n",
        "                \"output_dir\": output_dir,\n",
        "                \"mode\": mode,\n",
        "                \"random_seed\": seed,\n",
        "                \"comm_rounds\": 5,\n",
        "\n",
        "                \"num_clients\": 15,\n",
        "                \"dirichlet_alpha\": 0.4,\n",
        "                \"num_clients_to_select\": 8,\n",
        "\n",
        "                \"local_episodes_per_round\": 4,\n",
        "                \"batch_size\": 128,\n",
        "\n",
        "                # FedProx 的 mu 值，在 FedAvg 模式下會被自動設為 0\n",
        "                \"fedprox_mu\": 0.1,\n",
        "\n",
        "                \"enable_dp\": True,\n",
        "                \"dp_target_epsilon\": 8.0,\n",
        "                \"dp_noise_multiplier\": 0.6,\n",
        "                \"dp_max_grad_norm\": 1.5,\n",
        "                \"enable_adaptive_clipping\": True,\n",
        "                \"adaptive_clipping_percentile\": 0.8,\n",
        "\n",
        "                \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            }\n",
        "\n",
        "            # 執行實驗\n",
        "            success, result_info = run_single_experiment(config, DATA_PATH)\n",
        "\n",
        "            # 記錄結果\n",
        "            master_results_log.append({\n",
        "                'seed': seed, 'mode': mode, 'success': success, 'result_info': result_info\n",
        "            })"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1ouEe1u-bMmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8E: 🚀 實驗 3 - CQL Baseline（專家修正版）\n",
        "if 'BASE_OUTPUT_DIR' not in locals():\n",
        "    print(\"請先運行 Cell 8B 進行環境設定！\")\n",
        "else:\n",
        "    mode = \"CQL\"\n",
        "    for seed in SEEDS:\n",
        "        exp_name = f\"{mode}_expert_s{seed}\"\n",
        "        output_dir = os.path.join(BASE_OUTPUT_DIR, f\"seed_{seed}\", mode)\n",
        "\n",
        "        config = {\n",
        "            \"experiment_name\": exp_name,\n",
        "            \"output_dir\": output_dir,\n",
        "            \"mode\": mode,\n",
        "            \"random_seed\": seed,\n",
        "            \"comm_rounds\": 5,\n",
        "\n",
        "            \"num_clients\": 15,\n",
        "            \"dirichlet_alpha\": 0.4,\n",
        "            \"num_clients_to_select\": 8,\n",
        "\n",
        "            \"local_episodes_per_round\": 4,\n",
        "            \"batch_size\": 128,\n",
        "\n",
        "            # CQL 特定參數\n",
        "            \"enable_cql\": True,\n",
        "            \"cql_alpha\": 7.5,\n",
        "            \"cql_temperature\": 1.0,\n",
        "\n",
        "            # CQL 是一種非聯邦的聚合方法，但我們這裡模擬在 FL 設定下的表現\n",
        "            # 因此 fedprox_mu 設為 0\n",
        "            \"fedprox_mu\": 0.0,\n",
        "\n",
        "            \"enable_dp\": True,\n",
        "            \"dp_target_epsilon\": 8.0,\n",
        "            \"dp_noise_multiplier\": 0.6,\n",
        "            \"dp_max_grad_norm\": 1.5,\n",
        "            \"enable_adaptive_clipping\": True,\n",
        "            \"adaptive_clipping_percentile\": 0.8,\n",
        "\n",
        "            \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        }\n",
        "\n",
        "        # 執行實驗\n",
        "        success, result_info = run_single_experiment(config, DATA_PATH)\n",
        "\n",
        "        # 記錄結果\n",
        "        master_results_log.append({\n",
        "            'seed': seed, 'mode': mode, 'success': success, 'result_info': result_info\n",
        "        })"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2x7606tsbN6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 8F: 📊 實驗總結（專家修正版）\n",
        "print(\"=\"*60)\n",
        "print(\"🎉 所有實驗執行完成！\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 統計成功率\n",
        "successful_experiments = sum(1 for r in master_results_log if r['success'])\n",
        "total_experiments = len(master_results_log)\n",
        "success_rate = (successful_experiments / total_experiments) * 100 if total_experiments > 0 else 0\n",
        "\n",
        "print(f\"\\n📊 實驗統計:\")\n",
        "print(f\"   - 總實驗數: {total_experiments}\")\n",
        "print(f\"   - 成功數: {successful_experiments}\")\n",
        "print(f\"   - 成功率: {success_rate:.1f}%\\n\")\n",
        "\n",
        "# 成功實驗的詳細統計\n",
        "summary_data = []\n",
        "for result in master_results_log:\n",
        "    if result['success']:\n",
        "        mode = result['mode']\n",
        "        info = result['result_info']\n",
        "        if info and 'avg_rewards' in info:\n",
        "            rewards = info['avg_rewards']\n",
        "            privacy = info.get('privacy_stats', {'consumed_epsilon': 0})\n",
        "\n",
        "            summary_data.append({\n",
        "                'Mode': mode,\n",
        "                'Global Reward': rewards.get('global', 0),\n",
        "                'Personalized Reward': rewards.get('personalized', 0),\n",
        "                'PFL Reward': rewards.get('pfl', 0),\n",
        "                'Epsilon': privacy.get('consumed_epsilon', 0),\n",
        "                'Time (min)': info.get('execution_time', 0)\n",
        "            })\n",
        "\n",
        "if summary_data:\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    summary_df = summary_df.round(4)\n",
        "\n",
        "    # 計算提升率和隱私效率\n",
        "    best_global_reward = summary_df.loc[summary_df['Mode'] != 'CQL', 'Global Reward'].max()\n",
        "    summary_df['PFL Improvement (%)'] = (summary_df['PFL Reward'] / summary_df['Global Reward'] - 1) * 100\n",
        "    summary_df['Privacy-Utility'] = summary_df['PFL Reward'] / summary_df['Epsilon'].replace(0, 1e-9)\n",
        "\n",
        "    summary_df = summary_df.round(2)\n",
        "\n",
        "    print(\"📈 成功實驗詳細結果:\")\n",
        "    print(summary_df.to_markdown(index=False))\n",
        "\n",
        "    # 比較不同方法\n",
        "    if len(summary_df) > 1:\n",
        "        best_pfl = summary_df.loc[summary_df['PFL Reward'].idxmax()]\n",
        "        best_privacy_utility = summary_df.loc[summary_df['Privacy-Utility'].idxmax()]\n",
        "\n",
        "        print(f\"\\n🏆 最佳表現:\")\n",
        "        print(f\"   - 最佳 PFL 獎勵: {best_pfl['Mode']} ({best_pfl['PFL Reward']:.4f})\")\n",
        "        print(f\"   - 最佳隱私效用權衡: {best_privacy_utility['Mode']} ({best_privacy_utility['Privacy-Utility']:.4f} Reward/ε)\")\n",
        "\n",
        "# 保存實驗總結\n",
        "summary_path = os.path.join(BASE_OUTPUT_DIR, \"experiment_summary.json\")\n",
        "with open(summary_path, 'w') as f:\n",
        "    # 創建一個可序列化的版本\n",
        "    serializable_log = []\n",
        "    for log in master_results_log:\n",
        "        new_log = log.copy()\n",
        "        if isinstance(new_log.get('result_info'), dict):\n",
        "             new_log['result_info'].pop('error', None) # 移除不可序列化的 Error 對象\n",
        "        serializable_log.append(new_log)\n",
        "    json.dump(serializable_log, f, indent=4)\n",
        "print(f\"\\n📄 實驗總結已保存至: {summary_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q3sFkjTjbPGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 9: 📊 結果視覺化（專家修正版）\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def load_all_expert_results(base_output_dir):\n",
        "    \"\"\"\n",
        "    從指定的輸出目錄加載所有專家實驗的 reward_vs_epsilon.csv 和 evaluation_results.csv 文件。\n",
        "    \"\"\"\n",
        "    all_evals, all_reward_vs_eps = [], []\n",
        "\n",
        "    if not os.path.exists(base_output_dir):\n",
        "        print(f\"❌ 結果目錄未找到: {base_output_dir}\")\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    eval_files = glob.glob(os.path.join(base_output_dir, '**', '*_evaluation_results.csv'), recursive=True)\n",
        "    reward_eps_files = glob.glob(os.path.join(base_output_dir, '**', '*_reward_vs_epsilon.csv'), recursive=True)\n",
        "\n",
        "    def extract_info_from_path(path):\n",
        "        parts = path.split(os.sep)\n",
        "        # 預期路徑結構: .../seed_XX/MODE/...\n",
        "        mode = parts[-2]\n",
        "        seed_str = [p for p in parts if p.startswith('seed_')][0]\n",
        "        seed = int(seed_str.split('_')[1])\n",
        "        return mode, seed\n",
        "\n",
        "    for f in eval_files:\n",
        "        try:\n",
        "            df = pd.read_csv(f)\n",
        "            mode, seed = extract_info_from_path(f)\n",
        "            df['mode'] = mode\n",
        "            df['seed'] = seed\n",
        "            all_evals.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"🟡 警告: 讀取評估文件失敗: {f}, {e}\")\n",
        "\n",
        "    for f in reward_eps_files:\n",
        "        try:\n",
        "            df = pd.read_csv(f)\n",
        "            mode, seed = extract_info_from_path(f)\n",
        "            df['mode'] = mode\n",
        "            df['seed'] = seed\n",
        "            all_reward_vs_eps.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"🟡 警告: 讀取獎勵文件失敗: {f}, {e}\")\n",
        "\n",
        "    return (pd.concat(all_evals, ignore_index=True) if all_evals else pd.DataFrame()), \\\n",
        "           (pd.concat(all_reward_vs_eps, ignore_index=True) if all_reward_vs_eps else pd.DataFrame())\n",
        "\n",
        "# --- 視覺化設定 ---\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
        "FIGURES_OUTPUT_DIR = os.path.join(BASE_OUTPUT_DIR, \"figures\")\n",
        "os.makedirs(FIGURES_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"🔍 正在從以下路徑加載結果: {BASE_OUTPUT_DIR}\")\n",
        "eval_df, reward_vs_eps_df = load_all_expert_results(BASE_OUTPUT_DIR)\n",
        "\n",
        "if eval_df.empty or reward_vs_eps_df.empty:\n",
        "    print(\"❌ 未找到任何結果文件，無法生成圖表。請確保 Cell 8 的實驗已成功完成。\")\n",
        "else:\n",
        "    mode_order = [\"FedAvg\", \"FedProx\", \"ClusteredFL\", \"CQL\"]\n",
        "    print(f\"✅ 成功加載了 {len(eval_df['seed'].unique())} 次運行的結果。\")\n",
        "    print(f\"📊 找到的模式: {sorted(eval_df['mode'].unique())}\")\n",
        "\n",
        "    # --- 圖 1: 訓練歷史（獎勵 vs. 通信輪） ---\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    sns.lineplot(data=reward_vs_eps_df, x='round', y='avg_reward', hue='mode',\n",
        "                 hue_order=[m for m in mode_order if m in reward_vs_eps_df['mode'].unique()],\n",
        "                 errorbar='sd', linewidth=2.5)\n",
        "    plt.title('Training Performance Comparison', fontsize=18, weight='bold')\n",
        "    plt.xlabel('Communication Round', fontsize=14)\n",
        "    plt.ylabel('Average Episodic Reward', fontsize=14)\n",
        "    plt.legend(title='Training Mode', fontsize=12)\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'expert_training_history.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # --- 圖 2: 最終性能比較 (PFL Reward) ---\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    sns.boxplot(data=eval_df, x='mode', y='reward_pfl_finetuned',\n",
        "                order=[m for m in mode_order if m in eval_df['mode'].unique()])\n",
        "    plt.title('Final Performance After PFL Fine-tuning', fontsize=18, weight='bold')\n",
        "    plt.xlabel('Experiment Mode', fontsize=14)\n",
        "    plt.ylabel('Final Reward Score', fontsize=14)\n",
        "    plt.xticks(rotation=10)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'expert_final_performance.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # --- 圖 3: 隱私-效用權衡曲線 ---\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    sns.lineplot(data=reward_vs_eps_df, x='cumulative_epsilon', y='avg_reward', hue='mode',\n",
        "                 hue_order=[m for m in mode_order if m in reward_vs_eps_df['mode'].unique()],\n",
        "                 errorbar='sd', linewidth=2.5, marker='o', markersize=5, markevery=1)\n",
        "    plt.title('Privacy-Utility Trade-off Curve', fontsize=18, weight='bold')\n",
        "    plt.xlabel('Cumulative Privacy Loss ε (Epsilon)', fontsize=14)\n",
        "    plt.ylabel('Average Episodic Reward', fontsize=14)\n",
        "    plt.legend(title='Training Mode')\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'expert_privacy_utility_tradeoff.png'), dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # --- 圖 4: 個性化效益分析 (以 ClusteredFL 為例) ---\n",
        "    if 'ClusteredFL' in eval_df['mode'].unique():\n",
        "        target_eval = eval_df[eval_df['mode'] == 'ClusteredFL']\n",
        "        target_melted = target_eval.melt(\n",
        "            id_vars=['client_id'],\n",
        "            value_vars=['reward_global', 'reward_personalized', 'reward_pfl_finetuned'],\n",
        "            var_name='Model Type', value_name='Average Reward'\n",
        "        ).replace({\n",
        "            'reward_global': 'Global', 'reward_personalized': 'Clustered', 'reward_pfl_finetuned': 'PFL-Finetuned'\n",
        "        })\n",
        "\n",
        "        plt.figure(figsize=(15, 7))\n",
        "        sns.barplot(data=target_melted, x='client_id', y='Average Reward', hue='Model Type', palette='viridis')\n",
        "        plt.title('Personalization Benefits in ClusteredFL', fontsize=16, weight='bold')\n",
        "        plt.xlabel('Client ID', fontsize=14)\n",
        "        plt.ylabel('Average Reward', fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'expert_personalization_benefit.png'), dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "print(f\"✅ Cell 9: 結果視覺化（專家修正版）已完成。\")\n",
        "print(f\"📁 所有圖表已保存至: {FIGURES_OUTPUT_DIR}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LVRV21G5bQeZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d4e62175267b4b0d9f823ed94693fb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eae03b77833490c901481782ada898c",
              "IPY_MODEL_d12be659f2dd43198d43b879434ee8d7",
              "IPY_MODEL_6ebcb5e03a8d4d35b1388dad65f3a62e"
            ],
            "layout": "IPY_MODEL_926879cf15a7449485f67b4c8b5af75d"
          }
        },
        "4eae03b77833490c901481782ada898c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ac3b5efef344548d590367e90b77d3",
            "placeholder": "​",
            "style": "IPY_MODEL_2ad37512e9c04ef8b4df55b8bb31c116",
            "value": "創建客戶端軌跡: 100%"
          }
        },
        "d12be659f2dd43198d43b879434ee8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62eeb1961b3c450f8bb98e973ea301bd",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bae2a1144f749a18716174d3490edba",
            "value": 15
          }
        },
        "6ebcb5e03a8d4d35b1388dad65f3a62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27635c9a414b473aaf618309ccac42f8",
            "placeholder": "​",
            "style": "IPY_MODEL_1d1bcc4ce3804e8c9da04843c4c0b057",
            "value": " 15/15 [00:00&lt;00:00, 328.84it/s]"
          }
        },
        "926879cf15a7449485f67b4c8b5af75d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ac3b5efef344548d590367e90b77d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ad37512e9c04ef8b4df55b8bb31c116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62eeb1961b3c450f8bb98e973ea301bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bae2a1144f749a18716174d3490edba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27635c9a414b473aaf618309ccac42f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1bcc4ce3804e8c9da04843c4c0b057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4b8984c33384cf5a94326c18b4950a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9bc722af3e24624911a4ad3187446ca",
              "IPY_MODEL_c0cefb7c0a924650acd3263f35eab243",
              "IPY_MODEL_8920d9e4c8bf48fd85f6951fd063038d"
            ],
            "layout": "IPY_MODEL_939ec7c7559b41069189bd0b34855ff4"
          }
        },
        "e9bc722af3e24624911a4ad3187446ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01a6787e2ba74c828e0ecc6e6d3ee084",
            "placeholder": "​",
            "style": "IPY_MODEL_54363bf8e7204c59bcb465a503a3d519",
            "value": "ClusteredFL Training:  60%"
          }
        },
        "c0cefb7c0a924650acd3263f35eab243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80417484270e4fedbc5aacf357d34574",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ea5e63c4f654e1b9ba7a630c94a9a32",
            "value": 3
          }
        },
        "8920d9e4c8bf48fd85f6951fd063038d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_212d572aa4c449039faecc8d23ed08fd",
            "placeholder": "​",
            "style": "IPY_MODEL_74b8cafd5303482493b357a610f2da0c",
            "value": " 3/5 [1:27:25&lt;1:02:50, 1885.08s/it, eps=0.000, loss=47339296.9048, reward=272.60]"
          }
        },
        "939ec7c7559b41069189bd0b34855ff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01a6787e2ba74c828e0ecc6e6d3ee084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54363bf8e7204c59bcb465a503a3d519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80417484270e4fedbc5aacf357d34574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ea5e63c4f654e1b9ba7a630c94a9a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "212d572aa4c449039faecc8d23ed08fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b8cafd5303482493b357a610f2da0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}