{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thc1006/flora-dp-federated-ColO-RAN/blob/main/0706_FLORA_DP_client_15_v1_0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWyXJ3F_H9G-",
        "outputId": "f0805dd0-6512-498e-fd55-a8be5763c510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Cell 1: 環境與函式庫準備就緒。\n",
            "PyTorch/Opacus 版本: 2.6.0+cu124 / 1.5.4\n",
            "CUDA 是否可用: True\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 1: 環境設定與函式庫匯入（修正版）\n",
        "!pip install --upgrade opacus -q\n",
        "\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np, pandas as pd, random, copy, json, os, time, warnings, math, re, contextlib\n",
        "from collections import deque\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from dataclasses import dataclass, asdict\n",
        "from sklearn.cluster import KMeans\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "from opacus.data_loader import DPDataLoader\n",
        "\n",
        "# --- 環境設定 ---\n",
        "try: torch._dynamo.disable()\n",
        "except Exception: pass\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", message=\".*overflow encountered.*\", category=RuntimeWarning)\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "print(\"✅ Cell 1: 環境與函式庫準備就緒。\")\n",
        "import opacus\n",
        "print(f\"PyTorch/Opacus 版本: {torch.__version__} / {opacus.__version__}\")\n",
        "print(f\"CUDA 是否可用: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp11BP-2IANH",
        "outputId": "a9d8aed3-a5d4-4861-ee84-cc60a5f8a667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 2: TrainingConfig（虛擬客戶端優化版）定義完成。\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 2: 🎓 實驗參數設定（虛擬客戶端優化版）\n",
        "from dataclasses import dataclass, field  # 【修正】添加 field 導入\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    experiment_name: str\n",
        "    output_dir: str\n",
        "    mode: str = \"ClusteredFL\"\n",
        "    random_seed: int = 42\n",
        "    comm_rounds: int = 20\n",
        "\n",
        "    # 【修改5】虛擬客戶端擴增配置\n",
        "    base_client_pairs: tuple = ((1, 2), (3, 7), (5, 6))  # 原始3對基站\n",
        "    virtual_expansion_factor: int = 3  # 每個基站組合生成3個虛擬客戶端\n",
        "    num_virtual_clients: int = 9       # 3×3 = 9個虛擬客戶端\n",
        "    num_real_clients: int = 3          # 原始真實客戶端\n",
        "    total_clients: int = 12            # 總計12個客戶端\n",
        "    num_clients: int = 12              # 實際參與的客戶端數量\n",
        "    num_clients_to_select: int = 8     # 每輪選擇參與的客戶端數量\n",
        "\n",
        "    # 虛擬客戶端生成參數\n",
        "    temporal_split_method: str = \"sliding_window\"  # 時間窗口分割\n",
        "    noise_injection_std: float = 0.03  # 添加差分隱私友好的噪聲\n",
        "    feature_augmentation: bool = True   # 特徵增強\n",
        "    cross_validation_split: bool = True # 交叉驗證分割\n",
        "\n",
        "    # 【修改4】放大本地批次與回合\n",
        "    local_episodes_per_round: int = 4  # 6 → 12\n",
        "    steps_per_episode: int = 500        # 300 → 600\n",
        "    batch_size: int = 256              # 64 → 256\n",
        "    gamma: float = 0.99\n",
        "\n",
        "    # 學習參數\n",
        "    lr: float = 1e-4\n",
        "    target_update_freq: int = 15\n",
        "\n",
        "    # RL 探索參數\n",
        "    epsilon_start: float = 1.0\n",
        "    epsilon_decay: float = 0.9995\n",
        "    epsilon_min: float = 0.05\n",
        "\n",
        "    # 記憶與回放（擴增以配合大批次）\n",
        "    memory_capacity: int = 50000       # 50000 → 100000\n",
        "    replay_start_size: int = 1000       # 1000 → 2000\n",
        "    replay_frequency: int = 2\n",
        "    replay_batches_per_call: int = 3    # 2 → 3\n",
        "\n",
        "    # 【修改6】調高FedProx正則化強度\n",
        "    fedprox_mu: float = 0.15           # 0.01 → 0.15\n",
        "    num_clusters: int = 3              # 配合客戶端數量調整\n",
        "    cluster_update_freq: int = 8       # 15 → 8，更頻繁更新\n",
        "\n",
        "    # 【修改1&4】差分隱私參數優化\n",
        "    enable_dp: bool = True\n",
        "    dp_target_epsilon: float = 8.0\n",
        "    dp_target_delta: float = 1e-5\n",
        "    dp_max_grad_norm: float = 1.0\n",
        "    dp_noise_multiplier: float = 0.5   # 0.7 → 0.5（配合大批次）\n",
        "    dp_sampling_probability: float = 0.1  # 0.05 → 0.1\n",
        "    dp_virtual_batch_size: int = 256   # 64 → 256\n",
        "    dp_microbatch_size: int = 1\n",
        "\n",
        "    # 【修改2】重設機制參數\n",
        "    dp_reset_threshold_multiplier: float = 1.5  # 超過1.5×target_epsilon時重設\n",
        "    enable_dp_reset: bool = True\n",
        "\n",
        "    # 功能開關\n",
        "    enable_heterogeneity: bool = True\n",
        "    enable_compression: bool = True\n",
        "\n",
        "    # 系統設定\n",
        "    straggler_ratio: float = 0.1\n",
        "    dropout_ratio: float = 0.05\n",
        "    compression_type: str = \"quantize_fp16\"\n",
        "    use_pfl_finetune: bool = True\n",
        "    local_finetune_episodes: int = 15\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    reset_to_random_start: bool = True\n",
        "\n",
        "    # 兼容性參數（保持向後兼容）\n",
        "    client_pairs: tuple = field(init=False)  # 將在 __post_init__ 中設定\n",
        "\n",
        "    def __post_init__(self):\n",
        "        # 動態生成客戶端配對（用於兼容性）\n",
        "        extended_client_pairs = []\n",
        "        for i in range(self.total_clients):\n",
        "            embb_id = i + 1\n",
        "            urllc_id = i + 2\n",
        "            extended_client_pairs.append((embb_id, urllc_id))\n",
        "        self.client_pairs = tuple(extended_client_pairs)\n",
        "\n",
        "        # GPU 環境檢測\n",
        "        if torch.cuda.is_available():\n",
        "            if \"L4\" in torch.cuda.get_device_name(0):\n",
        "                print(f\"🚀 L4 GPU檢測到，啟用大批次優化配置\")\n",
        "\n",
        "        # 差分隱私模式檢測\n",
        "        if self.mode == 'Centralized':\n",
        "            self.enable_dp = False\n",
        "\n",
        "        # 配置信息顯示\n",
        "        print(f\"🔄 虛擬客戶端配置:\")\n",
        "        print(f\"   - 真實基站對: {len(self.base_client_pairs)} ({self.base_client_pairs})\")\n",
        "        print(f\"   - 擴增因子: {self.virtual_expansion_factor}\")\n",
        "        print(f\"   - 總客戶端數: {self.total_clients} (真實: {self.num_real_clients}, 虛擬: {self.num_virtual_clients})\")\n",
        "        print(f\"   - 每輪參與: {self.num_clients_to_select}\")\n",
        "\n",
        "        if self.enable_dp and self.mode != 'Centralized':\n",
        "            print(f\"🛡️ 差分隱私已啟用（GDP/PRV Accountant + Poisson Sampling）\")\n",
        "            print(f\"   - 目標隱私預算: ε={self.dp_target_epsilon}\")\n",
        "            print(f\"   - 批次大小: {self.batch_size}\")\n",
        "            print(f\"   - 噪聲乘數: {self.dp_noise_multiplier}\")\n",
        "            print(f\"   - 重設機制: {'啟用' if self.enable_dp_reset else '禁用'}\")\n",
        "        else:\n",
        "            print(f\"🛡️ 差分隱私：禁用（模式: {self.mode}）\")\n",
        "\n",
        "    def save(self):\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        path = os.path.join(self.output_dir, f'{self.experiment_name}_config.json')\n",
        "        config_dict = {k: (list(v) if isinstance(v, tuple) else v) for k, v in self.__dict__.items()}\n",
        "        with open(path, 'w') as f:\n",
        "            json.dump(config_dict, f, indent=4)\n",
        "        print(f\"✅ 配置已保存至: {path}\")\n",
        "\n",
        "print(\"✅ Cell 2: TrainingConfig（虛擬客戶端優化版）定義完成。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PK6SehiIDD0",
        "outputId": "1828e8e7-2051-4136-95c5-a0a8fa291b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 3: DataManager（修正版）定義完成。\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 3: 🧩 數據與環境準備（修正版）\n",
        "class DataManager:\n",
        "    def __init__(self, data_path, client_pairs_config):\n",
        "        print(f\"\\n[DataManager] 正在從 {data_path} 讀取數據...\")\n",
        "        self.df_kpi = pd.read_parquet(data_path)\n",
        "        self.client_pairs_config = client_pairs_config\n",
        "        self._sanitize_column_names(); self._preflight_check()\n",
        "\n",
        "    def _sanitize_column_names(self):\n",
        "        sanitized_columns = [re.sub(r'[\\[\\]\\(\\)%\\s\\.-]+', '_', col.strip().lower()).strip('_')\n",
        "                           for col in self.df_kpi.columns]\n",
        "        self.df_kpi.columns = sanitized_columns\n",
        "\n",
        "    def _preflight_check(self):\n",
        "        print(\"\\n\" + \"=\"*20 + \" DataManager 啟動前預檢查 \" + \"=\"*20)\n",
        "        cols = self.df_kpi.columns.tolist()\n",
        "        tput_cand = ['throughput_dl_mbps', 'tx_brate_downlink_mbps']\n",
        "        lat_cand = ['buffer_occupancy_dl_bytes', 'dl_buffer_bytes']\n",
        "\n",
        "        self.tput_col = next((c for c in tput_cand if c in cols), None)\n",
        "        self.lat_col = next((c for c in lat_cand if c in cols), None)\n",
        "\n",
        "        print(f\"✅ 清理後的欄位列表 (共 {len(cols)} 個):\")\n",
        "        print(f\"   - 吞吐量欄位成功匹配: '{self.tput_col}'\" if self.tput_col\n",
        "              else \"   - 吞吐量欄位匹配失敗！\")\n",
        "        print(f\"   - 延遲/緩衝區欄位成功匹配: '{self.lat_col}'\" if self.lat_col\n",
        "              else \"   - 延遲/緩衝區欄位匹配失敗！\")\n",
        "\n",
        "        # 修正：檢查BS節點的實際可用性\n",
        "        available_bs = sorted(self.df_kpi['bs_id'].unique())\n",
        "        print(f\"   - 可用BS節點: {available_bs}\")\n",
        "\n",
        "        # 驗證客戶端配對的有效性\n",
        "        for i, (embb_bs, urllc_bs) in enumerate(self.client_pairs_config):\n",
        "            if embb_bs not in available_bs or urllc_bs not in available_bs:\n",
        "                raise ValueError(f\"客戶端 {i} 的BS配對 ({embb_bs}, {urllc_bs}) 中包含不存在的BS節點\")\n",
        "        print(\"   - 客戶端BS配對驗證通過\")\n",
        "        print(\"=\"*65 + \"\\n\")\n",
        "\n",
        "        if not (self.tput_col and self.lat_col):\n",
        "            raise ValueError(\"預檢查失敗: 找不到必要的數據欄位。\")\n",
        "\n",
        "    def _get_clean_df(self, gnb_id, slice_id):\n",
        "        \"\"\"修正版：增加更嚴格的數據過濾和驗證\"\"\"\n",
        "        df, bs_col, sl_col = self.df_kpi, 'bs_id', 'slice_id'\n",
        "\n",
        "        # 確保數據類型一致性\n",
        "        mask = (df[bs_col].astype(int) == int(gnb_id)) & (df[sl_col].astype(int) == int(slice_id))\n",
        "        subset = df.loc[mask, ['timestamp', self.tput_col, self.lat_col]].copy()\n",
        "\n",
        "        # 修正：更嚴格的數據清理\n",
        "        subset = subset.rename(columns={self.tput_col: 'throughput', self.lat_col: 'latency'})\n",
        "        subset = subset.dropna()\n",
        "\n",
        "        # 移除異常值（超出合理範圍的數據點）\n",
        "        if not subset.empty:\n",
        "            subset = subset[\n",
        "                (subset['throughput'] >= 0) & (subset['throughput'] <= 1000) &  # 吞吐量範圍\n",
        "                (subset['latency'] >= 0) & (subset['latency'] <= 1e9)  # 延遲範圍\n",
        "            ]\n",
        "\n",
        "        return subset\n",
        "\n",
        "    def get_client_trajectories(self):\n",
        "        \"\"\"修正版：確保客戶端數據完全獨立\"\"\"\n",
        "        client_trajectories = {}\n",
        "        print(\"[DataManager] 正在為每個客戶端生成數據軌跡...\")\n",
        "\n",
        "        for i, (embb_id, urllc_id) in enumerate(tqdm(self.client_pairs_config, desc=\"處理客戶端數據\")):\n",
        "            try:\n",
        "                # 確保每個客戶端使用不同的BS，維護數據獨立性\n",
        "                df_embb = self._get_clean_df(embb_id, 0)  # eMBB切片\n",
        "                df_urllc = self._get_clean_df(urllc_id, 2)  # URLLC切片\n",
        "\n",
        "                if df_embb.empty or df_urllc.empty:\n",
        "                    print(f\"🟡 警告: 客戶端 {i} (BS {embb_id}/{urllc_id}) 篩選後無有效數據。\")\n",
        "                    client_trajectories[i] = np.array([])\n",
        "                    continue\n",
        "\n",
        "                # 修正：使用更保守的時間容忍度，避免數據洩漏\n",
        "                merged_df = pd.merge_asof(\n",
        "                    df_embb.sort_values('timestamp'),\n",
        "                    df_urllc.sort_values('timestamp'),\n",
        "                    on='timestamp',\n",
        "                    direction='backward',  # 確保只使用過去的信息\n",
        "                    tolerance=pd.Timedelta('100ms'),  # 減少容忍度\n",
        "                    suffixes=('_embb', '_urllc')\n",
        "                ).dropna()\n",
        "\n",
        "                if merged_df.empty:\n",
        "                    print(f\"🟡 警告: 客戶端 {i} 合併後無有效數據。\")\n",
        "                    client_trajectories[i] = np.array([])\n",
        "                    continue\n",
        "\n",
        "                # 確保數據序列的時間順序性\n",
        "                merged_df = merged_df.sort_values('timestamp').reset_index(drop=True)\n",
        "                trajectory = merged_df[['throughput_embb', 'latency_embb',\n",
        "                                      'throughput_urllc', 'latency_urllc']].to_numpy(dtype=np.float32)\n",
        "\n",
        "                client_trajectories[i] = trajectory\n",
        "                print(f\"   - 客戶端 {i}: {len(trajectory)} 個時間步\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ 錯誤: 處理客戶端 {i} 時發生嚴重錯誤: {e}\")\n",
        "                client_trajectories[i] = np.array([])\n",
        "\n",
        "        num_valid = sum(1 for traj in client_trajectories.values() if traj.size > 0)\n",
        "        print(f\"\\n[DataManager] 數據處理完成！成功為 {num_valid} / {len(self.client_pairs_config)} 個客戶端創建了環境。\")\n",
        "        return client_trajectories\n",
        "\n",
        "print(\"✅ Cell 3: DataManager（修正版）定義完成。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GhzPgA9QILLk",
        "outputId": "a354ecbe-0072-4658-9bd2-9d969a56f0af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 4: RL環境與數據處理（修正 GPU 設備處理）定義完成。\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 4: ⚡ RL環境與數據處理（修正 GPU 設備處理）\n",
        "import gc\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import contextlib\n",
        "from collections import deque\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "class PairedEnv:\n",
        "    \"\"\"配對環境類別 - 保持不變但加入GPU優化標記\"\"\"\n",
        "    def __init__(self, trajectory, config: TrainingConfig):\n",
        "        self.trajectory, self.config = trajectory, config\n",
        "        self.state_size = trajectory.shape[1] if trajectory.size > 0 else 4\n",
        "        self.action_size = 3\n",
        "        self.cursor = 0\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        if self.trajectory.size == 0:\n",
        "            return np.zeros(self.state_size, dtype=np.float32)\n",
        "        max_start = max(0, len(self.trajectory) - self.config.steps_per_episode)\n",
        "        if self.config.reset_to_random_start and max_start > 0:\n",
        "            self.cursor = np.random.randint(0, max_start)\n",
        "        else:\n",
        "            self.cursor = 0\n",
        "        return self.trajectory[self.cursor]\n",
        "\n",
        "    def step(self, action_id: int):\n",
        "        if self.trajectory.size == 0 or self.cursor >= len(self.trajectory) - 1:\n",
        "            state = self.trajectory[-1] if self.trajectory.size > 0 else np.zeros(self.state_size, dtype=np.float32)\n",
        "            return state, 0.0, True, {}\n",
        "        self.cursor += 1\n",
        "        done = self.cursor >= len(self.trajectory) - 1\n",
        "        state = self.trajectory[self.cursor]\n",
        "        reward = self._compute_reward_with_action(state, action_id)\n",
        "        return state, reward, done, {}\n",
        "\n",
        "    def _compute_reward_with_action(self, state: np.ndarray, action_id: int) -> float:\n",
        "        tput_embb, lat_embb, tput_urllc, lat_urllc = state\n",
        "        if action_id == 0: w_tput, w_lat = (0.7, 0.3)\n",
        "        elif action_id == 2: w_tput, w_lat = (0.3, 0.7)\n",
        "        else: w_tput, w_lat = (0.5, 0.5)\n",
        "        tput_reward = w_tput * (np.log1p(tput_embb) + 0.5 * np.log1p(tput_urllc))\n",
        "        lat_penalty = w_lat * (np.tanh(lat_urllc * 1e-6) + 0.3 * np.tanh(lat_embb * 1e-6))\n",
        "        reward_val = tput_reward - lat_penalty\n",
        "        return float(np.nan_to_num(reward_val, nan=0.0, posinf=10.0, neginf=-10.0))\n",
        "\n",
        "class RLDataset(Dataset):\n",
        "    \"\"\"RL數據集類別 - GPU優化版本\"\"\"\n",
        "    def __init__(self, memory_list):\n",
        "        self.data = memory_list[:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        state, action, reward, next_state, done = self.data[idx]\n",
        "        return (\n",
        "            torch.from_numpy(state).float(),\n",
        "            torch.tensor(action).long(),\n",
        "            torch.tensor(reward).float(),\n",
        "            torch.from_numpy(next_state).float(),\n",
        "            torch.tensor(done).bool()\n",
        "        )\n",
        "\n",
        "def get_gpu_optimized_data_loader(agent_memory: deque, batch_size: int, device: str):\n",
        "    \"\"\"\n",
        "    🔥 GPU性能優化的數據加載器（修正設備處理）\n",
        "    \"\"\"\n",
        "    if len(agent_memory) < batch_size:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        dataset = RLDataset(list(agent_memory))\n",
        "\n",
        "        # 確定 worker 數量\n",
        "        cpu_count = os.cpu_count() or 4\n",
        "        if cpu_count <= 2:\n",
        "            num_workers = 0  # T4 通常只有 2 CPU，使用單線程\n",
        "        else:\n",
        "            num_workers = min(2, cpu_count // 2)\n",
        "\n",
        "        # DataLoader 配置\n",
        "        dataloader_kwargs = {\n",
        "            'dataset': dataset,\n",
        "            'batch_size': batch_size,\n",
        "            'shuffle': True,\n",
        "            'num_workers': num_workers,\n",
        "            'pin_memory': torch.cuda.is_available() and device == 'cuda',\n",
        "            'drop_last': True,\n",
        "        }\n",
        "\n",
        "        # 只在有 worker 時添加 persistent_workers\n",
        "        if num_workers > 0:\n",
        "            dataloader_kwargs['persistent_workers'] = True\n",
        "            dataloader_kwargs['prefetch_factor'] = 2\n",
        "\n",
        "        # 設定正確的 generator\n",
        "        if device == 'cuda' and torch.cuda.is_available():\n",
        "            # 為 CUDA 設備創建 generator\n",
        "            g = torch.Generator(device='cuda')\n",
        "            g.manual_seed(42)\n",
        "            dataloader_kwargs['generator'] = g\n",
        "\n",
        "        return DataLoader(**dataloader_kwargs)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"🚨 GPU優化DataLoader創建失敗: {e}\")\n",
        "        print(f\"   回退到基本設定...\")\n",
        "\n",
        "        try:\n",
        "            # 簡化設定，不使用 generator\n",
        "            return DataLoader(\n",
        "                dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True,\n",
        "                num_workers=0,\n",
        "                pin_memory=False,\n",
        "                drop_last=True\n",
        "            )\n",
        "        except Exception as e2:\n",
        "            print(f\"🚨 回退也失敗: {e2}\")\n",
        "            return None\n",
        "\n",
        "def setup_gpu_environment():\n",
        "    \"\"\"\n",
        "    🚀 統一的GPU環境設定函數\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        compute_capability = torch.cuda.get_device_properties(0).major\n",
        "        cpu_count = os.cpu_count() or 4\n",
        "\n",
        "        print(f\"🎮 GPU 檢測: {gpu_name}\")\n",
        "        print(f\"📊 總記憶體: {total_memory:.1f} GB\")\n",
        "        print(f\"🔧 計算能力: {compute_capability}.x\")\n",
        "        print(f\"💻 可用CPU數: {cpu_count}\")\n",
        "\n",
        "        # 設定 CUDA 配置\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        # 清理記憶體\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        print(f\"🧹 GPU環境設定完成\")\n",
        "    else:\n",
        "        print(\"⚠️ 未檢測到GPU，將使用CPU模式運行\")\n",
        "\n",
        "# 其他函數保持不變\n",
        "def create_gpu_scaler():\n",
        "    \"\"\"創建GPU混合精度縮放器\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return GradScaler()\n",
        "    return None\n",
        "\n",
        "def optimize_batch_processing(states, actions, rewards, next_states, dones, device):\n",
        "    \"\"\"批次處理優化函數\"\"\"\n",
        "    states_gpu = states.to(device, non_blocking=True)\n",
        "    actions_gpu = actions.to(device, non_blocking=True)\n",
        "    rewards_gpu = rewards.to(device, non_blocking=True)\n",
        "    next_states_gpu = next_states.to(device, non_blocking=True)\n",
        "    dones_gpu = dones.to(device, non_blocking=True)\n",
        "    return states_gpu, actions_gpu, rewards_gpu, next_states_gpu, dones_gpu\n",
        "\n",
        "print(\"✅ Cell 4: RL環境與數據處理（修正 GPU 設備處理）定義完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hJCSz0KING1",
        "outputId": "a85d7879-09e1-4ac1-895a-72e346945dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 5: RLAgent（完整版）定義完成。\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 5: 🛡️ 核心學習代理（完整版，包含GPU優化）\n",
        "import gc\n",
        "import time\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.validators import ModuleValidator\n",
        "\n",
        "class RLAgent:\n",
        "    def __init__(self, state_size: int, action_size: int, config: TrainingConfig, client_id: int,\n",
        "                 dataset_size: int, is_eval_agent: bool = False):\n",
        "        self.state_size, self.action_size, self.config = state_size, action_size, config\n",
        "        self.client_id, self.dataset_size = client_id, dataset_size\n",
        "        self.device = torch.device(config.device)\n",
        "        self.mu = self.config.fedprox_mu\n",
        "        self.gamma, self.epsilon = config.gamma, config.epsilon_start\n",
        "        self.memory = deque(maxlen=config.memory_capacity)\n",
        "        self.global_params = None\n",
        "        self.is_eval_agent = is_eval_agent\n",
        "        self.privacy_engine = None\n",
        "        self.dp_steps = 0\n",
        "        self.current_epsilon = 0.0\n",
        "        self.current_best_alpha = None\n",
        "        self.consecutive_errors = 0\n",
        "        self.max_consecutive_errors = 5\n",
        "\n",
        "        # 【增強錯誤處理】隱私計算失敗追蹤\n",
        "        self.privacy_calc_failures = 0\n",
        "        self.last_valid_epsilon = 0.0\n",
        "        self.dp_reset_count = 0\n",
        "        self.last_reset_round = -1\n",
        "        self.original_optimizer_class = optim.Adam\n",
        "\n",
        "        self.model = self._build_dp_model()\n",
        "        self.target_model = self._build_dp_model()\n",
        "        self.update_target_model()\n",
        "        self.target_model.eval()\n",
        "\n",
        "        self.optimizer = self.original_optimizer_class(self.model.parameters(), lr=config.lr)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        if self.config.enable_dp and not self.is_eval_agent and self.config.mode != 'Centralized':\n",
        "            self._initialize_dp_engine()\n",
        "        else:\n",
        "            print(f\"[C-{self.client_id}] 🛡️ 標準模式（無差分隱私）\")\n",
        "\n",
        "    def _build_dp_model(self):\n",
        "        model = nn.Sequential(\n",
        "            nn.Linear(self.state_size, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 64), nn.ReLU(),\n",
        "            nn.Linear(64, self.action_size)\n",
        "        ).to(self.device)\n",
        "        if self.config.enable_dp and not self.is_eval_agent:\n",
        "            if not ModuleValidator.is_valid(model):\n",
        "                model = ModuleValidator.fix(model)\n",
        "        return model\n",
        "\n",
        "    def _initialize_dp_engine(self):\n",
        "        \"\"\"【穩定性增強版】差分隱私引擎初始化\"\"\"\n",
        "        print(f\"[C-{self.client_id}] 🛡️ 初始化差分隱私引擎...\")\n",
        "\n",
        "        # 初始化失敗計數器\n",
        "        self.privacy_calc_failures = 0\n",
        "        self.last_valid_epsilon = 0.0\n",
        "\n",
        "        try:\n",
        "            # 清理舊引擎\n",
        "            if hasattr(self, 'privacy_engine') and self.privacy_engine is not None:\n",
        "                del self.privacy_engine\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "            # 重建模型和優化器\n",
        "            self.model = self._build_dp_model()\n",
        "            self.optimizer = self.original_optimizer_class(self.model.parameters(), lr=self.config.lr)\n",
        "\n",
        "            # 創建虛擬數據集\n",
        "            dummy_data = []\n",
        "            effective_dataset_size = max(self.dataset_size, self.config.batch_size * 10)\n",
        "\n",
        "            for _ in range(effective_dataset_size):\n",
        "                state = np.random.randn(self.state_size).astype(np.float32)\n",
        "                action = int(np.random.randint(0, 3))\n",
        "                reward = float(np.random.randn())\n",
        "                next_state = np.random.randn(self.state_size).astype(np.float32)\n",
        "                done = bool(np.random.choice([True, False]))\n",
        "                dummy_data.append((state, action, reward, next_state, done))\n",
        "\n",
        "            dummy_dataset = RLDataset(dummy_data)\n",
        "            dummy_loader = DataLoader(\n",
        "                dummy_dataset, batch_size=self.config.batch_size, num_workers=0, shuffle=True\n",
        "            )\n",
        "\n",
        "            # 【增強】多重 accountant 回退機制\n",
        "            accountant_options = [\n",
        "                (\"gdp\", \"GDP\"),\n",
        "                (\"prv\", \"PRV\"),\n",
        "                (\"rdp\", \"RDP\"),\n",
        "                (None, \"Default\")\n",
        "            ]\n",
        "\n",
        "            for accountant_type, type_name in accountant_options:\n",
        "                try:\n",
        "                    if accountant_type:\n",
        "                        self.privacy_engine = PrivacyEngine(accountant=accountant_type)\n",
        "                    else:\n",
        "                        self.privacy_engine = PrivacyEngine()\n",
        "\n",
        "                    print(f\"   - 嘗試 Accountant: {type_name}\")\n",
        "                    break\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"   - {type_name} Accountant 失敗: {e}\")\n",
        "                    continue\n",
        "\n",
        "            if not self.privacy_engine:\n",
        "                raise RuntimeError(\"所有 Accountant 類型都失敗\")\n",
        "\n",
        "            # 動態 sample_rate 計算\n",
        "            sample_rate = min(self.config.batch_size / len(dummy_data), 1.0)\n",
        "            print(f\"   - Sample Rate: {sample_rate:.6f}\")\n",
        "\n",
        "            self.model, self.optimizer, dummy_loader = self.privacy_engine.make_private(\n",
        "                module=self.model,\n",
        "                optimizer=self.optimizer,\n",
        "                data_loader=dummy_loader,\n",
        "                noise_multiplier=self.config.dp_noise_multiplier,\n",
        "                max_grad_norm=self.config.dp_max_grad_norm,\n",
        "                poisson_sampling=True\n",
        "            )\n",
        "\n",
        "            # 重設計數器\n",
        "            self.dp_steps = 0\n",
        "            self.current_epsilon = 0.0\n",
        "            self.current_best_alpha = None\n",
        "\n",
        "            print(f\"   - ✅ 差分隱私引擎初始化成功\")\n",
        "            print(f\"   - 噪聲乘數: {self.config.dp_noise_multiplier}\")\n",
        "            print(f\"   - 梯度裁剪: {self.config.dp_max_grad_norm}\")\n",
        "            print(f\"   - Poisson採樣: True\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   - ❌ 差分隱私初始化失敗: {e}\")\n",
        "            print(f\"   - 🔄 切換到非差分隱私模式\")\n",
        "            self.privacy_engine = None\n",
        "            self.privacy_calc_failures = 999  # 標記為永久失敗狀態\n",
        "\n",
        "    def reset_dp_engine(self, round_num: int):\n",
        "        \"\"\"【完全修正2】正確的DP引擎重設方法\"\"\"\n",
        "        if not self.config.enable_dp_reset or not self.privacy_engine:\n",
        "            return False\n",
        "\n",
        "        print(f\"[C-{self.client_id}] 🔄 重設差分隱私引擎（Round {round_num}）...\")\n",
        "        try:\n",
        "            # 記錄重設資訊\n",
        "            self.dp_reset_count += 1\n",
        "            self.last_reset_round = round_num\n",
        "            old_epsilon = self.current_epsilon\n",
        "\n",
        "            # 重新初始化整個engine\n",
        "            self._initialize_dp_engine()\n",
        "\n",
        "            print(f\"   - ✅ 重設完成（第{self.dp_reset_count}次）\")\n",
        "            print(f\"   - 舊ε: {old_epsilon:.4f} → 新ε: {self.current_epsilon:.4f}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"   - ❌ 重設失敗: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_privacy_cost(self):\n",
        "        \"\"\"【增強版】隱私成本計算，多重錯誤處理機制\"\"\"\n",
        "        if not self.privacy_engine:\n",
        "            return 0.0\n",
        "\n",
        "        # 如果之前計算失敗太多次，直接返回緩存值\n",
        "        if hasattr(self, 'privacy_calc_failures') and self.privacy_calc_failures > 10:\n",
        "            return getattr(self, 'last_valid_epsilon', 0.0)\n",
        "\n",
        "        try:\n",
        "            # 【方法1】嘗試標準 get_epsilon 調用\n",
        "            result = self.privacy_engine.get_epsilon(delta=self.config.dp_target_delta)\n",
        "\n",
        "            # 處理不同返回格式\n",
        "            if isinstance(result, tuple):\n",
        "                if len(result) == 2:\n",
        "                    epsilon, best_alpha = result\n",
        "                    self.current_best_alpha = best_alpha\n",
        "                else:\n",
        "                    epsilon = result[0]\n",
        "                    self.current_best_alpha = None\n",
        "            elif isinstance(result, (int, float)):\n",
        "                epsilon = result\n",
        "                self.current_best_alpha = None\n",
        "            else:\n",
        "                raise ValueError(f\"未知的epsilon返回格式: {type(result)}\")\n",
        "\n",
        "            # 驗證 epsilon 值有效性\n",
        "            if np.isinf(epsilon) or np.isnan(epsilon) or epsilon < 0:\n",
        "                raise ValueError(f\"無效epsilon值: {epsilon}\")\n",
        "\n",
        "            # 成功計算，重置失敗計數\n",
        "            if hasattr(self, 'privacy_calc_failures'):\n",
        "                self.privacy_calc_failures = 0\n",
        "\n",
        "            self.current_epsilon = float(epsilon)\n",
        "            self.last_valid_epsilon = self.current_epsilon  # 緩存有效值\n",
        "            return self.current_epsilon\n",
        "\n",
        "        except Exception as primary_error:\n",
        "            # 記錄失敗次數\n",
        "            if not hasattr(self, 'privacy_calc_failures'):\n",
        "                self.privacy_calc_failures = 0\n",
        "            self.privacy_calc_failures += 1\n",
        "\n",
        "            # 【方法2】嘗試使用替代計算方法\n",
        "            try:\n",
        "                # 使用步數估算隱私成本（粗略估計）\n",
        "                if hasattr(self, 'dp_steps') and self.dp_steps > 0:\n",
        "                    # 基於已執行步數的簡單估算\n",
        "                    estimated_epsilon = self.dp_steps * 0.01  # 每步消耗0.01 epsilon（保守估計）\n",
        "                    estimated_epsilon = min(estimated_epsilon, self.config.dp_target_epsilon)\n",
        "\n",
        "                    if self.privacy_calc_failures <= 3:  # 前幾次失敗時顯示詳細信息\n",
        "                        print(f\"[C-{self.client_id}] ⚠️ 隱私成本計算失敗: {primary_error}\")\n",
        "                        print(f\"   🔄 使用估算值: ε ≈ {estimated_epsilon:.4f} (基於 {self.dp_steps} 步)\")\n",
        "\n",
        "                    self.current_epsilon = estimated_epsilon\n",
        "                    return estimated_epsilon\n",
        "\n",
        "            except Exception as fallback_error:\n",
        "                if self.privacy_calc_failures <= 3:\n",
        "                    print(f\"[C-{self.client_id}] ⚠️ 備用隱私計算也失敗: {fallback_error}\")\n",
        "\n",
        "            # 【方法3】最終回退：使用緩存值或返回0\n",
        "            if hasattr(self, 'last_valid_epsilon'):\n",
        "                cached_value = self.last_valid_epsilon\n",
        "                if self.privacy_calc_failures <= 3:\n",
        "                    print(f\"[C-{self.client_id}] 🔄 使用緩存隱私值: ε = {cached_value:.4f}\")\n",
        "                return cached_value\n",
        "\n",
        "            # 完全失敗的情況\n",
        "            if self.privacy_calc_failures <= 3:  # 只在前幾次失敗時顯示\n",
        "                print(f\"[C-{self.client_id}] ⚠️ 隱私成本計算完全失敗: {primary_error}\")\n",
        "                print(f\"   🔄 返回 0.0，訓練繼續（失敗次數: {self.privacy_calc_failures}）\")\n",
        "            elif self.privacy_calc_failures == 11:  # 失敗次數過多時的一次性提醒\n",
        "                print(f\"[C-{self.client_id}] ⚠️ 隱私計算持續失敗，已切換至靜默模式\")\n",
        "\n",
        "            return 0.0\n",
        "\n",
        "    def get_privacy_detailed_info(self):\n",
        "        \"\"\"【新增】獲取詳細隱私資訊供日誌記錄\"\"\"\n",
        "        return {\n",
        "            'client_id': self.client_id,\n",
        "            'epsilon': self.current_epsilon,\n",
        "            'best_alpha': self.current_best_alpha,\n",
        "            'dp_steps': self.dp_steps,\n",
        "            'reset_count': self.dp_reset_count,\n",
        "            'last_reset_round': self.last_reset_round,\n",
        "            'calc_failures': getattr(self, 'privacy_calc_failures', 0),\n",
        "            'last_valid_epsilon': getattr(self, 'last_valid_epsilon', 0.0)\n",
        "        }\n",
        "\n",
        "    def replay(self, num_batches: int):\n",
        "        if len(self.memory) < self.config.batch_size:\n",
        "            return 0.0\n",
        "\n",
        "        data_loader = get_gpu_optimized_data_loader(\n",
        "            self.memory, self.config.batch_size, self.device\n",
        "        )\n",
        "        if data_loader is None:\n",
        "            return 0.0\n",
        "\n",
        "        total_loss, batches_processed = 0.0, 0\n",
        "        self.model.train()\n",
        "\n",
        "        try:\n",
        "            for i, batch in enumerate(data_loader):\n",
        "                if i >= num_batches:\n",
        "                    break\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                states, actions, rewards, next_states, dones = [item.to(self.device, non_blocking=True) for item in batch]\n",
        "\n",
        "                current_q = self.model(states).gather(1, actions.view(-1, 1))\n",
        "                with torch.no_grad():\n",
        "                    max_next_q = self.target_model(next_states).max(1)[0].unsqueeze(1)\n",
        "                    target_q = rewards.view(-1, 1) + (self.gamma * max_next_q * (~dones.view(-1, 1)))\n",
        "\n",
        "                loss = self.criterion(current_q, target_q)\n",
        "\n",
        "                # 【效能優化6】增強的FedProx正則化（μ=0.15）\n",
        "                if self.config.mode in ['FedProx', 'ClusteredFL'] and self.mu > 0 and self.global_params:\n",
        "                    proximal_term = 0.0\n",
        "                    model_params = self.model._module.parameters() if hasattr(self.model, '_module') else self.model.parameters()\n",
        "                    for local_param, global_param in zip(model_params, self.global_params):\n",
        "                        proximal_term += torch.sum((local_param - global_param.to(self.device))**2)\n",
        "                    loss += (self.mu / 2) * proximal_term\n",
        "\n",
        "                if not torch.isfinite(loss):\n",
        "                    continue\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                batches_processed += 1\n",
        "                if self.privacy_engine:\n",
        "                    self.dp_steps += 1\n",
        "\n",
        "            return total_loss / batches_processed if batches_processed > 0 else 0.0\n",
        "        except Exception as e:\n",
        "            print(f\"[C-{self.client_id}] 🚨 回放錯誤: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    # 其餘方法保持不變...\n",
        "    def remember(self, *args):\n",
        "        self.memory.append(args)\n",
        "\n",
        "    def set_global_params(self, state_dict):\n",
        "        with torch.no_grad():\n",
        "            self.global_params = [p.clone().detach().cpu() for p in state_dict.values()]\n",
        "\n",
        "    def act(self, state):\n",
        "        if not self.is_eval_agent and np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(torch.from_numpy(state).float().unsqueeze(0).to(self.device))\n",
        "        return q_values.argmax().item()\n",
        "\n",
        "    def get_clean_state_dict(self):\n",
        "        return self.model._module.state_dict() if self.privacy_engine and hasattr(self.model, '_module') else self.model.state_dict()\n",
        "\n",
        "    def update_target_model(self):\n",
        "        self.target_model.load_state_dict(self.get_clean_state_dict())\n",
        "\n",
        "    def get_model_weights_flat(self):\n",
        "        with torch.no_grad():\n",
        "            params = self.model._module.parameters() if self.privacy_engine and hasattr(self.model, '_module') else self.model.parameters()\n",
        "            return torch.cat([p.view(-1) for p in params]).cpu().numpy()\n",
        "\n",
        "    def get_model_for_upload(self):\n",
        "        state_dict = self.get_clean_state_dict()\n",
        "        return {k: v.half() for k, v in state_dict.items()} if self.config.enable_compression else state_dict\n",
        "\n",
        "print(\"✅ Cell 5: RLAgent（完整版）定義完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9WEQIAOrE2a",
        "outputId": "0912a0b5-f26e-466b-f3ce-a4ca300e9305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 5.5: FLServer 類別定義完成。\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 5.5: 🌐 聯邦學習服務器類別（FLServer）\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import copy\n",
        "\n",
        "class FLServer:\n",
        "    \"\"\"\n",
        "    聯邦學習服務器類別\n",
        "    負責模型聚合、客戶端聚類和模型分發\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: TrainingConfig):\n",
        "        self.config = config\n",
        "        self.num_clusters = config.num_clusters\n",
        "        self.client_to_cluster = {}\n",
        "        self.cluster_models = {}\n",
        "        self.aggregation_weights = {}\n",
        "\n",
        "        # 初始化聚類模型\n",
        "        for i in range(self.num_clusters):\n",
        "            self.cluster_models[i] = None\n",
        "\n",
        "        print(f\"[FLServer] 初始化完成 - 聚類數: {self.num_clusters}\")\n",
        "\n",
        "    def distribute_model(self, participating_agents: Dict, global_model_state: Dict):\n",
        "        \"\"\"\n",
        "        將模型分發給參與的客戶端\n",
        "        \"\"\"\n",
        "        for client_id, agent in participating_agents.items():\n",
        "            if self.config.mode == 'ClusteredFL':\n",
        "                # 聚類聯邦學習：使用對應聚類的模型\n",
        "                cluster_id = self.client_to_cluster.get(client_id, 0)\n",
        "                if cluster_id in self.cluster_models and self.cluster_models[cluster_id] is not None:\n",
        "                    model_to_send = self.cluster_models[cluster_id]\n",
        "                else:\n",
        "                    model_to_send = global_model_state\n",
        "            else:\n",
        "                # 其他模式：使用全域模型\n",
        "                model_to_send = global_model_state\n",
        "\n",
        "            # 處理壓縮模型\n",
        "            if self.config.enable_compression:\n",
        "                model_to_send = {k: v.float() if hasattr(v, 'float') else v\n",
        "                               for k, v in model_to_send.items()}\n",
        "\n",
        "            # 設置全域參數和載入模型\n",
        "            agent.set_global_params(model_to_send)\n",
        "            agent.model.load_state_dict(model_to_send)\n",
        "\n",
        "    def aggregate_weighted(self, client_updates: List[Tuple[Dict, int]]) -> Dict:\n",
        "        \"\"\"\n",
        "        加權聚合客戶端模型更新\n",
        "\n",
        "        Args:\n",
        "            client_updates: [(model_state_dict, num_samples), ...]\n",
        "\n",
        "        Returns:\n",
        "            aggregated_model_state: 聚合後的模型狀態\n",
        "        \"\"\"\n",
        "        if not client_updates:\n",
        "            return {}\n",
        "\n",
        "        # 計算總樣本數\n",
        "        total_samples = sum(num_samples for _, num_samples in client_updates)\n",
        "        if total_samples == 0:\n",
        "            return client_updates[0][0]  # 返回第一個模型\n",
        "\n",
        "        # 初始化聚合模型\n",
        "        aggregated_model = {}\n",
        "        first_model = client_updates[0][0]\n",
        "\n",
        "        for key in first_model.keys():\n",
        "            aggregated_model[key] = torch.zeros_like(first_model[key])\n",
        "\n",
        "        # 加權聚合\n",
        "        for model_state, num_samples in client_updates:\n",
        "            weight = num_samples / total_samples\n",
        "            for key in aggregated_model.keys():\n",
        "                if key in model_state:\n",
        "                    aggregated_model[key] += weight * model_state[key].to(aggregated_model[key].device)\n",
        "\n",
        "        return aggregated_model\n",
        "\n",
        "    def update_clusters(self, client_agents: Dict, current_round: int):\n",
        "        \"\"\"\n",
        "        更新客戶端聚類\n",
        "        \"\"\"\n",
        "        if len(client_agents) < self.num_clusters:\n",
        "            # 客戶端數量少於聚類數，簡單分配\n",
        "            for i, client_id in enumerate(client_agents.keys()):\n",
        "                self.client_to_cluster[client_id] = i % self.num_clusters\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # 提取客戶端模型特徵進行聚類\n",
        "            client_features = []\n",
        "            client_ids = []\n",
        "\n",
        "            for client_id, agent in client_agents.items():\n",
        "                # 獲取模型權重向量\n",
        "                weights = agent.get_model_weights_flat()\n",
        "                if weights is not None and len(weights) > 0:\n",
        "                    client_features.append(weights)\n",
        "                    client_ids.append(client_id)\n",
        "\n",
        "            if len(client_features) < self.num_clusters:\n",
        "                # 特徵不足，使用簡單分配\n",
        "                for i, client_id in enumerate(client_ids):\n",
        "                    self.client_to_cluster[client_id] = i % self.num_clusters\n",
        "                return\n",
        "\n",
        "            # 使用 K-means 進行聚類\n",
        "            client_features_array = np.vstack(client_features)\n",
        "\n",
        "            # 標準化特徵\n",
        "            from sklearn.preprocessing import StandardScaler\n",
        "            scaler = StandardScaler()\n",
        "            normalized_features = scaler.fit_transform(client_features_array)\n",
        "\n",
        "            # K-means 聚類\n",
        "            kmeans = KMeans(n_clusters=self.num_clusters, random_state=42, n_init=10)\n",
        "            cluster_labels = kmeans.fit_predict(normalized_features)\n",
        "\n",
        "            # 更新客戶端到聚類的映射\n",
        "            for client_id, cluster_label in zip(client_ids, cluster_labels):\n",
        "                self.client_to_cluster[client_id] = int(cluster_label)\n",
        "\n",
        "            print(f\"[FLServer] Round {current_round}: 聚類更新完成\")\n",
        "            for cluster_id in range(self.num_clusters):\n",
        "                clients_in_cluster = [cid for cid, cid_cluster in self.client_to_cluster.items()\n",
        "                                    if cid_cluster == cluster_id]\n",
        "                print(f\"  聚類 {cluster_id}: {clients_in_cluster}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[FLServer] 聚類更新失敗: {e}\")\n",
        "            # 回退到簡單分配\n",
        "            for i, client_id in enumerate(client_agents.keys()):\n",
        "                self.client_to_cluster[client_id] = i % self.num_clusters\n",
        "\n",
        "    def get_cluster_info(self) -> Dict:\n",
        "        \"\"\"\n",
        "        獲取聚類信息\n",
        "        \"\"\"\n",
        "        cluster_info = {}\n",
        "        for cluster_id in range(self.num_clusters):\n",
        "            clients_in_cluster = [cid for cid, cid_cluster in self.client_to_cluster.items()\n",
        "                                if cid_cluster == cluster_id]\n",
        "            cluster_info[cluster_id] = {\n",
        "                'clients': clients_in_cluster,\n",
        "                'size': len(clients_in_cluster),\n",
        "                'has_model': cluster_id in self.cluster_models and self.cluster_models[cluster_id] is not None\n",
        "            }\n",
        "        return cluster_info\n",
        "\n",
        "print(\"✅ Cell 5.5: FLServer 類別定義完成。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtMd7sQ5IOyr",
        "outputId": "ad106a46-bcb3-40bd-c032-507abc582009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 6: FLServer 類別定義完成（完整修正版 - DP格式轉換）。\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 6: 🌐 聯邦學習服務器類別（FLServer）- 完整修正版\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import copy\n",
        "\n",
        "class FLServer:\n",
        "    \"\"\"\n",
        "    聯邦學習服務器類別（完整修正版）\n",
        "    負責模型聚合、客戶端聚類和模型分發\n",
        "    特別處理差分隱私模型的 state_dict 格式轉換\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: TrainingConfig):\n",
        "        self.config = config\n",
        "        self.num_clusters = config.num_clusters\n",
        "        self.client_to_cluster = {}\n",
        "        self.cluster_models = {}\n",
        "        self.aggregation_weights = {}\n",
        "\n",
        "        # 初始化聚類模型\n",
        "        for i in range(self.num_clusters):\n",
        "            self.cluster_models[i] = None\n",
        "\n",
        "        print(f\"[FLServer] 初始化完成 - 聚類數: {self.num_clusters}\")\n",
        "\n",
        "    def _convert_state_dict_for_dp_model(self, state_dict: Dict, target_is_dp: bool) -> Dict:\n",
        "        \"\"\"\n",
        "        【關鍵修正】自動轉換state_dict格式以匹配DP/非DP模型\n",
        "\n",
        "        Args:\n",
        "            state_dict: 源模型的state_dict\n",
        "            target_is_dp: 目標模型是否為DP包裝模型（GradSampleModule）\n",
        "\n",
        "        Returns:\n",
        "            轉換後的state_dict\n",
        "        \"\"\"\n",
        "        if not state_dict:\n",
        "            return state_dict\n",
        "\n",
        "        converted_dict = {}\n",
        "\n",
        "        for key, value in state_dict.items():\n",
        "            if target_is_dp and not key.startswith('_module.'):\n",
        "                # 目標是DP模型，源是標準格式 → 添加_module前綴\n",
        "                new_key = f\"_module.{key}\"\n",
        "                converted_dict[new_key] = value\n",
        "            elif not target_is_dp and key.startswith('_module.'):\n",
        "                # 目標是標準模型，源是DP格式 → 移除_module前綴\n",
        "                new_key = key.replace('_module.', '')\n",
        "                converted_dict[new_key] = value\n",
        "            else:\n",
        "                # 格式已匹配，直接複製\n",
        "                converted_dict[key] = value\n",
        "\n",
        "        return converted_dict\n",
        "\n",
        "    def _is_dp_model(self, model) -> bool:\n",
        "        \"\"\"\n",
        "        檢測模型是否為差分隱私包裝模型\n",
        "        \"\"\"\n",
        "        # 方法1: 檢查是否有 _module 屬性\n",
        "        if hasattr(model, '_module'):\n",
        "            return True\n",
        "\n",
        "        # 方法2: 檢查 state_dict 的鍵名\n",
        "        try:\n",
        "            state_dict = model.state_dict()\n",
        "            return any(k.startswith('_module.') for k in state_dict.keys())\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def distribute_model(self, participating_agents: Dict, global_model_state: Dict):\n",
        "        \"\"\"\n",
        "        【完全修正版】將模型分發給參與的客戶端，自動處理DP模型格式轉換\n",
        "        \"\"\"\n",
        "        if not global_model_state:\n",
        "            print(f\"[FLServer] ⚠️ 全域模型狀態為空，跳過分發\")\n",
        "            return\n",
        "\n",
        "        # 統計和調試信息\n",
        "        total_clients = len(participating_agents)\n",
        "        successful_distributions = 0\n",
        "        failed_distributions = 0\n",
        "\n",
        "        for client_id, agent in participating_agents.items():\n",
        "            try:\n",
        "                # 選擇要分發的模型\n",
        "                if self.config.mode == 'ClusteredFL':\n",
        "                    # 聚類聯邦學習：使用對應聚類的模型\n",
        "                    cluster_id = self.client_to_cluster.get(client_id, 0)\n",
        "                    if cluster_id in self.cluster_models and self.cluster_models[cluster_id] is not None:\n",
        "                        model_to_send = self.cluster_models[cluster_id]\n",
        "                    else:\n",
        "                        model_to_send = global_model_state\n",
        "                else:\n",
        "                    # 其他模式：使用全域模型\n",
        "                    model_to_send = global_model_state\n",
        "\n",
        "                if not model_to_send:\n",
        "                    print(f\"[FLServer] ⚠️ 客戶端 {client_id}: 無可分發模型\")\n",
        "                    failed_distributions += 1\n",
        "                    continue\n",
        "\n",
        "                # 【關鍵修正】自動檢測客戶端模型類型並轉換格式\n",
        "                agent_is_dp = self._is_dp_model(agent.model)\n",
        "\n",
        "                # 自動轉換state_dict格式\n",
        "                converted_model = self._convert_state_dict_for_dp_model(\n",
        "                    model_to_send, target_is_dp=agent_is_dp\n",
        "                )\n",
        "\n",
        "                # 處理模型壓縮\n",
        "                if self.config.enable_compression:\n",
        "                    converted_model = {k: v.half() if hasattr(v, 'half') else v\n",
        "                                     for k, v in converted_model.items()}\n",
        "\n",
        "                # 設置全域參數（用於FedProx等算法）\n",
        "                try:\n",
        "                    agent.set_global_params(converted_model)\n",
        "                except Exception as e:\n",
        "                    print(f\"[FLServer] ⚠️ 客戶端 {client_id}: set_global_params失敗: {e}\")\n",
        "\n",
        "                # 載入模型狀態\n",
        "                agent.model.load_state_dict(converted_model, strict=True)\n",
        "                successful_distributions += 1\n",
        "\n",
        "                # 調試信息（只顯示第一個客戶端的詳細信息）\n",
        "                if client_id == list(participating_agents.keys())[0]:\n",
        "                    print(f\"[FLServer] 客戶端 {client_id}: 模型分發成功\")\n",
        "                    print(f\"  - DP模型: {agent_is_dp}\")\n",
        "                    print(f\"  - 原始鍵數: {len(model_to_send)}\")\n",
        "                    print(f\"  - 轉換後鍵數: {len(converted_model)}\")\n",
        "                    if model_to_send and converted_model:\n",
        "                        orig_sample_key = list(model_to_send.keys())[0]\n",
        "                        conv_sample_key = list(converted_model.keys())[0]\n",
        "                        print(f\"  - 鍵名範例: {orig_sample_key} → {conv_sample_key}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                failed_distributions += 1\n",
        "                print(f\"[FLServer] ❌ 客戶端 {client_id} 模型分發失敗: {e}\")\n",
        "                print(f\"  - 錯誤類型: {type(e).__name__}\")\n",
        "\n",
        "                # 【強化回退機制】嘗試多種載入方式\n",
        "                try:\n",
        "                    # 回退1: 使用非嚴格模式載入原始模型\n",
        "                    agent.model.load_state_dict(model_to_send, strict=False)\n",
        "                    successful_distributions += 1\n",
        "                    print(f\"  - 🔄 回退成功：非嚴格模式載入\")\n",
        "                except Exception as e2:\n",
        "                    try:\n",
        "                        # 回退2: 嘗試反向轉換\n",
        "                        agent_is_dp = self._is_dp_model(agent.model)\n",
        "                        alt_converted_model = self._convert_state_dict_for_dp_model(\n",
        "                            model_to_send, target_is_dp=not agent_is_dp\n",
        "                        )\n",
        "                        agent.model.load_state_dict(alt_converted_model, strict=False)\n",
        "                        successful_distributions += 1\n",
        "                        print(f\"  - 🔄 反向轉換回退成功\")\n",
        "                    except Exception as e3:\n",
        "                        print(f\"  - ❌ 所有回退方式都失敗: {e3}\")\n",
        "\n",
        "        # 分發統計\n",
        "        print(f\"[FLServer] 模型分發完成: 成功 {successful_distributions}/{total_clients}\")\n",
        "        if failed_distributions > 0:\n",
        "            print(f\"  - ⚠️ 失敗數量: {failed_distributions}\")\n",
        "\n",
        "    def aggregate_weighted(self, client_updates: List[Tuple[Dict, int]]) -> Dict:\n",
        "        \"\"\"\n",
        "        【修正版】加權聚合客戶端模型更新，確保返回標準格式\n",
        "        \"\"\"\n",
        "        if not client_updates:\n",
        "            return {}\n",
        "\n",
        "        # 計算總樣本數\n",
        "        total_samples = sum(num_samples for _, num_samples in client_updates)\n",
        "        if total_samples == 0:\n",
        "            return client_updates[0][0] if client_updates else {}\n",
        "\n",
        "        # 獲取第一個模型的結構\n",
        "        first_model = client_updates[0][0]\n",
        "        if not first_model:\n",
        "            return {}\n",
        "\n",
        "        # 【修正】確保使用標準格式的鍵名進行聚合\n",
        "        standard_first_model = self._convert_state_dict_for_dp_model(first_model, target_is_dp=False)\n",
        "\n",
        "        # 初始化聚合模型\n",
        "        aggregated_model = {}\n",
        "        for key in standard_first_model.keys():\n",
        "            aggregated_model[key] = torch.zeros_like(standard_first_model[key])\n",
        "\n",
        "        # 加權聚合\n",
        "        for model_state, num_samples in client_updates:\n",
        "            if not model_state:\n",
        "                continue\n",
        "\n",
        "            weight = num_samples / total_samples\n",
        "\n",
        "            # 轉換為標準格式\n",
        "            standard_model_state = self._convert_state_dict_for_dp_model(model_state, target_is_dp=False)\n",
        "\n",
        "            for key in aggregated_model.keys():\n",
        "                if key in standard_model_state:\n",
        "                    # 確保設備匹配\n",
        "                    param_tensor = standard_model_state[key]\n",
        "                    if param_tensor.device != aggregated_model[key].device:\n",
        "                        param_tensor = param_tensor.to(aggregated_model[key].device)\n",
        "\n",
        "                    aggregated_model[key] += weight * param_tensor\n",
        "\n",
        "        return aggregated_model\n",
        "\n",
        "    def update_clusters(self, client_agents: Dict, current_round: int):\n",
        "        \"\"\"\n",
        "        更新客戶端聚類（ClusteredFL模式使用）\n",
        "        \"\"\"\n",
        "        if len(client_agents) < self.num_clusters:\n",
        "            # 客戶端數量少於聚類數，簡單分配\n",
        "            for i, client_id in enumerate(client_agents.keys()):\n",
        "                self.client_to_cluster[client_id] = i % self.num_clusters\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # 提取客戶端模型特徵進行聚類\n",
        "            client_features = []\n",
        "            client_ids = []\n",
        "\n",
        "            for client_id, agent in client_agents.items():\n",
        "                try:\n",
        "                    # 獲取模型權重向量\n",
        "                    weights = agent.get_model_weights_flat()\n",
        "                    if weights is not None and len(weights) > 0:\n",
        "                        client_features.append(weights)\n",
        "                        client_ids.append(client_id)\n",
        "                except Exception as e:\n",
        "                    print(f\"[FLServer] ⚠️ 客戶端 {client_id} 特徵提取失敗: {e}\")\n",
        "                    continue\n",
        "\n",
        "            if len(client_features) < self.num_clusters:\n",
        "                # 特徵不足，使用簡單分配\n",
        "                for i, client_id in enumerate(client_ids):\n",
        "                    self.client_to_cluster[client_id] = i % self.num_clusters\n",
        "                return\n",
        "\n",
        "            # 使用 K-means 進行聚類\n",
        "            client_features_array = np.vstack(client_features)\n",
        "\n",
        "            # 標準化特徵\n",
        "            from sklearn.preprocessing import StandardScaler\n",
        "            scaler = StandardScaler()\n",
        "            normalized_features = scaler.fit_transform(client_features_array)\n",
        "\n",
        "            # K-means 聚類\n",
        "            kmeans = KMeans(n_clusters=self.num_clusters, random_state=42, n_init=10)\n",
        "            cluster_labels = kmeans.fit_predict(normalized_features)\n",
        "\n",
        "            # 更新客戶端到聚類的映射\n",
        "            for client_id, cluster_label in zip(client_ids, cluster_labels):\n",
        "                self.client_to_cluster[client_id] = int(cluster_label)\n",
        "\n",
        "            print(f\"[FLServer] Round {current_round}: 聚類更新完成\")\n",
        "            for cluster_id in range(self.num_clusters):\n",
        "                clients_in_cluster = [cid for cid, cid_cluster in self.client_to_cluster.items()\n",
        "                                    if cid_cluster == cluster_id]\n",
        "                print(f\"  聚類 {cluster_id}: {clients_in_cluster}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[FLServer] 聚類更新失敗: {e}\")\n",
        "            # 回退到簡單分配\n",
        "            for i, client_id in enumerate(client_agents.keys()):\n",
        "                self.client_to_cluster[client_id] = i % self.num_clusters\n",
        "\n",
        "    def get_cluster_info(self) -> Dict:\n",
        "        \"\"\"\n",
        "        獲取聚類信息\n",
        "        \"\"\"\n",
        "        cluster_info = {}\n",
        "        for cluster_id in range(self.num_clusters):\n",
        "            clients_in_cluster = [cid for cid, cid_cluster in self.client_to_cluster.items()\n",
        "                                if cid_cluster == cluster_id]\n",
        "            cluster_info[cluster_id] = {\n",
        "                'clients': clients_in_cluster,\n",
        "                'size': len(clients_in_cluster),\n",
        "                'has_model': cluster_id in self.cluster_models and self.cluster_models[cluster_id] is not None\n",
        "            }\n",
        "        return cluster_info\n",
        "\n",
        "print(\"✅ Cell 6: FLServer 類別定義完成（完整修正版 - DP格式轉換）。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8XuIPrqxMVj",
        "outputId": "f8b6ddfa-8bf2-441a-eb7a-068cba63e0e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 6.5: VirtualClientGenerator（學術合理版）定義完成。\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 6.5: 🔄 虛擬客戶端生成器（學術合理版）\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from typing import Dict, List, Tuple\n",
        "import copy\n",
        "\n",
        "class VirtualClientGenerator:\n",
        "    \"\"\"\n",
        "    學術上合理的虛擬客戶端生成器\n",
        "    基於時間分割和特徵增強技術，避免數據洩漏\n",
        "\n",
        "    學術依據:\n",
        "    - FedTDD: 時間序列聯邦學習中的時間對齊技術\n",
        "    - FFTS: 異質性時間序列的聯邦基礎模型方法\n",
        "    - SplitAVG: 基於分割的聯邦學習異質性處理\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: TrainingConfig):\n",
        "        self.config = config\n",
        "        self.scalers = {}\n",
        "        self.generation_stats = {\n",
        "            'real_clients': 0,\n",
        "            'virtual_clients': 0,\n",
        "            'failed_generations': 0,\n",
        "            'total_data_points': 0\n",
        "        }\n",
        "\n",
        "    def generate_virtual_clients(self, original_trajectories: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        從原始軌跡生成虛擬客戶端\n",
        "\n",
        "        Returns:\n",
        "            Dict: 包含真實和虛擬客戶端的軌跡字典\n",
        "        \"\"\"\n",
        "        virtual_trajectories = {}\n",
        "\n",
        "        print(f\"\\n🔄 開始生成虛擬客戶端...\")\n",
        "        print(f\"   - 原始客戶端數: {len(original_trajectories)}\")\n",
        "        print(f\"   - 目標總客戶端數: {self.config.total_clients}\")\n",
        "\n",
        "        # 1. 處理原始客戶端（真實基站對）\n",
        "        for i, (embb_bs, urllc_bs) in enumerate(self.config.base_client_pairs):\n",
        "            client_id = i\n",
        "            if client_id in original_trajectories:\n",
        "                virtual_trajectories[client_id] = original_trajectories[client_id]\n",
        "                self.generation_stats['real_clients'] += 1\n",
        "                self.generation_stats['total_data_points'] += len(original_trajectories[client_id])\n",
        "                print(f\"[真實客戶端 {client_id}] 基站對: ({embb_bs}, {urllc_bs}) - 數據點: {len(original_trajectories[client_id])}\")\n",
        "\n",
        "        # 2. 生成虛擬客戶端\n",
        "        virtual_client_id = len(self.config.base_client_pairs)\n",
        "\n",
        "        for base_id, (embb_bs, urllc_bs) in enumerate(self.config.base_client_pairs):\n",
        "            if base_id not in original_trajectories:\n",
        "                print(f\"⚠️ 跳過基站對 ({embb_bs}, {urllc_bs}) - 無原始數據\")\n",
        "                continue\n",
        "\n",
        "            base_trajectory = original_trajectories[base_id]\n",
        "\n",
        "            # 為每個基站對生成多個虛擬客戶端\n",
        "            for virtual_idx in range(self.config.virtual_expansion_factor):\n",
        "                virtual_traj = self._create_virtual_trajectory(\n",
        "                    base_trajectory, base_id, virtual_idx\n",
        "                )\n",
        "\n",
        "                if virtual_traj is not None and virtual_traj.size > 0:\n",
        "                    virtual_trajectories[virtual_client_id] = virtual_traj\n",
        "                    self.generation_stats['virtual_clients'] += 1\n",
        "                    self.generation_stats['total_data_points'] += len(virtual_traj)\n",
        "                    print(f\"[虛擬客戶端 {virtual_client_id}] 基於基站對 ({embb_bs}, {urllc_bs}) - 變體 {virtual_idx+1} - 數據點: {len(virtual_traj)}\")\n",
        "                    virtual_client_id += 1\n",
        "                else:\n",
        "                    self.generation_stats['failed_generations'] += 1\n",
        "                    print(f\"❌ 虛擬客戶端生成失敗: 基站對 ({embb_bs}, {urllc_bs}) - 變體 {virtual_idx+1}\")\n",
        "\n",
        "        # 3. 生成統計報告\n",
        "        print(f\"\\n✅ 虛擬客戶端生成完成:\")\n",
        "        print(f\"   - 真實客戶端: {self.generation_stats['real_clients']}\")\n",
        "        print(f\"   - 虛擬客戶端: {self.generation_stats['virtual_clients']}\")\n",
        "        print(f\"   - 失敗生成: {self.generation_stats['failed_generations']}\")\n",
        "        print(f\"   - 總客戶端: {len(virtual_trajectories)}\")\n",
        "        print(f\"   - 總數據點: {self.generation_stats['total_data_points']}\")\n",
        "\n",
        "        return virtual_trajectories\n",
        "\n",
        "    def _create_virtual_trajectory(self, base_trajectory: np.ndarray,\n",
        "                                   base_id: int, virtual_idx: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        創建虛擬軌跡的核心方法\n",
        "\n",
        "        採用多種學術驗證的技術:\n",
        "        1. 時間滑動窗口分割 (避免數據重複)\n",
        "        2. 差分隱私友好的噪聲注入\n",
        "        3. 特徵變換和增強\n",
        "        4. 統計不變性保持\n",
        "        \"\"\"\n",
        "        if base_trajectory.size == 0:\n",
        "            return np.array([])\n",
        "\n",
        "        try:\n",
        "            # 方法選擇：根據配置選擇生成方法\n",
        "            if self.config.temporal_split_method == \"sliding_window\":\n",
        "                virtual_traj = self._temporal_sliding_window(\n",
        "                    base_trajectory, virtual_idx\n",
        "                )\n",
        "            elif self.config.temporal_split_method == \"cross_validation\":\n",
        "                virtual_traj = self._cross_validation_split(\n",
        "                    base_trajectory, virtual_idx\n",
        "                )\n",
        "            else:\n",
        "                virtual_traj = self._feature_subspace_projection(\n",
        "                    base_trajectory, virtual_idx\n",
        "                )\n",
        "\n",
        "            # 確保基本數據完整性\n",
        "            if virtual_traj.size == 0:\n",
        "                return np.array([])\n",
        "\n",
        "            # 添加差分隱私友好的噪聲\n",
        "            if self.config.noise_injection_std > 0:\n",
        "                virtual_traj = self._add_privacy_preserving_noise(\n",
        "                    virtual_traj, base_id, virtual_idx\n",
        "                )\n",
        "\n",
        "            # 特徵增強\n",
        "            if self.config.feature_augmentation:\n",
        "                virtual_traj = self._feature_augmentation(\n",
        "                    virtual_traj, base_id, virtual_idx\n",
        "                )\n",
        "\n",
        "            # 最終驗證\n",
        "            if not self._validate_trajectory(virtual_traj):\n",
        "                print(f\"⚠️ 虛擬軌跡驗證失敗 (base_id={base_id}, virtual_idx={virtual_idx})\")\n",
        "                return np.array([])\n",
        "\n",
        "            return virtual_traj\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ 虛擬客戶端生成失敗 (base_id={base_id}, virtual_idx={virtual_idx}): {e}\")\n",
        "            return np.array([])\n",
        "\n",
        "    def _temporal_sliding_window(self, trajectory: np.ndarray, virtual_idx: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        時間滑動窗口分割 - 學術依據: FedTDD\n",
        "\n",
        "        將時間序列按照不同窗口分割，確保數據非重疊\n",
        "        \"\"\"\n",
        "        total_length = len(trajectory)\n",
        "        # 確保每個虛擬客戶端都有足夠的數據\n",
        "        window_size = total_length // (self.config.virtual_expansion_factor + 1)\n",
        "\n",
        "        # 最小數據量保證\n",
        "        min_window_size = max(100, self.config.batch_size * 5)\n",
        "        if window_size < min_window_size:\n",
        "            # 如果窗口太小，使用重疊窗口但添加更多噪聲\n",
        "            window_size = min_window_size\n",
        "            overlap = 0.3  # 30% 重疊\n",
        "            stride = int(window_size * (1 - overlap))\n",
        "            start_idx = virtual_idx * stride\n",
        "        else:\n",
        "            # 非重疊窗口\n",
        "            start_idx = virtual_idx * window_size\n",
        "\n",
        "        end_idx = start_idx + window_size\n",
        "\n",
        "        # 邊界檢查\n",
        "        if start_idx >= total_length:\n",
        "            # 循環使用數據\n",
        "            start_idx = start_idx % total_length\n",
        "            end_idx = start_idx + min(window_size, total_length - start_idx)\n",
        "\n",
        "        if end_idx > total_length:\n",
        "            end_idx = total_length\n",
        "\n",
        "        if start_idx >= end_idx:\n",
        "            # 使用尾部數據\n",
        "            return trajectory[-min_window_size:].copy()\n",
        "\n",
        "        return trajectory[start_idx:end_idx].copy()\n",
        "\n",
        "    def _cross_validation_split(self, trajectory: np.ndarray, virtual_idx: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        交叉驗證分割 - 學術依據: SLVR\n",
        "\n",
        "        模擬K-fold交叉驗證的數據分割方式\n",
        "        \"\"\"\n",
        "        total_length = len(trajectory)\n",
        "        k_folds = self.config.virtual_expansion_factor + 1\n",
        "        fold_size = total_length // k_folds\n",
        "\n",
        "        # 確保每個fold有最小數據量\n",
        "        min_fold_size = max(100, self.config.batch_size * 3)\n",
        "        if fold_size < min_fold_size:\n",
        "            # 使用隨機抽樣代替嚴格分割\n",
        "            return self._random_stratified_sampling(trajectory, virtual_idx)\n",
        "\n",
        "        # 使用不同的fold作為虛擬客戶端數據\n",
        "        indices = np.arange(total_length)\n",
        "        np.random.seed(42 + virtual_idx)  # 確保可重現性\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        start_idx = virtual_idx * fold_size\n",
        "        end_idx = start_idx + fold_size\n",
        "\n",
        "        if end_idx > len(indices):\n",
        "            end_idx = len(indices)\n",
        "\n",
        "        selected_indices = indices[start_idx:end_idx]\n",
        "        selected_indices.sort()  # 保持時間順序\n",
        "\n",
        "        return trajectory[selected_indices].copy()\n",
        "\n",
        "    def _random_stratified_sampling(self, trajectory: np.ndarray, virtual_idx: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        隨機分層抽樣 - 當數據量不足時的備用方法\n",
        "        \"\"\"\n",
        "        total_length = len(trajectory)\n",
        "        sample_ratio = 0.7  # 抽取70%的數據\n",
        "        sample_size = int(total_length * sample_ratio)\n",
        "\n",
        "        np.random.seed(100 + virtual_idx)\n",
        "        selected_indices = np.random.choice(\n",
        "            total_length, size=sample_size, replace=False\n",
        "        )\n",
        "        selected_indices.sort()\n",
        "\n",
        "        return trajectory[selected_indices].copy()\n",
        "\n",
        "    def _feature_subspace_projection(self, trajectory: np.ndarray, virtual_idx: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        特徵子空間投影 - 學術依據: SplitAVG\n",
        "\n",
        "        在不同特徵子空間中投影數據，模擬不同視角\n",
        "        \"\"\"\n",
        "        if trajectory.ndim < 2:\n",
        "            return trajectory\n",
        "\n",
        "        num_features = trajectory.shape[1]\n",
        "        if num_features < 4:\n",
        "            return trajectory\n",
        "\n",
        "        # 選擇不同的特徵子集\n",
        "        feature_indices = np.arange(num_features)\n",
        "        np.random.seed(100 + virtual_idx)\n",
        "\n",
        "        # 保留80%的特徵，但選擇不同的組合\n",
        "        num_selected = max(int(num_features * 0.8), num_features - 2)\n",
        "        selected_features = np.random.choice(\n",
        "            feature_indices, size=num_selected, replace=False\n",
        "        )\n",
        "        selected_features.sort()\n",
        "\n",
        "        return trajectory[:, selected_features].copy()\n",
        "\n",
        "    def _add_privacy_preserving_noise(self, trajectory: np.ndarray,\n",
        "                                      base_id: int, virtual_idx: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        添加差分隱私友好的高斯噪聲\n",
        "        學術依據: DP聯邦學習\n",
        "        \"\"\"\n",
        "        np.random.seed(200 + base_id * 10 + virtual_idx)\n",
        "\n",
        "        # 根據數據尺度自適應噪聲\n",
        "        if trajectory.ndim == 1:\n",
        "            data_std = np.std(trajectory)\n",
        "            noise_scale = self.config.noise_injection_std * data_std\n",
        "            noise = np.random.normal(0, noise_scale, trajectory.shape)\n",
        "        else:\n",
        "            data_std = np.std(trajectory, axis=0)\n",
        "            noise_scale = self.config.noise_injection_std * data_std\n",
        "            noise = np.random.normal(0, noise_scale, trajectory.shape)\n",
        "\n",
        "        # 確保噪聲不會破壞數據的基本特性\n",
        "        noise_magnitude = np.abs(noise).max()\n",
        "        data_magnitude = np.abs(trajectory).max()\n",
        "\n",
        "        if noise_magnitude > 0.1 * data_magnitude:  # 限制噪聲幅度\n",
        "            noise = noise * (0.1 * data_magnitude / noise_magnitude)\n",
        "\n",
        "        return trajectory + noise\n",
        "\n",
        "    def _feature_augmentation(self, trajectory: np.ndarray,\n",
        "                              base_id: int, virtual_idx: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        特徵增強 - 學術依據: FedRDN\n",
        "\n",
        "        通過統計特徵變換增強數據多樣性\n",
        "        \"\"\"\n",
        "        if trajectory.size == 0:\n",
        "            return trajectory\n",
        "\n",
        "        augmented_traj = trajectory.copy()\n",
        "\n",
        "        # 1. 時間平移（模擬不同起始時間）\n",
        "        shift_amount = virtual_idx * 3  # 適度的時間平移\n",
        "        if len(augmented_traj) > shift_amount:\n",
        "            augmented_traj = np.roll(augmented_traj, shift_amount, axis=0)\n",
        "\n",
        "        # 2. 輕微的尺度變換（模擬不同系統條件）\n",
        "        scale_factor = 1.0 + (virtual_idx - 1) * 0.015  # ±1.5%的變化\n",
        "        augmented_traj = augmented_traj * scale_factor\n",
        "\n",
        "        # 3. 添加季節性變化（模擬不同時間段的特性）\n",
        "        if len(augmented_traj) > 10:\n",
        "            seasonal_period = max(10, len(augmented_traj) // 5)\n",
        "            seasonal_component = 0.02 * np.sin(\n",
        "                2 * np.pi * np.arange(len(augmented_traj)) / seasonal_period + virtual_idx\n",
        "            )\n",
        "            if augmented_traj.ndim == 1:\n",
        "                augmented_traj += seasonal_component\n",
        "            else:\n",
        "                augmented_traj[:, 0] += seasonal_component\n",
        "\n",
        "        return augmented_traj\n",
        "\n",
        "    def _validate_trajectory(self, trajectory: np.ndarray) -> bool:\n",
        "        \"\"\"\n",
        "        驗證生成的虛擬軌跡是否有效\n",
        "        \"\"\"\n",
        "        if trajectory.size == 0:\n",
        "            return False\n",
        "\n",
        "        # 檢查數據完整性\n",
        "        if np.any(np.isnan(trajectory)) or np.any(np.isinf(trajectory)):\n",
        "            return False\n",
        "\n",
        "        # 檢查最小數據量\n",
        "        min_required_length = max(50, self.config.batch_size * 2)\n",
        "        if len(trajectory) < min_required_length:\n",
        "            return False\n",
        "\n",
        "        # 檢查數據變異性\n",
        "        if trajectory.ndim == 1:\n",
        "            if np.std(trajectory) < 1e-6:  # 數據過於單調\n",
        "                return False\n",
        "        else:\n",
        "            if np.any(np.std(trajectory, axis=0) < 1e-6):\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def get_virtual_client_info(self) -> Dict:\n",
        "        \"\"\"返回虛擬客戶端生成的詳細資訊\"\"\"\n",
        "        return {\n",
        "            'base_clients': self.generation_stats['real_clients'],\n",
        "            'virtual_expansion_factor': self.config.virtual_expansion_factor,\n",
        "            'virtual_clients_generated': self.generation_stats['virtual_clients'],\n",
        "            'failed_generations': self.generation_stats['failed_generations'],\n",
        "            'total_clients': self.generation_stats['real_clients'] + self.generation_stats['virtual_clients'],\n",
        "            'total_data_points': self.generation_stats['total_data_points'],\n",
        "            'split_method': self.config.temporal_split_method,\n",
        "            'noise_std': self.config.noise_injection_std,\n",
        "            'feature_augmentation': self.config.feature_augmentation,\n",
        "            'generation_success_rate': self.generation_stats['virtual_clients'] / (self.generation_stats['virtual_clients'] + self.generation_stats['failed_generations']) if (self.generation_stats['virtual_clients'] + self.generation_stats['failed_generations']) > 0 else 0\n",
        "        }\n",
        "\n",
        "print(\"✅ Cell 6.5: VirtualClientGenerator（學術合理版）定義完成。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0yvrVAOIQM5",
        "outputId": "0fa80911-c268-4da9-f7bb-c908f0f01688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 7: ExperimentRunner（死循環修正版）定義完成。\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 7: 🚀 ExperimentRunner（死循環修正版）\n",
        "import scipy.stats as stats\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class ExperimentRunner:\n",
        "    def __init__(self, config: TrainingConfig, data_manager: DataManager, all_trajectories, client_pairs):\n",
        "        self.config, self.data_manager, self.server = config, data_manager, FLServer(config)\n",
        "        self.training_history, self.evaluation_results, self.privacy_costs = [], [], []\n",
        "\n",
        "        # 【修正死循環】隱私預算管理增強\n",
        "        self.total_privacy_budget = config.dp_target_epsilon if config.enable_dp else 0.0\n",
        "        self.consumed_privacy_budget = 0.0\n",
        "        self.privacy_budget_exceeded = False\n",
        "        self.dp_reset_history = []\n",
        "        self.round_privacy_costs = []\n",
        "        self.detailed_privacy_logs = []\n",
        "\n",
        "        # 【新增】死循環防護機制\n",
        "        self.max_resets_per_round = 3  # 每輪最多重設3次\n",
        "        self.current_round_resets = 0\n",
        "        self.consecutive_reset_rounds = 0\n",
        "        self.max_consecutive_resets = 5  # 最多連續5輪重設\n",
        "\n",
        "        self._set_seeds()\n",
        "        # 其他初始化邏輯保持不變...\n",
        "        print(\"\\n[ExperimentRunner] 正在初始化客戶端環境與代理...\")\n",
        "\n",
        "        if self.config.enable_dp and self.config.mode != 'Centralized':\n",
        "            print(f\"🛡️ 差分隱私模式啟用（死循環防護版）：\")\n",
        "            print(f\"   - 總隱私預算上限: ε={self.total_privacy_budget}\")\n",
        "            print(f\"   - 重設閾值: ε={self.total_privacy_budget * self.config.dp_reset_threshold_multiplier}\")\n",
        "            print(f\"   - 死循環防護: 每輪最多{self.max_resets_per_round}次重設\")\n",
        "            print(f\"   - 客戶端數量: {self.config.num_clients}\")\n",
        "\n",
        "        # 初始化客戶端環境（保持不變）\n",
        "        self.client_envs = {cid: PairedEnv(traj, config) for cid, traj in all_trajectories.items() if traj.size > 0}\n",
        "        if not self.client_envs:\n",
        "            raise ValueError(\"DataManager 未能為任何客戶端創建有效的環境。\")\n",
        "\n",
        "        self.config.num_clients = len(self.client_envs)\n",
        "\n",
        "        if self.config.mode == \"Centralized\":\n",
        "            central_config = copy.deepcopy(config)\n",
        "            central_config.enable_dp = False\n",
        "            pooled_trajectory = np.vstack([traj for traj in all_trajectories.values() if traj.size > 0])\n",
        "            self.central_env = PairedEnv(pooled_trajectory, central_config)\n",
        "            self.central_agent = RLAgent(self.central_env.state_size, self.central_env.action_size, central_config, 0, len(pooled_trajectory), False)\n",
        "            self.client_agents = {}\n",
        "        else:\n",
        "            self.client_agents = {}\n",
        "            for cid, env in self.client_envs.items():\n",
        "                dataset_size = len(env.trajectory) if env.trajectory.size > 0 else 1\n",
        "                self.client_agents[cid] = RLAgent(env.state_size, env.action_size, config, cid, dataset_size, False)\n",
        "\n",
        "        if self.client_agents:\n",
        "            self.global_model_state = self.client_agents[next(iter(self.client_agents))].get_clean_state_dict()\n",
        "        else:\n",
        "            self.global_model_state = self.central_agent.get_clean_state_dict()\n",
        "\n",
        "        self.config.save()\n",
        "        print(\"[ExperimentRunner] 初始化完成。\")\n",
        "\n",
        "    def _set_seeds(self):\n",
        "        seed = self.config.random_seed\n",
        "        torch.manual_seed(seed); torch.cuda.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "        np.random.seed(seed); random.seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True; torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    def _check_privacy_budget_and_reset(self, round_privacy_costs, current_round):\n",
        "        \"\"\"【修正死循環】隱私預算檢查與智能重設機制\"\"\"\n",
        "        if not self.config.enable_dp or self.config.mode == 'Centralized':\n",
        "            return\n",
        "\n",
        "        # 【新增】重設輪次開始時重置計數器\n",
        "        if current_round != getattr(self, '_last_checked_round', -1):\n",
        "            self.current_round_resets = 0\n",
        "            self._last_checked_round = current_round\n",
        "\n",
        "        # 收集詳細隱私資訊\n",
        "        round_detailed_info = []\n",
        "        for cid, agent in self.client_agents.items():\n",
        "            detailed_info = agent.get_privacy_detailed_info()\n",
        "            detailed_info['round'] = current_round\n",
        "            round_detailed_info.append(detailed_info)\n",
        "        self.detailed_privacy_logs.extend(round_detailed_info)\n",
        "\n",
        "        if round_privacy_costs:\n",
        "            # 使用平均值避免重複計帳\n",
        "            round_avg_epsilon = np.mean(round_privacy_costs)\n",
        "            round_max_epsilon = np.max(round_privacy_costs)\n",
        "            round_min_epsilon = np.min(round_privacy_costs)\n",
        "\n",
        "            self.consumed_privacy_budget += round_avg_epsilon\n",
        "\n",
        "            # 詳細的隱私成本記錄\n",
        "            self.round_privacy_costs.append({\n",
        "                'round': current_round,\n",
        "                'avg_epsilon': round_avg_epsilon,\n",
        "                'max_epsilon': round_max_epsilon,\n",
        "                'min_epsilon': round_min_epsilon,\n",
        "                'std_epsilon': np.std(round_privacy_costs),\n",
        "                'participating_clients': len(round_privacy_costs),\n",
        "                'cumulative_epsilon': self.consumed_privacy_budget,\n",
        "                'round_resets': self.current_round_resets\n",
        "            })\n",
        "\n",
        "            budget_ratio = self.consumed_privacy_budget / self.total_privacy_budget\n",
        "            reset_threshold = self.total_privacy_budget * self.config.dp_reset_threshold_multiplier\n",
        "\n",
        "            # 檢查是否首次超支\n",
        "            if budget_ratio > 1.0 and not self.privacy_budget_exceeded:\n",
        "                print(f\"\\n{'='*20} ⚠️ 隱私預算首次超支！ {'='*20}\")\n",
        "                print(f\"   - 當前消耗: ε = {self.consumed_privacy_budget:.4f}\")\n",
        "                print(f\"   - 預算上限: ε = {self.total_privacy_budget}\")\n",
        "                print(f\"   - 本輪統計: 平均={round_avg_epsilon:.4f}, 最大={round_max_epsilon:.4f}\")\n",
        "                print(f\"{'='*58}\")\n",
        "                self.privacy_budget_exceeded = True\n",
        "\n",
        "            # 【關鍵修正】智能重設機制，防止死循環\n",
        "            should_reset = (\n",
        "                self.consumed_privacy_budget > reset_threshold and\n",
        "                self.config.enable_dp_reset and\n",
        "                self.current_round_resets < self.max_resets_per_round and  # 限制每輪重設次數\n",
        "                self.consecutive_reset_rounds < self.max_consecutive_resets  # 限制連續重設輪數\n",
        "            )\n",
        "\n",
        "            if should_reset:\n",
        "                print(f\"\\n🔄 觸發隱私預算重設機制（Round {current_round}）\")\n",
        "                print(f\"   - 觸發條件: {self.consumed_privacy_budget:.4f} > {reset_threshold:.4f}\")\n",
        "                print(f\"   - 本輪重設次數: {self.current_round_resets}/{self.max_resets_per_round}\")\n",
        "                print(f\"   - 連續重設輪數: {self.consecutive_reset_rounds}/{self.max_consecutive_resets}\")\n",
        "\n",
        "                reset_count = 0\n",
        "                successful_resets = []\n",
        "                reset_failures = []\n",
        "\n",
        "                for cid, agent in self.client_agents.items():\n",
        "                    if agent.reset_dp_engine(current_round):\n",
        "                        reset_count += 1\n",
        "                        successful_resets.append(cid)\n",
        "                    else:\n",
        "                        reset_failures.append(cid)\n",
        "\n",
        "                if reset_count > 0:\n",
        "                    self.current_round_resets += 1\n",
        "                    self.consecutive_reset_rounds += 1\n",
        "\n",
        "                    self.dp_reset_history.append({\n",
        "                        'round': current_round,\n",
        "                        'reset_count': reset_count,\n",
        "                        'total_clients': len(self.client_agents),\n",
        "                        'successful_resets': successful_resets,\n",
        "                        'failed_resets': reset_failures,\n",
        "                        'budget_before_reset': self.consumed_privacy_budget,\n",
        "                        'trigger_threshold': reset_threshold,\n",
        "                        'round_reset_number': self.current_round_resets\n",
        "                    })\n",
        "\n",
        "                    # 重設系統預算計數\n",
        "                    self.consumed_privacy_budget = 0.0\n",
        "                    self.privacy_budget_exceeded = False\n",
        "\n",
        "                    print(f\"   - ✅ 重設完成：{reset_count}/{len(self.client_agents)}個客戶端\")\n",
        "                    print(f\"   - 本輪重設計數：{self.current_round_resets}\")\n",
        "                    if reset_failures:\n",
        "                        print(f\"   - ⚠️ 重設失敗的客戶端: {reset_failures}\")\n",
        "\n",
        "            elif self.consumed_privacy_budget > reset_threshold and self.config.enable_dp_reset:\n",
        "                # 達到重設限制的情況\n",
        "                if self.current_round_resets >= self.max_resets_per_round:\n",
        "                    print(f\"\\n⚠️ 本輪重設次數已達上限 ({self.max_resets_per_round})，跳過重設\")\n",
        "                if self.consecutive_reset_rounds >= self.max_consecutive_resets:\n",
        "                    print(f\"\\n⚠️ 連續重設輪數已達上限 ({self.max_consecutive_resets})，停用重設\")\n",
        "                    self.config.enable_dp_reset = False  # 暫時停用重設\n",
        "            else:\n",
        "                # 沒有觸發重設，重置連續重設計數\n",
        "                self.consecutive_reset_rounds = 0\n",
        "\n",
        "    def _train_agent_locally(self, agent: RLAgent, env: PairedEnv, episodes: int, is_finetune: bool = False):\n",
        "        \"\"\"【修正】訓練邏輯，增加步數監控\"\"\"\n",
        "        agent.model.train()\n",
        "        total_loss, total_reward, training_steps, episode_count = 0.0, 0.0, 0, 0\n",
        "\n",
        "        if episodes == 0:\n",
        "            return 0.0, 0.0, 0.0\n",
        "\n",
        "        # 【新增】訓練步數監控\n",
        "        initial_dp_steps = getattr(agent, 'dp_steps', 0)\n",
        "        max_steps_per_round = self.config.local_episodes_per_round * self.config.steps_per_episode * 2  # 設定上限\n",
        "\n",
        "        for episode in range(episodes):\n",
        "            state, episode_reward, done = env.reset(), 0.0, False\n",
        "            for step in range(1, self.config.steps_per_episode + 1):\n",
        "                action = agent.act(state)\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                agent.remember(state, action, reward, next_state, done)\n",
        "                state = next_state\n",
        "                episode_reward += reward\n",
        "\n",
        "                if len(agent.memory) > self.config.replay_start_size and step % self.config.replay_frequency == 0:\n",
        "                    loss = agent.replay(num_batches=self.config.replay_batches_per_call)\n",
        "                    total_loss += loss\n",
        "                    training_steps += 1\n",
        "\n",
        "                    # 【新增】步數監控，防止無限訓練\n",
        "                    current_dp_steps = getattr(agent, 'dp_steps', 0)\n",
        "                    if current_dp_steps - initial_dp_steps > max_steps_per_round:\n",
        "                        print(f\"[C-{agent.client_id}] ⚠️ 訓練步數超限 ({current_dp_steps - initial_dp_steps}>{max_steps_per_round})，提前結束\")\n",
        "                        break\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            total_reward += episode_reward\n",
        "            episode_count += 1\n",
        "            if (episode + 1) % self.config.target_update_freq == 0:\n",
        "                agent.update_target_model()\n",
        "\n",
        "        if not agent.is_eval_agent and not is_finetune and agent.epsilon > self.config.epsilon_min:\n",
        "            agent.epsilon *= self.config.epsilon_decay\n",
        "\n",
        "        avg_loss = total_loss / training_steps if training_steps > 0 else 0.0\n",
        "        avg_reward = total_reward / episode_count if episode_count > 0 else 0.0\n",
        "        privacy_cost = agent.get_privacy_cost() if training_steps > 0 and self.config.enable_dp and agent.privacy_engine else 0.0\n",
        "\n",
        "        return avg_loss, avg_reward, privacy_cost\n",
        "\n",
        "    def _run_federated_training(self):\n",
        "        \"\"\"【修正】聯邦訓練主流程，增加調試信息\"\"\"\n",
        "        print(f\"\\n[模式] 執行聯邦式訓練 ({self.config.mode})\")\n",
        "        available_client_ids = list(self.client_agents.keys())\n",
        "        progress_bar = tqdm(range(self.config.comm_rounds), desc=f\"{self.config.mode} Training\")\n",
        "\n",
        "        for comm_round in progress_bar:\n",
        "            print(f\"\\n--- 開始 Round {comm_round+1}/{self.config.comm_rounds} ---\")\n",
        "\n",
        "            # 聚類更新\n",
        "            if (self.config.mode == 'ClusteredFL' and comm_round > 0 and\n",
        "                comm_round % self.config.cluster_update_freq == 0):\n",
        "                self.server.update_clusters(self.client_agents, comm_round)\n",
        "\n",
        "            # 客戶端選擇\n",
        "            num_to_select = min(self.config.num_clients_to_select, len(available_client_ids))\n",
        "            selected_ids = np.random.choice(available_client_ids, num_to_select, replace=False)\n",
        "            participating_ids = list(selected_ids)\n",
        "            straggler_ids = set()\n",
        "\n",
        "            # 異質性模擬\n",
        "            if self.config.enable_heterogeneity and len(participating_ids) > 1:\n",
        "                num_dropouts = int(self.config.dropout_ratio * len(participating_ids))\n",
        "                if num_dropouts > 0 and len(participating_ids) > num_dropouts:\n",
        "                    dropout_ids = set(np.random.choice(participating_ids, num_dropouts, replace=False))\n",
        "                    participating_ids = [cid for cid in participating_ids if cid not in dropout_ids]\n",
        "\n",
        "                if participating_ids and len(participating_ids) > 1:\n",
        "                    num_stragglers = int(self.config.straggler_ratio * len(participating_ids))\n",
        "                    if num_stragglers > 0:\n",
        "                        straggler_ids = set(np.random.choice(participating_ids, num_stragglers, replace=False))\n",
        "\n",
        "            if not participating_ids:\n",
        "                continue\n",
        "\n",
        "            print(f\"參與客戶端: {participating_ids}\")\n",
        "\n",
        "            participating_agents = {cid: self.client_agents[cid] for cid in participating_ids}\n",
        "            self.server.distribute_model(participating_agents, self.global_model_state)\n",
        "\n",
        "            # 本地訓練並收集隱私成本\n",
        "            client_updates, round_losses, round_rewards, round_privacy_costs = [], [], [], []\n",
        "            for cid in participating_ids:\n",
        "                agent, env = self.client_agents[cid], self.client_envs[cid]\n",
        "                episodes = (self.config.local_episodes_per_round // 2 if cid in straggler_ids\n",
        "                           else self.config.local_episodes_per_round)\n",
        "\n",
        "                print(f\"[C-{cid}] 開始訓練 ({episodes} episodes)...\")\n",
        "                loss, reward, privacy_cost = self._train_agent_locally(agent, env, episodes)\n",
        "                print(f\"[C-{cid}] 完成 - Loss: {loss:.4f}, Reward: {reward:.4f}, ε: {privacy_cost:.4f}\")\n",
        "\n",
        "                client_updates.append((agent.get_model_for_upload(), len(env.trajectory)))\n",
        "                round_losses.append(loss); round_rewards.append(reward)\n",
        "                if self.config.enable_dp and privacy_cost > 0:\n",
        "                    round_privacy_costs.append(privacy_cost)\n",
        "\n",
        "            # 隱私預算檢查與重設\n",
        "            print(f\"檢查隱私預算...\")\n",
        "            self._check_privacy_budget_and_reset(round_privacy_costs, comm_round)\n",
        "\n",
        "            # 模型聚合\n",
        "            if self.config.mode == 'ClusteredFL':\n",
        "                client_updates_by_cluster = {i: [] for i in range(self.config.num_clusters)}\n",
        "                for i, (model_update, num_points) in enumerate(client_updates):\n",
        "                    cid = participating_ids[i]\n",
        "                    cluster_id = self.server.client_to_cluster.get(cid, 0)\n",
        "                    client_updates_by_cluster[cluster_id].append((model_update, num_points))\n",
        "\n",
        "                new_cluster_models = []\n",
        "                for cluster_id, updates in client_updates_by_cluster.items():\n",
        "                    if updates:\n",
        "                        updated_cluster_model = self.server.aggregate_weighted(updates)\n",
        "                        self.server.cluster_models[cluster_id] = updated_cluster_model\n",
        "                        new_cluster_models.append((updated_cluster_model, sum(n for _, n in updates)))\n",
        "                if new_cluster_models:\n",
        "                    self.global_model_state = self.server.aggregate_weighted(new_cluster_models)\n",
        "            else:\n",
        "                if client_updates:\n",
        "                    self.global_model_state = self.server.aggregate_weighted(client_updates)\n",
        "\n",
        "            # 記錄訓練歷史\n",
        "            avg_reward = np.mean(round_rewards) if round_rewards else 0\n",
        "            avg_loss = np.mean(round_losses) if round_losses else 0\n",
        "            self.training_history.append({'round': comm_round, 'avg_reward': avg_reward, 'avg_loss': avg_loss})\n",
        "\n",
        "            # 更詳細的隱私成本記錄\n",
        "            if self.config.enable_dp:\n",
        "                if round_privacy_costs:\n",
        "                    epsilon_stats = {\n",
        "                        'round': comm_round,\n",
        "                        'epsilon': np.mean(round_privacy_costs),\n",
        "                        'epsilon_max': np.max(round_privacy_costs),\n",
        "                        'epsilon_min': np.min(round_privacy_costs),\n",
        "                        'epsilon_std': np.std(round_privacy_costs),\n",
        "                        'cumulative_epsilon': self.consumed_privacy_budget,\n",
        "                        'budget_ratio': self.consumed_privacy_budget / self.total_privacy_budget,\n",
        "                        'reset_count': len(self.dp_reset_history),\n",
        "                        'participating_clients': len(round_privacy_costs)\n",
        "                    }\n",
        "                else:\n",
        "                    epsilon_stats = {\n",
        "                        'round': comm_round,\n",
        "                        'epsilon': 0.0, 'epsilon_max': 0.0, 'epsilon_min': 0.0, 'epsilon_std': 0.0,\n",
        "                        'cumulative_epsilon': self.consumed_privacy_budget,\n",
        "                        'budget_ratio': self.consumed_privacy_budget / self.total_privacy_budget,\n",
        "                        'reset_count': len(self.dp_reset_history),\n",
        "                        'participating_clients': 0\n",
        "                    }\n",
        "                self.privacy_costs.append(epsilon_stats)\n",
        "\n",
        "            # 進度條更新\n",
        "            postfix = {'reward': f\"{avg_reward:.2f}\", 'loss': f\"{avg_loss:.4f}\"}\n",
        "            if self.config.enable_dp and self.consumed_privacy_budget > 0:\n",
        "                postfix['ε_used'] = f\"{self.consumed_privacy_budget:.3f}\"\n",
        "                postfix['resets'] = str(len(self.dp_reset_history))\n",
        "            progress_bar.set_postfix(postfix)\n",
        "\n",
        "            print(f\"Round {comm_round+1} 完成 - {postfix}\")\n",
        "\n",
        "    # 其他方法保持不變（太長了，這裡省略）...\n",
        "    def _evaluate_agent(self, env, model_state, num_episodes=15):\n",
        "        if env.trajectory.size == 0: return 0.0\n",
        "        eval_config = copy.deepcopy(self.config); eval_config.enable_dp = False\n",
        "        eval_agent = RLAgent(env.state_size, env.action_size, eval_config, -1, 1, True)\n",
        "        eval_agent.model.load_state_dict(model_state); eval_agent.model.eval(); eval_agent.epsilon = 0.0\n",
        "        total_reward = 0\n",
        "        for _ in range(num_episodes):\n",
        "            state, episode_reward, done = env.reset(), 0, False\n",
        "            for _ in range(self.config.steps_per_episode):\n",
        "                action = eval_agent.act(state)\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                episode_reward += reward; state = next_state\n",
        "                if done: break\n",
        "            total_reward += episode_reward\n",
        "        return total_reward / num_episodes\n",
        "\n",
        "    def _run_centralized_training(self):\n",
        "        print(f\"\\n[模式] 執行集中式訓練 (Centralized)\")\n",
        "        progress_bar = tqdm(range(self.config.comm_rounds), desc=\"Centralized Training\")\n",
        "        num_clients_per_round = min(self.config.num_clients_to_select, self.config.num_clients)\n",
        "        equivalent_episodes = self.config.local_episodes_per_round * num_clients_per_round\n",
        "        for r in progress_bar:\n",
        "            loss, reward, _ = self._train_agent_locally(self.central_agent, self.central_env, episodes=equivalent_episodes)\n",
        "            self.training_history.append({'round': r, 'avg_reward': reward, 'avg_loss': loss})\n",
        "            self.privacy_costs.append({'round': r, 'epsilon': 0.0, 'cumulative_epsilon': 0.0, 'budget_ratio': 0.0})\n",
        "            progress_bar.set_postfix(reward=f\"{reward:.2f}\", loss=f\"{loss:.4f}\")\n",
        "        self.global_model_state = self.central_agent.get_clean_state_dict()\n",
        "\n",
        "    def _run_isolated_training(self):\n",
        "        print(f\"\\n[模式] 執行孤立式訓練 (Isolated)\")\n",
        "        progress_bar = tqdm(range(self.config.comm_rounds), desc=\"Isolated Training Rounds\")\n",
        "        num_clients_per_round = min(self.config.num_clients_to_select, self.config.num_clients)\n",
        "        equivalent_episodes_per_client = int(np.ceil((self.config.local_episodes_per_round * num_clients_per_round) / self.config.num_clients))\n",
        "\n",
        "        for r in progress_bar:\n",
        "            round_rewards, round_losses, round_epsilons = [], [], []\n",
        "            for cid, agent in self.client_agents.items():\n",
        "                env = self.client_envs[cid]\n",
        "                loss, reward, privacy_cost = self._train_agent_locally(agent, env, episodes=equivalent_episodes_per_client)\n",
        "                round_rewards.append(reward); round_losses.append(loss)\n",
        "                if self.config.enable_dp and privacy_cost > 0:\n",
        "                    round_epsilons.append(privacy_cost)\n",
        "\n",
        "            avg_reward = np.mean(round_rewards) if round_rewards else np.nan\n",
        "            avg_loss = np.mean(round_losses) if round_losses else np.nan\n",
        "            self.training_history.append({'round': r, 'avg_reward': avg_reward, 'avg_loss': avg_loss})\n",
        "\n",
        "            if self.config.enable_dp and round_epsilons:\n",
        "                avg_epsilon = np.mean(round_epsilons)\n",
        "                self.consumed_privacy_budget += avg_epsilon\n",
        "                self.privacy_costs.append({\n",
        "                    'round': r, 'epsilon': avg_epsilon,\n",
        "                    'cumulative_epsilon': self.consumed_privacy_budget,\n",
        "                    'budget_ratio': self.consumed_privacy_budget / self.total_privacy_budget\n",
        "                })\n",
        "            else:\n",
        "                self.privacy_costs.append({\n",
        "                    'round': r, 'epsilon': 0.0, 'cumulative_epsilon': self.consumed_privacy_budget,\n",
        "                    'budget_ratio': self.consumed_privacy_budget / self.total_privacy_budget\n",
        "                })\n",
        "\n",
        "            postfix = {'reward': f\"{avg_reward:.2f}\" if not np.isnan(avg_reward) else \"NaN\",\n",
        "                      'loss': f\"{avg_loss:.4f}\" if not np.isnan(avg_loss) else \"NaN\"}\n",
        "            if self.config.enable_dp and self.consumed_privacy_budget > 0:\n",
        "                postfix['ε_used'] = f\"{self.consumed_privacy_budget:.3f}\"\n",
        "            progress_bar.set_postfix(postfix)\n",
        "\n",
        "    def _run_final_evaluation_and_pfl(self):\n",
        "        print(\"\\n[評估] 正在執行最終評估...\")\n",
        "        final_model_path = os.path.join(self.config.output_dir, f'{self.config.experiment_name}_global_model.pt')\n",
        "        if self.global_model_state:\n",
        "            torch.save(self.global_model_state, final_model_path)\n",
        "\n",
        "        for cid, env in tqdm(self.client_envs.items(), desc=\"最終評估\"):\n",
        "            eval_row = {'client_id': cid}\n",
        "            seed = self.config.random_seed + cid\n",
        "\n",
        "            if self.config.mode == \"Isolated\":\n",
        "                base_model_state = self.client_agents[cid].get_clean_state_dict()\n",
        "                personalized_model_state = base_model_state\n",
        "            else:\n",
        "                base_model_state = self.global_model_state\n",
        "                personalized_model_state = base_model_state\n",
        "                if self.config.mode == 'ClusteredFL':\n",
        "                    cluster_id = self.server.client_to_cluster.get(cid)\n",
        "                    if cluster_id is not None and cluster_id in self.server.cluster_models:\n",
        "                        personalized_model_state = self.server.cluster_models[cluster_id]\n",
        "\n",
        "            torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
        "            eval_row['reward_global'] = self._evaluate_agent(env, base_model_state)\n",
        "\n",
        "            if personalized_model_state is base_model_state:\n",
        "                eval_row['reward_personalized'] = eval_row['reward_global']\n",
        "            else:\n",
        "                torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
        "                eval_row['reward_personalized'] = self._evaluate_agent(env, personalized_model_state)\n",
        "\n",
        "            if self.config.use_pfl_finetune:\n",
        "                finetune_config = copy.deepcopy(self.config); finetune_config.enable_dp = False\n",
        "                finetune_agent = RLAgent(env.state_size, env.action_size, finetune_config, cid, len(env.trajectory), False)\n",
        "                finetune_agent.epsilon = 0.01; finetune_agent.model.load_state_dict(personalized_model_state)\n",
        "                self._train_agent_locally(finetune_agent, env, self.config.local_finetune_episodes, True)\n",
        "                torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
        "                finetuned_model_state = finetune_agent.get_clean_state_dict()\n",
        "                eval_row['reward_pfl_finetuned'] = self._evaluate_agent(env, finetuned_model_state)\n",
        "            else:\n",
        "                eval_row['reward_pfl_finetuned'] = eval_row['reward_personalized']\n",
        "\n",
        "            self.evaluation_results.append(eval_row)\n",
        "\n",
        "    def run(self):\n",
        "        print(f\"\\n{'='*20} 🏃♂️ 開始執行實驗: {self.config.experiment_name} ({self.config.mode}) {'='*20}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        if self.config.mode == 'Centralized':\n",
        "            self._run_centralized_training()\n",
        "        elif self.config.mode == 'Isolated':\n",
        "            self._run_isolated_training()\n",
        "        elif self.config.mode in ['FedAvg', 'FedProx', 'ClusteredFL']:\n",
        "            self._run_federated_training()\n",
        "        else:\n",
        "            raise ValueError(f\"未知的實驗模式: {self.config.mode}\")\n",
        "\n",
        "        self._run_final_evaluation_and_pfl()\n",
        "\n",
        "        total_time = (time.time() - start_time) / 60\n",
        "        print(f\"✅ 實驗 {self.config.experiment_name} 完成！總耗時: {total_time:.2f} 分鐘\")\n",
        "\n",
        "        if self.config.enable_dp and self.config.mode != 'Centralized':\n",
        "            print(f\"🛡️ 最終隱私報告：\")\n",
        "            print(f\"   - 總消耗隱私預算: ε = {self.consumed_privacy_budget:.4f}\")\n",
        "            print(f\"   - DP引擎重設次數: {len(self.dp_reset_history)}\")\n",
        "            if self.privacy_budget_exceeded:\n",
        "                print(f\"   - ⚠️ 隱私預算已超支\")\n",
        "            else:\n",
        "                print(f\"   - ✅ 隱私預算控制良好\")\n",
        "\n",
        "            if self.dp_reset_history:\n",
        "                print(f\"   - 重設歷史: {[r['round'] for r in self.dp_reset_history]}\")\n",
        "\n",
        "        # 保存結果\n",
        "        if self.training_history:\n",
        "            pd.DataFrame(self.training_history).to_csv(\n",
        "                os.path.join(self.config.output_dir, f'{self.config.experiment_name}_training_history.csv'), index=False)\n",
        "        if self.evaluation_results:\n",
        "            pd.DataFrame(self.evaluation_results).to_csv(\n",
        "                os.path.join(self.config.output_dir, f'{self.config.experiment_name}_evaluation_results.csv'), index=False)\n",
        "        if self.config.enable_dp and self.privacy_costs:\n",
        "            pd.DataFrame(self.privacy_costs).to_csv(\n",
        "                os.path.join(self.config.output_dir, f'{self.config.experiment_name}_privacy_costs.csv'), index=False)\n",
        "\n",
        "        # 保存詳細隱私日誌\n",
        "        if self.config.enable_dp and self.detailed_privacy_logs:\n",
        "            pd.DataFrame(self.detailed_privacy_logs).to_csv(\n",
        "                os.path.join(self.config.output_dir, f'{self.config.experiment_name}_detailed_privacy_logs.csv'), index=False)\n",
        "\n",
        "        # 保存重設歷史\n",
        "        if self.config.enable_dp and self.dp_reset_history:\n",
        "            pd.DataFrame(self.dp_reset_history).to_csv(\n",
        "                os.path.join(self.config.output_dir, f'{self.config.experiment_name}_dp_resets.csv'), index=False)\n",
        "\n",
        "        return pd.DataFrame(self.evaluation_results), pd.DataFrame(self.training_history)\n",
        "\n",
        "print(\"✅ Cell 7: ExperimentRunner（死循環修正版）定義完成。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnrYjd_IFbY6",
        "outputId": "91d33fa9-ddb1-4587-8e28-0da92a3d836e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 8A: 修正後的虛擬客戶端實驗函數已載入\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 8A: 🎬 修正後的虛擬客戶端實驗函數\n",
        "import time\n",
        "import gc\n",
        "from datetime import datetime\n",
        "\n",
        "def run_virtual_client_experiment(config_dict: dict, data_path: str):\n",
        "    \"\"\"\n",
        "    運行基於虛擬客戶端擴增的實驗\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    runner = None  # 初始化 runner 變數\n",
        "\n",
        "    try:\n",
        "        config = TrainingConfig(**config_dict)\n",
        "        print(f\"\\n{'='*15} 🔄 虛擬客戶端DP實驗: {config.experiment_name} {'='*15}\")\n",
        "\n",
        "        # 1. 準備原始數據\n",
        "        print(f\"📊 正在準備原始數據...\")\n",
        "        data_manager = DataManager(data_path, config.base_client_pairs)\n",
        "        original_trajectories = data_manager.get_client_trajectories()\n",
        "\n",
        "        print(f\"   - 原始數據源: {len(original_trajectories)} 個真實客戶端\")\n",
        "        for cid, traj in original_trajectories.items():\n",
        "            print(f\"     客戶端 {cid}: {len(traj)} 數據點\")\n",
        "\n",
        "        # 2. 生成虛擬客戶端\n",
        "        print(f\"\\n🔄 開始虛擬客戶端生成...\")\n",
        "        virtual_generator = VirtualClientGenerator(config)\n",
        "        all_trajectories = virtual_generator.generate_virtual_clients(original_trajectories)\n",
        "\n",
        "        # 3. 獲取生成統計\n",
        "        virtual_info = virtual_generator.get_virtual_client_info()\n",
        "        print(f\"\\n📈 虛擬客戶端生成統計:\")\n",
        "        print(f\"   - 真實客戶端: {virtual_info['base_clients']}\")\n",
        "        print(f\"   - 虛擬客戶端: {virtual_info['virtual_clients_generated']}\")\n",
        "        print(f\"   - 生成失敗: {virtual_info['failed_generations']}\")\n",
        "        print(f\"   - 總計客戶端: {virtual_info['total_clients']}\")\n",
        "        print(f\"   - 成功率: {virtual_info['generation_success_rate']:.2%}\")\n",
        "        print(f\"   - 分割方法: {virtual_info['split_method']}\")\n",
        "        print(f\"   - 總數據點: {virtual_info['total_data_points']:,}\")\n",
        "\n",
        "        # 4. 數據質量驗證\n",
        "        print(f\"\\n🔍 數據質量驗證:\")\n",
        "        for cid, traj in list(all_trajectories.items())[:5]:  # 顯示前5個的統計\n",
        "            if len(traj) > 0:\n",
        "                # 計算均值和標準差\n",
        "                if traj.ndim == 1:\n",
        "                    mean_val = np.mean(traj)\n",
        "                    std_val = np.std(traj)\n",
        "                else:\n",
        "                    mean_val = np.mean(traj, axis=0)\n",
        "                    std_val = np.std(traj, axis=0)\n",
        "\n",
        "                client_type = \"真實\" if cid < config.num_real_clients else \"虛擬\"\n",
        "\n",
        "                # 處理numpy陣列格式化問題\n",
        "                if isinstance(mean_val, np.ndarray):\n",
        "                    if mean_val.size == 1:\n",
        "                        mean_str = f\"{mean_val.item():.4f}\"\n",
        "                    else:\n",
        "                        mean_str = \"[\" + \",\".join([f\"{x:.4f}\" for x in mean_val.flatten()[:3]]) + \"]\"\n",
        "                else:\n",
        "                    mean_str = f\"{float(mean_val):.4f}\"\n",
        "\n",
        "                if isinstance(std_val, np.ndarray):\n",
        "                    if std_val.size == 1:\n",
        "                        std_str = f\"{std_val.item():.4f}\"\n",
        "                    else:\n",
        "                        std_str = \"[\" + \",\".join([f\"{x:.4f}\" for x in std_val.flatten()[:3]]) + \"]\"\n",
        "                else:\n",
        "                    std_str = f\"{float(std_val):.4f}\"\n",
        "\n",
        "                print(f\"   - 客戶端 {cid} ({client_type}): 長度={len(traj)}, 均值={mean_str}, 標差={std_str}\")\n",
        "\n",
        "        # 5. 更新配置以匹配生成的客戶端\n",
        "        config.num_clients = len(all_trajectories)\n",
        "        config.num_clients_to_select = min(config.num_clients_to_select, config.num_clients)\n",
        "\n",
        "        # 6. 創建兼容的客戶端配對\n",
        "        extended_client_pairs = []\n",
        "        for i in range(config.num_clients):\n",
        "            embb_id = i + 1\n",
        "            urllc_id = i + 2\n",
        "            extended_client_pairs.append((embb_id, urllc_id))\n",
        "        config.client_pairs = tuple(extended_client_pairs)\n",
        "\n",
        "        # 7. 差分隱私配置檢查\n",
        "        if config.enable_dp and config.mode != 'Centralized':\n",
        "            print(f\"\\n🛡️ 差分隱私配置:\")\n",
        "            print(f\"   - 目標ε: {config.dp_target_epsilon}\")\n",
        "            print(f\"   - 批次大小: {config.batch_size}\")\n",
        "            print(f\"   - 噪聲乘數: {config.dp_noise_multiplier}\")\n",
        "            print(f\"   - 客戶端數量: {config.num_clients} (大幅增加)\")\n",
        "            print(f\"   - 每輪參與: {config.num_clients_to_select}\")\n",
        "            print(f\"   - 重設機制: {'啟用' if config.enable_dp_reset else '禁用'}\")\n",
        "\n",
        "        # 8. 運行實驗\n",
        "        print(f\"\\n🚀 開始聯邦學習實驗...\")\n",
        "        runner = ExperimentRunner(config, data_manager, all_trajectories, config.client_pairs)\n",
        "        eval_res, history_res = runner.run()\n",
        "\n",
        "        execution_time = (time.time() - start_time) / 60\n",
        "        print(f\"\\n⏱️ 實驗完成時間: {execution_time:.2f} 分鐘\")\n",
        "\n",
        "        # 9. 結果分析\n",
        "        print(f\"\\n✅ 實驗結果摘要:\")\n",
        "        if not eval_res.empty and len(eval_res) > 0:\n",
        "            avg_global_reward = eval_res['reward_global'].mean()\n",
        "            avg_personalized_reward = eval_res['reward_personalized'].mean()\n",
        "            avg_pfl_reward = eval_res['reward_pfl_finetuned'].mean()\n",
        "\n",
        "            print(f\"   - 平均全域獎勵: {avg_global_reward:.4f}\")\n",
        "            print(f\"   - 平均個人化獎勵: {avg_personalized_reward:.4f}\")\n",
        "            print(f\"   - 平均PFL微調獎勵: {avg_pfl_reward:.4f}\")\n",
        "            print(f\"   - 個人化提升: {((avg_personalized_reward/avg_global_reward-1)*100):.2f}%\")\n",
        "        else:\n",
        "            print(f\"   - ⚠️ 評估結果為空，可能實驗未完成\")\n",
        "            avg_global_reward = avg_personalized_reward = avg_pfl_reward = 0.0\n",
        "\n",
        "        # 10. 隱私分析 - 修正關鍵錯誤\n",
        "        privacy_stats = None\n",
        "        if config.enable_dp and config.mode != 'Centralized' and runner is not None:\n",
        "            print(f\"\\n🛡️ 虛擬客戶端隱私分析:\")\n",
        "            print(f\"   - 數據獨立性: ✅ 時間分割確保非重疊\")\n",
        "            print(f\"   - 隱私保護: ✅ DP噪聲 (σ={config.noise_injection_std})\")\n",
        "            print(f\"   - 統計真實性: ✅ 保持原始分佈特性\")\n",
        "\n",
        "            # 安全地獲取隱私預算信息\n",
        "            consumed_budget = getattr(runner, 'consumed_privacy_budget', 0.0)\n",
        "            dp_reset_history = getattr(runner, 'dp_reset_history', [])\n",
        "            privacy_budget_exceeded = getattr(runner, 'privacy_budget_exceeded', False)\n",
        "\n",
        "            print(f\"   - 最終ε消耗: {consumed_budget:.4f}\")\n",
        "            print(f\"   - 預算使用率: {(consumed_budget/config.dp_target_epsilon*100):.1f}%\")\n",
        "            print(f\"   - 重設次數: {len(dp_reset_history)}\")\n",
        "\n",
        "            # 隱私效率分析\n",
        "            if consumed_budget > 0 and avg_global_reward > 0:\n",
        "                privacy_efficiency = avg_global_reward / consumed_budget\n",
        "                print(f\"   - 隱私效率: {privacy_efficiency:.4f} (獎勵/ε)\")\n",
        "\n",
        "            if privacy_budget_exceeded:\n",
        "                print(f\"   - ⚠️ 隱私預算已超支 - 啟用重設機制管控\")\n",
        "            else:\n",
        "                print(f\"   - ✅ 隱私預算控制良好\")\n",
        "\n",
        "            privacy_stats = {\n",
        "                'consumed_epsilon': consumed_budget,\n",
        "                'reset_count': len(dp_reset_history)\n",
        "            }\n",
        "\n",
        "        # 11. 保存詳細結果\n",
        "        if not eval_res.empty and len(eval_res) > 0:\n",
        "            eval_summary = eval_res[['client_id', 'reward_global', 'reward_personalized', 'reward_pfl_finetuned']].round(4)\n",
        "            print(f\"\\n📊 詳細結果 (前10個客戶端):\")\n",
        "            print(eval_summary.head(10).to_string(index=False))\n",
        "\n",
        "        # 12. 清理資源\n",
        "        del runner, data_manager, virtual_generator, all_trajectories\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        return True, {\n",
        "            'virtual_info': virtual_info,\n",
        "            'execution_time': execution_time,\n",
        "            'avg_rewards': {\n",
        "                'global': avg_global_reward,\n",
        "                'personalized': avg_personalized_reward,\n",
        "                'pfl': avg_pfl_reward\n",
        "            },\n",
        "            'privacy_stats': privacy_stats\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        execution_time = (time.time() - start_time) / 60\n",
        "        print(f\"\\n❌ 虛擬客戶端實驗失敗: {config_dict.get('experiment_name')}\")\n",
        "        print(f\"⏱️ 失敗時間: {execution_time:.2f} 分鐘\")\n",
        "        print(f\"🔍 錯誤詳情: {str(e)}\")\n",
        "        import traceback\n",
        "        print(f\"📋 錯誤堆疊: {traceback.format_exc()}\")\n",
        "\n",
        "        # 清理資源\n",
        "        if runner is not None:\n",
        "            del runner\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        return False, None\n",
        "\n",
        "print(\"✅ Cell 8A: 修正後的虛擬客戶端實驗函數已載入\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfCeRCdAFe5V",
        "outputId": "b9fa525c-2d40-4b73-b29f-037665aed612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎮 GPU 檢測: NVIDIA L4\n",
            "📊 總記憶體: 23.8 GB\n",
            "🔧 計算能力: 8.x\n",
            "💻 可用CPU數: 12\n",
            "🧹 GPU環境設定完成\n",
            "🎮 GPU 可用: NVIDIA L4\n",
            "📊 GPU 記憶體: 23.8 GB\n",
            "Mounted at /content/drive\n",
            "🔗 Google Drive 掛載成功\n",
            "📁 數據路徑: /content/drive/MyDrive/FRL_Slicing_Sim/kpi_traces_final_robust0.parquet\n",
            "📁 輸出目錄: /content/drive/MyDrive/FRL_Slicing_Sim/outputs_virtual_clients_gpu\n",
            "\n",
            "🎯 實驗計劃:\n",
            "   - 測試模式: ['ClusteredFL', 'FedProx', 'FedAvg']\n",
            "   - 隨機種子: [42]\n",
            "   - 總實驗數: 3\n",
            "\n",
            "✅ 環境設定完成，準備執行實驗\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 8B: 🔧 環境設定與初始化（修正版）\n",
        "import os\n",
        "import time\n",
        "\n",
        "# GPU環境設定\n",
        "setup_gpu_environment()\n",
        "\n",
        "# 確保GPU被正確使用\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"🎮 GPU 可用: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"📊 GPU 記憶體: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    # 不要設定預設張量類型，這會導致設備不匹配問題\n",
        "    # torch.set_default_tensor_type('torch.cuda.FloatTensor')  # 移除這行\n",
        "else:\n",
        "    print(\"⚠️ GPU 不可用，使用 CPU 模式\")\n",
        "\n",
        "# 環境路徑設定\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_WORK_DIR = \"/content/drive/MyDrive/FRL_Slicing_Sim\"\n",
        "    print(\"🔗 Google Drive 掛載成功\")\n",
        "except ImportError:\n",
        "    BASE_WORK_DIR = \"./FRL_Slicing_Sim\"\n",
        "    print(\"💻 本地環境模式\")\n",
        "\n",
        "os.makedirs(BASE_WORK_DIR, exist_ok=True)\n",
        "DATA_PATH = os.path.join(BASE_WORK_DIR, \"kpi_traces_final_robust0.parquet\")\n",
        "BASE_OUTPUT_DIR = os.path.join(BASE_WORK_DIR, \"outputs_virtual_clients_gpu\")\n",
        "print(f\"📁 數據路徑: {DATA_PATH}\")\n",
        "print(f\"📁 輸出目錄: {BASE_OUTPUT_DIR}\")\n",
        "\n",
        "# 實驗配置\n",
        "MODES_TO_RUN = [\"ClusteredFL\", \"FedProx\", \"FedAvg\"]\n",
        "SEEDS = [42]\n",
        "\n",
        "print(f\"\\n🎯 實驗計劃:\")\n",
        "print(f\"   - 測試模式: {MODES_TO_RUN}\")\n",
        "print(f\"   - 隨機種子: {SEEDS}\")\n",
        "print(f\"   - 總實驗數: {len(MODES_TO_RUN) * len(SEEDS)}\")\n",
        "\n",
        "# 全局結果存儲\n",
        "experiment_results = []\n",
        "\n",
        "print(\"\\n✅ 環境設定完成，準備執行實驗\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "adf6d4d8b8bb4e0a94833044bd43d7f3",
            "90cb0f7ce15f4320bf1533860a33ba72",
            "79233c6a328f43d38bd153fb7be6ac53",
            "8177404e6c3e49fcb7a282fc9dc511aa",
            "23fbd48c5c6240e09d8b90cb16e69f50",
            "3e08b6bb93964764abb8a92b0bf11697",
            "fba740bc81ea45e19f28784ceeae705a",
            "641052e8de5a4bf8a800409f33944ca9",
            "50037d1d410442b8aeddd1c232946536",
            "3b1351faa78e4e9ba7337bfa9657cf2f",
            "901a2caee05d45d8b91a9d4db2b952f4",
            "7d3d1404483f441db96027bb518bd35d",
            "cde168f1fb1a4c8dac2752e3df87020a",
            "09dd428dd809495c89c2c2c1cc35f6c5",
            "e9fbf4d213f24882bbf9c2d92bbec63e",
            "4538927fab94458191b9cd1c2ba3db54",
            "c2a7a40f85974863bd7830c990683d4c",
            "296ba0f6a70e4592affde73d0bacd733",
            "fdafbc16c86f422c895f56a4342b72e9",
            "25c9727ea9f642b788851b2dbe66feb7",
            "5d9153f821734f3e827f175ec86ed42d",
            "f3922222487a40b3b940e4b5132ae615"
          ]
        },
        "id": "NSGJYd__FhxG",
        "outputId": "9c9438cf-291f-4cba-8025-bb6445b621d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "🚀 開始執行實驗 1: ClusteredFL\n",
            "============================================================\n",
            "🔧 配置摘要:\n",
            "   - 客戶端: 12 (真實:3, 虛擬:9)\n",
            "   - 批次大小: 128\n",
            "   - FedProx μ: 0.15\n",
            "   - DP噪聲: 0.3\n",
            "   - 使用裝置: cuda\n",
            "🚀 L4 GPU檢測到，啟用大批次優化配置\n",
            "🔄 虛擬客戶端配置:\n",
            "   - 真實基站對: 3 (((1, 2), (3, 7), (5, 6)))\n",
            "   - 擴增因子: 4\n",
            "   - 總客戶端數: 12 (真實: 3, 虛擬: 9)\n",
            "   - 每輪參與: 8\n",
            "🛡️ 差分隱私已啟用（GDP/PRV Accountant + Poisson Sampling）\n",
            "   - 目標隱私預算: ε=8.0\n",
            "   - 批次大小: 128\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 重設機制: 啟用\n",
            "\n",
            "=============== 🔄 虛擬客戶端DP實驗: ClusteredFL_virtual_clients_s42 ===============\n",
            "📊 正在準備原始數據...\n",
            "\n",
            "[DataManager] 正在從 /content/drive/MyDrive/FRL_Slicing_Sim/kpi_traces_final_robust0.parquet 讀取數據...\n",
            "\n",
            "==================== DataManager 啟動前預檢查 ====================\n",
            "✅ 清理後的欄位列表 (共 38 個):\n",
            "   - 吞吐量欄位成功匹配: 'throughput_dl_mbps'\n",
            "   - 延遲/緩衝區欄位成功匹配: 'buffer_occupancy_dl_bytes'\n",
            "   - 可用BS節點: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
            "   - 客戶端BS配對驗證通過\n",
            "=================================================================\n",
            "\n",
            "[DataManager] 正在為每個客戶端生成數據軌跡...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "處理客戶端數據:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adf6d4d8b8bb4e0a94833044bd43d7f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   - 客戶端 0: 10568 個時間步\n",
            "   - 客戶端 1: 6918 個時間步\n",
            "   - 客戶端 2: 8756 個時間步\n",
            "\n",
            "[DataManager] 數據處理完成！成功為 3 / 3 個客戶端創建了環境。\n",
            "   - 原始數據源: 3 個真實客戶端\n",
            "     客戶端 0: 10568 數據點\n",
            "     客戶端 1: 6918 數據點\n",
            "     客戶端 2: 8756 數據點\n",
            "\n",
            "🔄 開始虛擬客戶端生成...\n",
            "\n",
            "🔄 開始生成虛擬客戶端...\n",
            "   - 原始客戶端數: 3\n",
            "   - 目標總客戶端數: 12\n",
            "[真實客戶端 0] 基站對: (1, 2) - 數據點: 10568\n",
            "[真實客戶端 1] 基站對: (3, 7) - 數據點: 6918\n",
            "[真實客戶端 2] 基站對: (5, 6) - 數據點: 8756\n",
            "[虛擬客戶端 3] 基於基站對 (1, 2) - 變體 1 - 數據點: 2113\n",
            "[虛擬客戶端 4] 基於基站對 (1, 2) - 變體 2 - 數據點: 2113\n",
            "[虛擬客戶端 5] 基於基站對 (1, 2) - 變體 3 - 數據點: 2113\n",
            "[虛擬客戶端 6] 基於基站對 (1, 2) - 變體 4 - 數據點: 2113\n",
            "[虛擬客戶端 7] 基於基站對 (3, 7) - 變體 1 - 數據點: 1383\n",
            "[虛擬客戶端 8] 基於基站對 (3, 7) - 變體 2 - 數據點: 1383\n",
            "[虛擬客戶端 9] 基於基站對 (3, 7) - 變體 3 - 數據點: 1383\n",
            "[虛擬客戶端 10] 基於基站對 (3, 7) - 變體 4 - 數據點: 1383\n",
            "[虛擬客戶端 11] 基於基站對 (5, 6) - 變體 1 - 數據點: 1751\n",
            "[虛擬客戶端 12] 基於基站對 (5, 6) - 變體 2 - 數據點: 1751\n",
            "[虛擬客戶端 13] 基於基站對 (5, 6) - 變體 3 - 數據點: 1751\n",
            "[虛擬客戶端 14] 基於基站對 (5, 6) - 變體 4 - 數據點: 1751\n",
            "\n",
            "✅ 虛擬客戶端生成完成:\n",
            "   - 真實客戶端: 3\n",
            "   - 虛擬客戶端: 12\n",
            "   - 失敗生成: 0\n",
            "   - 總客戶端: 15\n",
            "   - 總數據點: 47230\n",
            "\n",
            "📈 虛擬客戶端生成統計:\n",
            "   - 真實客戶端: 3\n",
            "   - 虛擬客戶端: 12\n",
            "   - 生成失敗: 0\n",
            "   - 總計客戶端: 15\n",
            "   - 成功率: 100.00%\n",
            "   - 分割方法: sliding_window\n",
            "   - 總數據點: 47,230\n",
            "\n",
            "🔍 數據質量驗證:\n",
            "   - 客戶端 0 (真實): 長度=10568, 均值=[2.4685,116036.3125,0.1131], 標差=[1.3085,86761.3594,0.0395]\n",
            "   - 客戶端 1 (真實): 長度=6918, 均值=[2.6377,51258.6523,0.0941], 標差=[1.7496,81026.1250,0.0542]\n",
            "   - 客戶端 2 (真實): 長度=8756, 均值=[2.0969,102297.3906,0.1085], 標差=[1.6933,88073.7344,0.0445]\n",
            "   - 客戶端 3 (虛擬): 長度=2113, 均值=[1.3988,168987.1962,0.1124], 標差=[0.5423,44658.8255,0.0379]\n",
            "   - 客戶端 4 (虛擬): 長度=2113, 均值=[2.4551,119922.5926,0.1076], 標差=[1.2283,83823.1913,0.0456]\n",
            "\n",
            "🛡️ 差分隱私配置:\n",
            "   - 目標ε: 8.0\n",
            "   - 批次大小: 128\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 客戶端數量: 15 (大幅增加)\n",
            "   - 每輪參與: 8\n",
            "   - 重設機制: 啟用\n",
            "\n",
            "🚀 開始聯邦學習實驗...\n",
            "[FLServer] 初始化完成 - 聚類數: 3\n",
            "\n",
            "[ExperimentRunner] 正在初始化客戶端環境與代理...\n",
            "🛡️ 差分隱私模式啟用（死循環防護版）：\n",
            "   - 總隱私預算上限: ε=8.0\n",
            "   - 重設閾值: ε=12.0\n",
            "   - 死循環防護: 每輪最多3次重設\n",
            "   - 客戶端數量: 15\n",
            "[C-0] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.012112\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-1] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.018502\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-2] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.014619\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-3] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.060577\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-4] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.060577\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-5] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.060577\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-6] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.060577\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-7] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.092552\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-8] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.092552\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-9] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.092552\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-10] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.092552\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-11] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.073101\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-12] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.073101\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-13] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.073101\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "[C-14] 🛡️ 初始化差分隱私引擎...\n",
            "   - 嘗試 Accountant: GDP\n",
            "   - Sample Rate: 0.073101\n",
            "   - ✅ 差分隱私引擎初始化成功\n",
            "   - 噪聲乘數: 0.3\n",
            "   - 梯度裁剪: 1.0\n",
            "   - Poisson採樣: True\n",
            "✅ 配置已保存至: /content/drive/MyDrive/FRL_Slicing_Sim/outputs_virtual_clients_gpu/seed_42/ClusteredFL/ClusteredFL_virtual_clients_s42_config.json\n",
            "[ExperimentRunner] 初始化完成。\n",
            "\n",
            "==================== 🏃♂️ 開始執行實驗: ClusteredFL_virtual_clients_s42 (ClusteredFL) ====================\n",
            "\n",
            "[模式] 執行聯邦式訓練 (ClusteredFL)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ClusteredFL Training:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d3d1404483f441db96027bb518bd35d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 開始 Round 1/15 ---\n",
            "參與客戶端: [np.int64(10), np.int64(13), np.int64(12), np.int64(5), np.int64(11), np.int64(6), np.int64(0), np.int64(9)]\n",
            "[FLServer] 客戶端 10: 模型分發成功\n",
            "  - DP模型: True\n",
            "  - 原始鍵數: 6\n",
            "  - 轉換後鍵數: 6\n",
            "  - 鍵名範例: 0.weight → _module.0.weight\n",
            "[FLServer] 模型分發完成: 成功 8/8\n",
            "[C-10] 開始訓練 (3 episodes)...\n",
            "[C-10] ⚠️ 隱私成本計算失敗: f(a) and f(b) must have different signs\n",
            "   🔄 使用估算值: ε ≈ 7.5000 (基於 750 步)\n",
            "[C-10] 完成 - Loss: 30403515.2819, Reward: 173.9722, ε: 7.5000\n",
            "[C-13] 開始訓練 (3 episodes)...\n",
            "[C-13] ⚠️ 隱私成本計算失敗: f(a) and f(b) must have different signs\n",
            "   🔄 使用估算值: ε ≈ 7.5000 (基於 750 步)\n",
            "[C-13] 完成 - Loss: 13783617.2534, Reward: 343.8890, ε: 7.5000\n",
            "[C-12] 開始訓練 (3 episodes)...\n",
            "[C-12] ⚠️ 隱私成本計算失敗: f(a) and f(b) must have different signs\n",
            "   🔄 使用估算值: ε ≈ 7.5000 (基於 750 步)\n",
            "[C-12] 完成 - Loss: 6748539.4390, Reward: 419.6740, ε: 7.5000\n",
            "[C-5] 開始訓練 (3 episodes)...\n",
            "[C-5] ⚠️ 隱私成本計算失敗: f(a) and f(b) must have different signs\n",
            "   🔄 使用估算值: ε ≈ 7.5000 (基於 750 步)\n",
            "[C-5] 完成 - Loss: 72471.2287, Reward: 408.4791, ε: 7.5000\n",
            "[C-11] 開始訓練 (3 episodes)...\n",
            "[C-11] ⚠️ 隱私成本計算失敗: f(a) and f(b) must have different signs\n",
            "   🔄 使用估算值: ε ≈ 7.5000 (基於 750 步)\n",
            "[C-11] 完成 - Loss: 8006281.0162, Reward: 165.4049, ε: 7.5000\n",
            "[C-6] 開始訓練 (3 episodes)...\n",
            "[C-6] ⚠️ 隱私成本計算失敗: f(a) and f(b) must have different signs\n",
            "   🔄 使用估算值: ε ≈ 7.5000 (基於 750 步)\n",
            "[C-6] 完成 - Loss: 32648415.8128, Reward: 208.5418, ε: 7.5000\n",
            "[C-0] 開始訓練 (3 episodes)...\n",
            "[C-0] ⚠️ 隱私成本計算失敗: f(a) and f(b) must have different signs\n",
            "   🔄 使用估算值: ε ≈ 7.5000 (基於 750 步)\n",
            "[C-0] 完成 - Loss: 5599493.1748, Reward: 353.2366, ε: 7.5000\n",
            "[C-9] 開始訓練 (3 episodes)...\n",
            "[C-9] ⚠️ 隱私成本計算失敗: f(a) and f(b) must have different signs\n",
            "   🔄 使用估算值: ε ≈ 7.5000 (基於 750 步)\n",
            "[C-9] 完成 - Loss: 8158559.5191, Reward: 209.6781, ε: 7.5000\n",
            "檢查隱私預算...\n",
            "Round 1 完成 - {'reward': '285.36', 'loss': '13177611.5907', 'ε_used': '7.500', 'resets': '0'}\n",
            "\n",
            "--- 開始 Round 2/15 ---\n",
            "參與客戶端: [np.int64(1), np.int64(13), np.int64(4), np.int64(5), np.int64(6), np.int64(3), np.int64(14), np.int64(9)]\n",
            "[FLServer] 客戶端 1: 模型分發成功\n",
            "  - DP模型: True\n",
            "  - 原始鍵數: 6\n",
            "  - 轉換後鍵數: 6\n",
            "  - 鍵名範例: 0.weight → _module.0.weight\n",
            "[FLServer] 模型分發完成: 成功 8/8\n",
            "[C-1] 開始訓練 (3 episodes)...\n",
            "[C-1] ⚠️ 隱私成本計算失敗: f(a) and f(b) must have different signs\n",
            "   🔄 使用估算值: ε ≈ 7.5000 (基於 750 步)\n",
            "[C-1] 完成 - Loss: 59689.1191, Reward: 335.2505, ε: 7.5000\n",
            "[C-13] 開始訓練 (3 episodes)...\n"
          ]
        }
      ],
      "source": [
        "# @title Cell 8C: 🚀 實驗 1 - ClusteredFL（修正版）\n",
        "print(\"=\"*60)\n",
        "print(\"🚀 開始執行實驗 1: ClusteredFL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 不要設定全局張量類型\n",
        "# if torch.cuda.is_available():\n",
        "#     torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "mode = \"ClusteredFL\"\n",
        "seed = SEEDS[0]\n",
        "exp_name = f\"{mode}_virtual_clients_s{seed}\"\n",
        "output_dir = os.path.join(BASE_OUTPUT_DIR, f\"seed_{seed}\", mode)\n",
        "\n",
        "# 虛擬客戶端實驗配置\n",
        "config_params = {\n",
        "    \"experiment_name\": exp_name,\n",
        "    \"output_dir\": output_dir,\n",
        "    \"mode\": mode,\n",
        "    \"random_seed\": seed,\n",
        "\n",
        "    # 虛擬客戶端擴增設定\n",
        "    \"base_client_pairs\": ((1, 2), (3, 7), (5, 6)),\n",
        "    \"virtual_expansion_factor\": 4,\n",
        "    \"total_clients\": 12,\n",
        "    \"num_clients_to_select\": 8,\n",
        "\n",
        "    # 訓練參數優化\n",
        "    \"comm_rounds\": 15,\n",
        "    \"local_episodes_per_round\": 3,\n",
        "    \"steps_per_episode\": 500,\n",
        "    \"batch_size\": 128,\n",
        "    \"memory_capacity\": 50000,\n",
        "    \"replay_batches_per_call\": 3,\n",
        "\n",
        "    # 聯邦學習參數\n",
        "    \"fedprox_mu\": 0.15,\n",
        "    \"num_clusters\": 3,\n",
        "    \"cluster_update_freq\": 8,\n",
        "\n",
        "    # 虛擬客戶端生成參數\n",
        "    \"temporal_split_method\": \"sliding_window\",\n",
        "    \"noise_injection_std\": 0.03,\n",
        "    \"feature_augmentation\": True,\n",
        "    \"cross_validation_split\": True,\n",
        "\n",
        "    # 差分隱私參數\n",
        "    \"enable_dp\": True,\n",
        "    \"dp_target_epsilon\": 8.0,\n",
        "    \"dp_target_delta\": 1e-5,\n",
        "    \"dp_noise_multiplier\": 0.3,\n",
        "    \"dp_max_grad_norm\": 1.0,\n",
        "    \"enable_dp_reset\": True,\n",
        "    \"dp_reset_threshold_multiplier\": 1.5,\n",
        "\n",
        "    # 其他參數\n",
        "    \"lr\": 1e-4,\n",
        "    \"gamma\": 0.99,\n",
        "    \"enable_heterogeneity\": True,\n",
        "    \"enable_compression\": True,\n",
        "    \"use_pfl_finetune\": True,\n",
        "    # GPU 優化設定\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "}\n",
        "\n",
        "print(f\"🔧 配置摘要:\")\n",
        "print(f\"   - 客戶端: {config_params['total_clients']} (真實:3, 虛擬:9)\")\n",
        "print(f\"   - 批次大小: {config_params['batch_size']}\")\n",
        "print(f\"   - FedProx μ: {config_params['fedprox_mu']}\")\n",
        "print(f\"   - DP噪聲: {config_params['dp_noise_multiplier']}\")\n",
        "print(f\"   - 使用裝置: {config_params['device']}\")\n",
        "\n",
        "# 執行實驗\n",
        "start_time = time.time()\n",
        "success, result_info = run_virtual_client_experiment(config_params, DATA_PATH)\n",
        "\n",
        "if success:\n",
        "    experiment_results.append({\n",
        "        'seed': seed,\n",
        "        'mode': mode,\n",
        "        'success': True,\n",
        "        'result_info': result_info\n",
        "    })\n",
        "    print(f\"\\n✅ {mode} 實驗成功\")\n",
        "\n",
        "    # 顯示關鍵指標\n",
        "    if result_info and 'avg_rewards' in result_info:\n",
        "        rewards = result_info['avg_rewards']\n",
        "        print(f\"   - 全域獎勵: {rewards['global']:.4f}\")\n",
        "        print(f\"   - 個人化獎勵: {rewards['personalized']:.4f}\")\n",
        "        if result_info.get('privacy_stats'):\n",
        "            privacy = result_info['privacy_stats']\n",
        "            print(f\"   - ε消耗: {privacy['consumed_epsilon']:.4f}\")\n",
        "            print(f\"   - 重設次數: {privacy['reset_count']}\")\n",
        "else:\n",
        "    experiment_results.append({\n",
        "        'seed': seed,\n",
        "        'mode': mode,\n",
        "        'success': False,\n",
        "        'result_info': None\n",
        "    })\n",
        "    print(f\"\\n❌ {mode} 實驗失敗\")\n",
        "\n",
        "execution_time = (time.time() - start_time) / 60\n",
        "print(f\"\\n⏱️ ClusteredFL 實驗執行時間: {execution_time:.2f} 分鐘\")\n",
        "\n",
        "# 清理資源\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"實驗 1 完成\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "OAahBs7oFkqO"
      },
      "outputs": [],
      "source": [
        "# @title Cell 8D: 🚀 實驗 2 - FedProx（最佳化版本）\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "# 假設以下變數已在您的環境中定義\n",
        "# SEEDS = [some_seed_value]\n",
        "# BASE_OUTPUT_DIR = \"some/path\"\n",
        "# DATA_PATH = \"some/data/path\"\n",
        "# experiment_results = []\n",
        "# def run_virtual_client_experiment(config, data_path):\n",
        "#     # 這是實驗執行函數的佔位符\n",
        "#     print(\"執行實驗...\")\n",
        "#     # 模擬一個成功的執行結果\n",
        "#     return True, {\n",
        "#         'avg_rewards': {'global': 0.95, 'personalized': 0.98},\n",
        "#         'privacy_stats': {'consumed_epsilon': 7.5, 'reset_count': 2}\n",
        "#     }\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"🚀 開始執行實驗 2: FedProx\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 最佳化實踐：不再設定全局預設張量類型。\n",
        "# 設備（CPU/GPU）的管理應由實驗邏輯內部透過 'device' 參數明確處理。\n",
        "\n",
        "mode = \"FedProx\"\n",
        "seed = SEEDS[0]\n",
        "exp_name = f\"{mode}_virtual_clients_s{seed}\"\n",
        "output_dir = os.path.join(BASE_OUTPUT_DIR, f\"seed_{seed}\", mode)\n",
        "\n",
        "# FedProx 專用配置\n",
        "config_params = {\n",
        "    \"experiment_name\": exp_name,\n",
        "    \"output_dir\": output_dir,\n",
        "    \"mode\": mode,\n",
        "    \"random_seed\": seed,\n",
        "\n",
        "    # 虛擬客戶端擴增設定\n",
        "    \"base_client_pairs\": ((1, 2), (3, 7), (5, 6)),\n",
        "    \"virtual_expansion_factor\": 4,\n",
        "    \"total_clients\": 12,\n",
        "    \"num_clients_to_select\": 8,\n",
        "\n",
        "    # 訓練參數優化\n",
        "    \"comm_rounds\": 15, # 25\n",
        "    \"local_episodes_per_round\": 3, # 5\n",
        "    \"steps_per_episode\": 500, # 300\n",
        "    \"batch_size\": 128,\n",
        "    \"memory_capacity\": 50000,\n",
        "    \"replay_batches_per_call\": 3,\n",
        "\n",
        "    # 聯邦學習參數\n",
        "    \"fedprox_mu\": 0.15,  # FedProx 的關鍵參數\n",
        "    \"num_clusters\": 3,   # 注意：此參數在FedProx中可能不會被使用，但保留以維持結構一致性\n",
        "    \"cluster_update_freq\": 8, # 注意：此參數在FedProx中可能不會被使用\n",
        "\n",
        "    # 虛擬客戶端生成參數\n",
        "    \"temporal_split_method\": \"sliding_window\",\n",
        "    \"noise_injection_std\": 0.03,\n",
        "    \"feature_augmentation\": True,\n",
        "    \"cross_validation_split\": True,\n",
        "\n",
        "    # 差分隱私參數\n",
        "    \"enable_dp\": True,\n",
        "    \"dp_target_epsilon\": 8.0,\n",
        "    \"dp_target_delta\": 1e-5,\n",
        "    \"dp_noise_multiplier\": 0.3,\n",
        "    \"dp_max_grad_norm\": 1.0,\n",
        "    \"enable_dp_reset\": True,\n",
        "    \"dp_reset_threshold_multiplier\": 1.5,\n",
        "\n",
        "    # 其他參數\n",
        "    \"lr\": 1e-4,\n",
        "    \"gamma\": 0.99,\n",
        "    \"enable_heterogeneity\": True,\n",
        "    \"enable_compression\": True,\n",
        "    \"use_pfl_finetune\": True,\n",
        "    # 透過此參數明確控制設備，是更佳的實踐方式\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "}\n",
        "\n",
        "print(f\"🔧 配置摘要:\")\n",
        "print(f\"   - 客戶端: {config_params['total_clients']} (真實:3, 虛擬:9)\")\n",
        "print(f\"   - 批次大小: {config_params['batch_size']}\")\n",
        "print(f\"   - FedProx μ: {config_params['fedprox_mu']}\")\n",
        "print(f\"   - DP噪聲: {config_params['dp_noise_multiplier']}\")\n",
        "print(f\"   - 使用裝置: {config_params['device']}\")\n",
        "\n",
        "# 執行實驗\n",
        "start_time = time.time()\n",
        "success, result_info = run_virtual_client_experiment(config_params, DATA_PATH)\n",
        "\n",
        "if success:\n",
        "    experiment_results.append({\n",
        "        'seed': seed,\n",
        "        'mode': mode,\n",
        "        'success': True,\n",
        "        'result_info': result_info\n",
        "    })\n",
        "    print(f\"\\n✅ {mode} 實驗成功\")\n",
        "\n",
        "    # 顯示關鍵指標\n",
        "    if result_info and 'avg_rewards' in result_info:\n",
        "        rewards = result_info['avg_rewards']\n",
        "        print(f\"   - 全域獎勵: {rewards['global']:.4f}\")\n",
        "        print(f\"   - 個人化獎勵: {rewards['personalized']:.4f}\")\n",
        "        if result_info.get('privacy_stats'):\n",
        "            privacy = result_info['privacy_stats']\n",
        "            print(f\"   - ε消耗: {privacy['consumed_epsilon']:.4f}\")\n",
        "            print(f\"   - 重設次數: {privacy['reset_count']}\")\n",
        "else:\n",
        "    experiment_results.append({\n",
        "        'seed': seed,\n",
        "        'mode': mode,\n",
        "        'success': False,\n",
        "        'result_info': None\n",
        "    })\n",
        "    print(f\"\\n❌ {mode} 實驗失敗\")\n",
        "\n",
        "execution_time = (time.time() - start_time) / 60\n",
        "print(f\"\\n⏱️ FedProx 實驗執行時間: {execution_time:.2f} 分鐘\")\n",
        "\n",
        "# 清理資源\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# 最佳化實踐：由於未在全局設定預設張量類型，此處也無需重設。\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"實驗 2 完成\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RjXyvnZOFnoP"
      },
      "outputs": [],
      "source": [
        "# @title Cell 8E: 🚀 實驗 3 - FedAvg（最佳化版本）\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "# 假設以下變數已在您的環境中定義\n",
        "# SEEDS = [some_seed_value]\n",
        "# BASE_OUTPUT_DIR = \"some/path\"\n",
        "# DATA_PATH = \"some/data/path\"\n",
        "# experiment_results = []\n",
        "# def run_virtual_client_experiment(config, data_path):\n",
        "#     # 這是實驗執行函數的佔位符\n",
        "#     print(\"執行實驗...\")\n",
        "#     # 模擬一個成功的執行結果\n",
        "#     return True, {\n",
        "#         'avg_rewards': {'global': 0.93, 'personalized': 0.96},\n",
        "#         'privacy_stats': {'consumed_epsilon': 7.6, 'reset_count': 2}\n",
        "#     }\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"🚀 開始執行實驗 3: FedAvg\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 最佳化實踐：不再設定全局預設張量類型。\n",
        "# 設備（CPU/GPU）的管理應由實驗邏輯內部透過 'device' 參數明確處理。\n",
        "\n",
        "mode = \"FedAvg\"\n",
        "seed = SEEDS[0]\n",
        "exp_name = f\"{mode}_virtual_clients_s{seed}\"\n",
        "output_dir = os.path.join(BASE_OUTPUT_DIR, f\"seed_{seed}\", mode)\n",
        "\n",
        "# FedAvg 專用配置（fedprox_mu 設為 0）\n",
        "config_params = {\n",
        "    \"experiment_name\": exp_name,\n",
        "    \"output_dir\": output_dir,\n",
        "    \"mode\": mode,\n",
        "    \"random_seed\": seed,\n",
        "\n",
        "    # 虛擬客戶端擴增設定\n",
        "    \"base_client_pairs\": ((1, 2), (3, 7), (5, 6)),\n",
        "    \"virtual_expansion_factor\": 4,\n",
        "    \"total_clients\": 12,\n",
        "    \"num_clients_to_select\": 8,\n",
        "\n",
        "    # 訓練參數優化\n",
        "    \"comm_rounds\": 15,\n",
        "    \"local_episodes_per_round\": 3,\n",
        "    \"steps_per_episode\": 500,\n",
        "    \"batch_size\": 128,\n",
        "    \"memory_capacity\": 50000,\n",
        "    \"replay_batches_per_call\": 3,\n",
        "\n",
        "    # 聯邦學習參數\n",
        "    \"fedprox_mu\": 0.0,  # FedAvg 不使用 proximal term\n",
        "    \"num_clusters\": 3,   # 注意：此參數在FedAvg中不會被使用\n",
        "    \"cluster_update_freq\": 8, # 注意：此參數在FedAvg中不會被使用\n",
        "\n",
        "    # 虛擬客戶端生成參數\n",
        "    \"temporal_split_method\": \"sliding_window\",\n",
        "    \"noise_injection_std\": 0.03,\n",
        "    \"feature_augmentation\": True,\n",
        "    \"cross_validation_split\": True,\n",
        "\n",
        "    # 差分隱私參數\n",
        "    \"enable_dp\": True,\n",
        "    \"dp_target_epsilon\": 8.0,\n",
        "    \"dp_target_delta\": 1e-5,\n",
        "    \"dp_noise_multiplier\": 0.3,\n",
        "    \"dp_max_grad_norm\": 1.0,\n",
        "    \"enable_dp_reset\": True,\n",
        "    \"dp_reset_threshold_multiplier\": 1.5,\n",
        "\n",
        "    # 其他參數\n",
        "    \"lr\": 1e-4,\n",
        "    \"gamma\": 0.99,\n",
        "    \"enable_heterogeneity\": True,\n",
        "    \"enable_compression\": True,\n",
        "    \"use_pfl_finetune\": True,\n",
        "    # 透過此參數明確控制設備，是更佳的實踐方式\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "}\n",
        "\n",
        "print(f\"🔧 配置摘要:\")\n",
        "print(f\"   - 客戶端: {config_params['total_clients']} (真實:3, 虛擬:9)\")\n",
        "print(f\"   - 批次大小: {config_params['batch_size']}\")\n",
        "print(f\"   - FedProx μ: {config_params['fedprox_mu']} (FedAvg: 無 proximal term)\")\n",
        "print(f\"   - DP噪聲: {config_params['dp_noise_multiplier']}\")\n",
        "print(f\"   - 使用裝置: {config_params['device']}\")\n",
        "\n",
        "# 執行實驗\n",
        "start_time = time.time()\n",
        "success, result_info = run_virtual_client_experiment(config_params, DATA_PATH)\n",
        "\n",
        "if success:\n",
        "    experiment_results.append({\n",
        "        'seed': seed,\n",
        "        'mode': mode,\n",
        "        'success': True,\n",
        "        'result_info': result_info\n",
        "    })\n",
        "    print(f\"\\n✅ {mode} 實驗成功\")\n",
        "\n",
        "    # 顯示關鍵指標\n",
        "    if result_info and 'avg_rewards' in result_info:\n",
        "        rewards = result_info['avg_rewards']\n",
        "        print(f\"   - 全域獎勵: {rewards['global']:.4f}\")\n",
        "        print(f\"   - 個人化獎勵: {rewards['personalized']:.4f}\")\n",
        "        if result_info.get('privacy_stats'):\n",
        "            privacy = result_info['privacy_stats']\n",
        "            print(f\"   - ε消耗: {privacy['consumed_epsilon']:.4f}\")\n",
        "            print(f\"   - 重設次數: {privacy['reset_count']}\")\n",
        "else:\n",
        "    experiment_results.append({\n",
        "        'seed': seed,\n",
        "        'mode': mode,\n",
        "        'success': False,\n",
        "        'result_info': None\n",
        "    })\n",
        "    print(f\"\\n❌ {mode} 實驗失敗\")\n",
        "\n",
        "execution_time = (time.time() - start_time) / 60\n",
        "print(f\"\\n⏱️ FedAvg 實驗執行時間: {execution_time:.2f} 分鐘\")\n",
        "\n",
        "# 清理資源\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# 最佳化實踐：由於未在全局設定預設張量類型，此處也無需重設。\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"實驗 3 完成\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wRfahNQjFqxN"
      },
      "outputs": [],
      "source": [
        "# @title Cell 8F: 📊 實驗總結\n",
        "print(\"=\"*60)\n",
        "print(\"🎉 所有實驗執行完成！\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 統計成功率\n",
        "successful_experiments = sum(1 for r in experiment_results if r['success'])\n",
        "total_experiments = len(experiment_results)\n",
        "success_rate = (successful_experiments / total_experiments) * 100 if total_experiments > 0 else 0\n",
        "\n",
        "print(f\"\\n📊 實驗統計:\")\n",
        "print(f\"   - 總實驗數: {total_experiments}\")\n",
        "print(f\"   - 成功數: {successful_experiments}\")\n",
        "print(f\"   - 成功率: {success_rate:.1f}%\")\n",
        "\n",
        "# 成功實驗的詳細統計\n",
        "successful_results = [r for r in experiment_results if r['success']]\n",
        "if successful_results:\n",
        "    print(f\"\\n📈 成功實驗詳細結果:\")\n",
        "    for result in successful_results:\n",
        "        mode = result['mode']\n",
        "        info = result['result_info']\n",
        "        if info and 'avg_rewards' in info:\n",
        "            rewards = info['avg_rewards']\n",
        "            print(f\"\\n   {mode}:\")\n",
        "            print(f\"     - 全域獎勵: {rewards['global']:.4f}\")\n",
        "            print(f\"     - 個人化獎勵: {rewards['personalized']:.4f}\")\n",
        "            print(f\"     - PFL微調獎勵: {rewards['pfl']:.4f}\")\n",
        "            print(f\"     - 個人化提升: {((rewards['personalized']/rewards['global']-1)*100):.2f}%\")\n",
        "            print(f\"     - 執行時間: {info['execution_time']:.2f} 分鐘\")\n",
        "\n",
        "            if info.get('privacy_stats'):\n",
        "                privacy = info['privacy_stats']\n",
        "                print(f\"     - ε消耗: {privacy['consumed_epsilon']:.4f}\")\n",
        "                print(f\"     - 重設次數: {privacy['reset_count']}\")\n",
        "                print(f\"     - 隱私效率: {rewards['global']/privacy['consumed_epsilon']:.4f} (獎勵/ε)\")\n",
        "\n",
        "    # 比較不同方法\n",
        "    if len(successful_results) > 1:\n",
        "        print(f\"\\n📊 方法比較:\")\n",
        "        modes_data = []\n",
        "        for result in successful_results:\n",
        "            if result['result_info'] and 'avg_rewards' in result['result_info']:\n",
        "                modes_data.append({\n",
        "                    'mode': result['mode'],\n",
        "                    'global_reward': result['result_info']['avg_rewards']['global'],\n",
        "                    'personalized_reward': result['result_info']['avg_rewards']['personalized'],\n",
        "                    'epsilon': result['result_info']['privacy_stats']['consumed_epsilon'] if result['result_info'].get('privacy_stats') else 0\n",
        "                })\n",
        "\n",
        "        if modes_data:\n",
        "            # 找出最佳方法\n",
        "            best_global = max(modes_data, key=lambda x: x['global_reward'])\n",
        "            best_personalized = max(modes_data, key=lambda x: x['personalized_reward'])\n",
        "\n",
        "            print(f\"   - 最佳全域獎勵: {best_global['mode']} ({best_global['global_reward']:.4f})\")\n",
        "            print(f\"   - 最佳個人化獎勵: {best_personalized['mode']} ({best_personalized['personalized_reward']:.4f})\")\n",
        "\n",
        "            if any(m['epsilon'] > 0 for m in modes_data):\n",
        "                best_privacy_efficiency = max(\n",
        "                    (m for m in modes_data if m['epsilon'] > 0),\n",
        "                    key=lambda x: x['global_reward']/x['epsilon']\n",
        "                )\n",
        "                print(f\"   - 最佳隱私效率: {best_privacy_efficiency['mode']} ({best_privacy_efficiency['global_reward']/best_privacy_efficiency['epsilon']:.4f} 獎勵/ε)\")\n",
        "\n",
        "print(f\"\\n🔄 虛擬客戶端方法總結:\")\n",
        "print(f\"   - 客戶端擴增: 3 → 12 (4倍增長)\")\n",
        "print(f\"   - 學術合理性: ✅ 基於時間分割的標準方法\")\n",
        "print(f\"   - 隱私保護: ✅ 非重疊數據 + DP噪聲\")\n",
        "print(f\"   - 統計多樣性: ✅ 保持原始數據特性\")\n",
        "print(f\"   - GPU加速: ✅ 已優化\")\n",
        "\n",
        "print(f\"\\n📁 結果已保存至: {BASE_OUTPUT_DIR}\")\n",
        "\n",
        "# 保存實驗總結\n",
        "import json\n",
        "summary_path = os.path.join(BASE_OUTPUT_DIR, \"experiment_summary.json\")\n",
        "with open(summary_path, 'w') as f:\n",
        "    json.dump({\n",
        "        'total_experiments': total_experiments,\n",
        "        'successful_experiments': successful_experiments,\n",
        "        'success_rate': success_rate,\n",
        "        'results': experiment_results\n",
        "    }, f, indent=4)\n",
        "print(f\"📄 實驗總結已保存至: {summary_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ 所有實驗完成！\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "izZVG_0CIV2e",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title Cell 9: 📊 結果視覺化（英文版）\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "def load_all_results(base_output_dir):\n",
        "    all_evals, all_histories, all_privacies = [], [], []\n",
        "    config_data = None\n",
        "\n",
        "    if not os.path.exists(base_output_dir):\n",
        "        print(f\"❌ Results directory not found: {base_output_dir}\")\n",
        "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), None\n",
        "\n",
        "    # Try to load configuration files first\n",
        "    config_files = glob.glob(os.path.join(base_output_dir, '**', '*_config.json'), recursive=True)\n",
        "    if config_files:\n",
        "        try:\n",
        "            with open(config_files[0], 'r') as f:\n",
        "                config_data = json.load(f)\n",
        "        except Exception as e:\n",
        "            print(f\"🟡 Warning: Failed to read config file: {e}\")\n",
        "\n",
        "    # List found files for debugging\n",
        "    print(f\"🔍 Searching directory: {base_output_dir}\")\n",
        "    if os.path.exists(base_output_dir):\n",
        "        print(f\"📁 Found subdirectories:\")\n",
        "        for item in sorted(os.listdir(base_output_dir)):\n",
        "            item_path = os.path.join(base_output_dir, item)\n",
        "            if os.path.isdir(item_path):\n",
        "                print(f\"   📂 {item}\")\n",
        "                for subitem in sorted(os.listdir(item_path)):\n",
        "                    subitem_path = os.path.join(item_path, subitem)\n",
        "                    if os.path.isdir(subitem_path):\n",
        "                        print(f\"      📂 {subitem}\")\n",
        "                        csv_files = glob.glob(os.path.join(subitem_path, \"*.csv\"))\n",
        "                        for csv_file in csv_files:\n",
        "                            print(f\"         📄 {os.path.basename(csv_file)}\")\n",
        "\n",
        "    for seed_folder in sorted(os.listdir(base_output_dir)):\n",
        "        if not seed_folder.startswith('seed_'): continue\n",
        "        try:\n",
        "            seed = int(seed_folder.split('_')[1])\n",
        "        except (ValueError, IndexError):\n",
        "            continue\n",
        "\n",
        "        for mode_folder in sorted(os.listdir(os.path.join(base_output_dir, seed_folder))):\n",
        "            exp_path = os.path.join(base_output_dir, seed_folder, mode_folder)\n",
        "            if not os.path.isdir(exp_path): continue\n",
        "\n",
        "            eval_files = glob.glob(os.path.join(exp_path, '*_evaluation_results.csv'))\n",
        "            history_files = glob.glob(os.path.join(exp_path, '*_training_history.csv'))\n",
        "            privacy_files = glob.glob(os.path.join(exp_path, '*_privacy_costs.csv'))\n",
        "\n",
        "            def read_and_append(file_list, data_list, mode_name, seed_val):\n",
        "                if not file_list:\n",
        "                    print(f\"🟡 Warning: No files found for {mode_name} (seed {seed_val})\")\n",
        "                    return\n",
        "                file_path = file_list[0]\n",
        "                try:\n",
        "                    if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
        "                        df = pd.read_csv(file_path)\n",
        "                        df['mode'] = mode_name\n",
        "                        df['seed'] = seed_val\n",
        "                        data_list.append(df)\n",
        "                        print(f\"✅ Successfully loaded: {mode_name} (seed {seed_val}) - {len(df)} rows\")\n",
        "                    else:\n",
        "                        print(f\"🟡 Warning: File is empty or doesn't exist: {file_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"🟡 Warning: Failed to read file: {file_path}, {e}\")\n",
        "\n",
        "            read_and_append(eval_files, all_evals, mode_folder, seed)\n",
        "            read_and_append(history_files, all_histories, mode_folder, seed)\n",
        "            read_and_append(privacy_files, all_privacies, mode_folder, seed)\n",
        "\n",
        "    return (pd.concat(all_evals, ignore_index=True) if all_evals else pd.DataFrame()), \\\n",
        "           (pd.concat(all_histories, ignore_index=True) if all_histories else pd.DataFrame()), \\\n",
        "           (pd.concat(all_privacies, ignore_index=True) if all_privacies else pd.DataFrame()), \\\n",
        "           config_data\n",
        "\n",
        "# --- Visualization Settings ---\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
        "BASE_WORK_DIR = \"/content/drive/MyDrive/FRL_Slicing_Sim\"\n",
        "BASE_OUTPUT_DIR = os.path.join(BASE_WORK_DIR, \"outputs_virtual_clients_gpu\")  # Match Cell 8 path\n",
        "FIGURES_OUTPUT_DIR = os.path.join(BASE_OUTPUT_DIR, \"figures\")\n",
        "os.makedirs(FIGURES_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"🔍 Loading results from: {BASE_OUTPUT_DIR}\")\n",
        "eval_df, history_df, privacy_df, loaded_config = load_all_results(BASE_OUTPUT_DIR)\n",
        "\n",
        "if eval_df.empty and history_df.empty:\n",
        "    print(\"❌ No result files found, cannot generate plots. Please ensure Cell 8 has completed successfully.\")\n",
        "    print(f\"📁 Expected path: {BASE_OUTPUT_DIR}\")\n",
        "    print(f\"📁 Path exists: {os.path.exists(BASE_OUTPUT_DIR)}\")\n",
        "else:\n",
        "    # Corrected settings to match Cell 8\n",
        "    SEEDS = [42]  # Only one seed\n",
        "    mode_order = [\"Centralized\", \"Isolated\", \"FedAvg\", \"FedProx\", \"ClusteredFL\"]  # Removed Centralized\n",
        "\n",
        "    print(f\"✅ Successfully loaded results from {len(eval_df['seed'].unique()) if not eval_df.empty else 0} runs.\")\n",
        "    if not eval_df.empty:\n",
        "        print(f\"📊 Found modes: {sorted(eval_df['mode'].unique())}\")\n",
        "        print(f\"📊 Found seeds: {sorted(eval_df['seed'].unique())}\")\n",
        "\n",
        "    # --- Figure 1: Training History Comparison ---\n",
        "    if not history_df.empty:\n",
        "        plt.figure(figsize=(15, 8))\n",
        "\n",
        "        # Only plot existing modes\n",
        "        available_modes = [mode for mode in mode_order if mode in history_df['mode'].unique()]\n",
        "\n",
        "        sns.lineplot(data=history_df, x='round', y='avg_reward', hue='mode',\n",
        "                     hue_order=available_modes, errorbar=('sd', 1), linewidth=2.5,\n",
        "                     err_style=\"band\", alpha=0.8)\n",
        "\n",
        "        plt.title('Differentially Private Federated Reinforcement Learning Training Performance', fontsize=18, weight='bold')\n",
        "        plt.xlabel('Communication Round / Equivalent Round', fontsize=14)\n",
        "        plt.ylabel('Average Episodic Reward', fontsize=14)\n",
        "        plt.legend(title='Training Mode', fontsize=12)\n",
        "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "        plt.xlim(0, 25)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'training_history_dp_eng.png'), dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"🟡 Warning: No training history data found\")\n",
        "\n",
        "    # --- Figure 2: Final Performance Comparison ---\n",
        "    if not eval_df.empty:\n",
        "        eval_to_plot = eval_df.rename(columns={'reward_pfl_finetuned': 'Final Reward Score'})\n",
        "        available_modes = [mode for mode in mode_order if mode in eval_to_plot['mode'].unique()]\n",
        "\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        ax = sns.boxplot(data=eval_to_plot, x='mode', y='Final Reward Score',\n",
        "                         order=available_modes, palette=\"viridis\")\n",
        "\n",
        "        # Add median annotations\n",
        "        medians = eval_to_plot.groupby(['mode'])['Final Reward Score'].median().reindex(available_modes)\n",
        "        for xtick in ax.get_xticks():\n",
        "            if xtick < len(available_modes):\n",
        "                mode_name = available_modes[xtick]\n",
        "                median_val = medians.get(mode_name)\n",
        "                if pd.notna(median_val):\n",
        "                    ax.text(xtick, median_val + 5, f'Median: {median_val:.1f}',\n",
        "                            horizontalalignment='center', size='medium',\n",
        "                            color='black', weight='semibold',\n",
        "                            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
        "\n",
        "        plt.title('Differentially Private Federated Learning Final Performance Comparison', fontsize=18)\n",
        "        plt.xlabel('Experiment Mode', fontsize=14)\n",
        "        plt.ylabel('Final Reward Score', fontsize=14)\n",
        "        plt.xticks(rotation=15)\n",
        "\n",
        "        # Statistical testing\n",
        "        groups = [eval_to_plot['Final Reward Score'][eval_to_plot['mode'] == m].dropna()\n",
        "                 for m in available_modes if m in eval_to_plot['mode'].unique()]\n",
        "        if len(groups) > 1:\n",
        "            h_stat, p_value = stats.kruskal(*groups)\n",
        "            plt.figtext(0.5, 0.01, f'Kruskal-Wallis Test: H = {h_stat:.2f}, p = {p_value:.4f}',\n",
        "                        ha='center', fontsize=12,\n",
        "                        bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 1])\n",
        "        plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'final_performance_dp_eng.png'), dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"🟡 Warning: No evaluation results data found\")\n",
        "\n",
        "    # --- Figure 3: Personalization Benefit Analysis ---\n",
        "    if not eval_df.empty:\n",
        "        first_seed = SEEDS[0]\n",
        "        # Prefer ClusteredFL, otherwise use the first available mode\n",
        "        if 'ClusteredFL' in eval_df['mode'].unique():\n",
        "            target_mode = 'ClusteredFL'\n",
        "        else:\n",
        "            target_mode = eval_df['mode'].unique()[0]\n",
        "\n",
        "        target_eval = eval_df[(eval_df['mode'] == target_mode) & (eval_df['seed'] == first_seed)]\n",
        "\n",
        "        if not target_eval.empty:\n",
        "            target_melted = target_eval.melt(\n",
        "                id_vars=['client_id'],\n",
        "                value_vars=['reward_global', 'reward_personalized', 'reward_pfl_finetuned'],\n",
        "                var_name='Model Type', value_name='Average Reward'\n",
        "            )\n",
        "\n",
        "            plt.figure(figsize=(14, 7))\n",
        "            sns.barplot(data=target_melted, x='client_id', y='Average Reward',\n",
        "                       hue='Model Type', palette='viridis')\n",
        "\n",
        "            plt.title(f'{target_mode} Mode Personalization Benefits Analysis (Seed={first_seed})', fontsize=16)\n",
        "            plt.xlabel('Client ID', fontsize=14)\n",
        "            plt.ylabel('Average Reward', fontsize=14)\n",
        "            plt.legend(title='Model Type', fontsize=12)\n",
        "            plt.grid(axis='y', linestyle='--')\n",
        "            plt.tight_layout()\n",
        "\n",
        "            plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'personalization_benefit_dp_eng.png'), dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"🟡 Warning: No data found for {target_mode} mode\")\n",
        "\n",
        "    # --- Figure 4: Privacy Cost Tracking ---\n",
        "    if not privacy_df.empty:\n",
        "        privacy_to_plot = privacy_df[privacy_df['mode'].isin(['FedAvg', 'FedProx', 'ClusteredFL'])]\n",
        "\n",
        "        if not privacy_to_plot.empty:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            sns.lineplot(data=privacy_to_plot, x='round', y='cumulative_epsilon', hue='mode',\n",
        "                         errorbar=('sd', 1), linewidth=2.5)\n",
        "\n",
        "            # Add target epsilon line\n",
        "            if loaded_config and 'dp_target_epsilon' in loaded_config:\n",
        "                target_eps = loaded_config['dp_target_epsilon']\n",
        "                plt.axhline(y=target_eps, color='r', linestyle='--',\n",
        "                           label=f'Target ε = {target_eps}')\n",
        "            else:\n",
        "                # If no config file, use Cell 8 default\n",
        "                target_eps = 15.0\n",
        "                plt.axhline(y=target_eps, color='r', linestyle='--',\n",
        "                           label=f'Target ε = {target_eps}')\n",
        "\n",
        "            plt.title('Differential Privacy Budget Consumption Tracking', fontsize=16)\n",
        "            plt.xlabel('Communication Round', fontsize=14)\n",
        "            plt.ylabel('Cumulative Privacy Loss ε (Epsilon)', fontsize=14)\n",
        "            plt.legend(fontsize=12)\n",
        "            plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'privacy_cost_dp_eng.png'), dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"🟡 Warning: No privacy cost data found\")\n",
        "    else:\n",
        "        print(\"🟡 Warning: No privacy cost files found\")\n",
        "\n",
        "print(\"✅ Cell 9: Results Visualization (English Version) completed.\")\n",
        "print(f\"📁 Figures saved to: {FIGURES_OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 9: 📊 結果視覺化（修正版）\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def load_all_results(base_output_dir):\n",
        "    \"\"\"\n",
        "    改進的結果載入函數，增加更強的錯誤處理和路徑檢查\n",
        "    \"\"\"\n",
        "    all_evals, all_histories, all_privacies = [], [], []\n",
        "    config_data = None\n",
        "\n",
        "    base_path = Path(base_output_dir)\n",
        "    if not base_path.exists():\n",
        "        print(f\"❌ Results directory not found: {base_output_dir}\")\n",
        "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), None\n",
        "\n",
        "    print(f\"🔍 Searching directory: {base_output_dir}\")\n",
        "\n",
        "    # 尋找配置檔案\n",
        "    config_files = list(base_path.rglob('*_config.json'))\n",
        "    if config_files:\n",
        "        try:\n",
        "            with open(config_files[0], 'r') as f:\n",
        "                config_data = json.load(f)\n",
        "            print(f\"✅ Loaded config from: {config_files[0].name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"🟡 Warning: Failed to read config file: {e}\")\n",
        "\n",
        "    # 改進的檔案搜尋邏輯\n",
        "    found_files = {\n",
        "        'evaluation': list(base_path.rglob('*evaluation_results.csv')),\n",
        "        'history': list(base_path.rglob('*training_history.csv')),\n",
        "        'privacy': list(base_path.rglob('*privacy_costs.csv'))\n",
        "    }\n",
        "\n",
        "    print(f\"📊 Found files:\")\n",
        "    for file_type, files in found_files.items():\n",
        "        print(f\"   - {file_type}: {len(files)} files\")\n",
        "        for file_path in files[:3]:  # 只顯示前3個\n",
        "            print(f\"     📄 {file_path.relative_to(base_path)}\")\n",
        "\n",
        "    # 解析檔案路徑以提取模式和種子\n",
        "    def extract_metadata(file_path):\n",
        "        \"\"\"從檔案路徑提取實驗元資料\"\"\"\n",
        "        parts = file_path.parts\n",
        "        seed, mode = None, None\n",
        "\n",
        "        # 尋找 seed_ 資料夾\n",
        "        for part in parts:\n",
        "            if part.startswith('seed_'):\n",
        "                try:\n",
        "                    seed = int(part.split('_')[1])\n",
        "                except (ValueError, IndexError):\n",
        "                    pass\n",
        "\n",
        "        # 從檔名或路徑提取模式\n",
        "        for part in parts:\n",
        "            if part in ['FedAvg', 'FedProx', 'ClusteredFL', 'Centralized', 'Isolated']:\n",
        "                mode = part\n",
        "                break\n",
        "\n",
        "        # 如果從路徑沒找到，嘗試從檔名解析\n",
        "        if mode is None:\n",
        "            filename = file_path.stem\n",
        "            for potential_mode in ['FedAvg', 'FedProx', 'ClusteredFL', 'Centralized', 'Isolated']:\n",
        "                if potential_mode.lower() in filename.lower():\n",
        "                    mode = potential_mode\n",
        "                    break\n",
        "\n",
        "        return seed, mode\n",
        "\n",
        "    def safe_read_csv(file_path, data_list, default_seed=42, default_mode='Unknown'):\n",
        "        \"\"\"安全讀取CSV檔案\"\"\"\n",
        "        try:\n",
        "            if file_path.stat().st_size == 0:\n",
        "                print(f\"🟡 Warning: Empty file: {file_path.name}\")\n",
        "                return\n",
        "\n",
        "            df = pd.read_csv(file_path)\n",
        "            if df.empty:\n",
        "                print(f\"🟡 Warning: No data in file: {file_path.name}\")\n",
        "                return\n",
        "\n",
        "            # 提取元資料\n",
        "            seed, mode = extract_metadata(file_path)\n",
        "            if seed is None:\n",
        "                seed = default_seed\n",
        "                print(f\"🟡 Using default seed {seed} for {file_path.name}\")\n",
        "            if mode is None:\n",
        "                mode = default_mode\n",
        "                print(f\"🟡 Using default mode {mode} for {file_path.name}\")\n",
        "\n",
        "            df['seed'] = seed\n",
        "            df['mode'] = mode\n",
        "            data_list.append(df)\n",
        "            print(f\"✅ Loaded: {mode} (seed {seed}) - {len(df)} rows from {file_path.name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error reading {file_path.name}: {e}\")\n",
        "\n",
        "    # 載入所有檔案\n",
        "    for eval_file in found_files['evaluation']:\n",
        "        safe_read_csv(eval_file, all_evals)\n",
        "\n",
        "    for history_file in found_files['history']:\n",
        "        safe_read_csv(history_file, all_histories)\n",
        "\n",
        "    for privacy_file in found_files['privacy']:\n",
        "        safe_read_csv(privacy_file, all_privacies)\n",
        "\n",
        "    # 合併資料\n",
        "    eval_df = pd.concat(all_evals, ignore_index=True) if all_evals else pd.DataFrame()\n",
        "    history_df = pd.concat(all_histories, ignore_index=True) if all_histories else pd.DataFrame()\n",
        "    privacy_df = pd.concat(all_privacies, ignore_index=True) if all_privacies else pd.DataFrame()\n",
        "\n",
        "    return eval_df, history_df, privacy_df, config_data\n",
        "\n",
        "def create_summary_statistics(eval_df, history_df, privacy_df):\n",
        "    \"\"\"生成摘要統計\"\"\"\n",
        "    summary = {}\n",
        "\n",
        "    if not eval_df.empty:\n",
        "        summary['evaluation'] = {\n",
        "            'modes': list(eval_df['mode'].unique()),\n",
        "            'seeds': list(eval_df['seed'].unique()),\n",
        "            'clients': eval_df['client_id'].nunique() if 'client_id' in eval_df.columns else 0,\n",
        "            'reward_stats': eval_df[['reward_global', 'reward_personalized', 'reward_pfl_finetuned']].describe().round(4).to_dict() if all(col in eval_df.columns for col in ['reward_global', 'reward_personalized', 'reward_pfl_finetuned']) else {}\n",
        "        }\n",
        "\n",
        "    if not history_df.empty:\n",
        "        summary['training'] = {\n",
        "            'total_rounds': history_df['round'].max() if 'round' in history_df.columns else 0,\n",
        "            'reward_progression': history_df.groupby('mode')['avg_reward'].agg(['min', 'max', 'mean']).round(4).to_dict() if 'avg_reward' in history_df.columns else {}\n",
        "        }\n",
        "\n",
        "    if not privacy_df.empty:\n",
        "        summary['privacy'] = {\n",
        "            'max_epsilon': privacy_df['cumulative_epsilon'].max() if 'cumulative_epsilon' in privacy_df.columns else 0,\n",
        "            'reset_info': privacy_df.groupby('mode')['reset_count'].max().to_dict() if 'reset_count' in privacy_df.columns else {}\n",
        "        }\n",
        "\n",
        "    return summary\n",
        "\n",
        "# --- 主要執行邏輯 ---\n",
        "# 設定視覺化樣式\n",
        "plt.style.use('seaborn-v0_8')  # 修正 seaborn 樣式\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# 路徑設定 - 修正路徑匹配\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    BASE_WORK_DIR = \"/content/drive/MyDrive/FRL_Slicing_Sim\"\n",
        "except ImportError:\n",
        "    BASE_WORK_DIR = \"./FRL_Slicing_Sim\"\n",
        "\n",
        "BASE_OUTPUT_DIR = os.path.join(BASE_WORK_DIR, \"outputs_virtual_clients_gpu\")\n",
        "FIGURES_OUTPUT_DIR = os.path.join(BASE_OUTPUT_DIR, \"figures\")\n",
        "os.makedirs(FIGURES_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"🔍 Loading results from: {BASE_OUTPUT_DIR}\")\n",
        "eval_df, history_df, privacy_df, loaded_config = load_all_results(BASE_OUTPUT_DIR)\n",
        "\n",
        "# 生成摘要統計\n",
        "if not (eval_df.empty and history_df.empty and privacy_df.empty):\n",
        "    summary_stats = create_summary_statistics(eval_df, history_df, privacy_df)\n",
        "    print(\"\\n📊 Data Summary:\")\n",
        "    print(json.dumps(summary_stats, indent=2))\n",
        "\n",
        "if eval_df.empty and history_df.empty and privacy_df.empty:\n",
        "    print(\"❌ No result files found. Please check:\")\n",
        "    print(f\"   1. Experiments have completed successfully\")\n",
        "    print(f\"   2. Output directory exists: {BASE_OUTPUT_DIR}\")\n",
        "    print(f\"   3. CSV files are present in subdirectories\")\n",
        "\n",
        "    # 提供目錄結構診斷\n",
        "    if os.path.exists(BASE_OUTPUT_DIR):\n",
        "        print(f\"\\n🔍 Directory structure diagnosis:\")\n",
        "        for root, dirs, files in os.walk(BASE_OUTPUT_DIR):\n",
        "            level = root.replace(BASE_OUTPUT_DIR, '').count(os.sep)\n",
        "            indent = ' ' * 2 * level\n",
        "            print(f\"{indent}{os.path.basename(root)}/\")\n",
        "            subindent = ' ' * 2 * (level + 1)\n",
        "            for file in files:\n",
        "                print(f\"{subindent}{file}\")\n",
        "else:\n",
        "    # 繼續原有的視覺化邏輯，但加入更多錯誤檢查\n",
        "    mode_order = [\"Centralized\", \"Isolated\", \"FedAvg\", \"FedProx\", \"ClusteredFL\"]\n",
        "    available_modes = []\n",
        "\n",
        "    if not eval_df.empty:\n",
        "        available_modes = [mode for mode in mode_order if mode in eval_df['mode'].unique()]\n",
        "        print(f\"✅ Available modes for visualization: {available_modes}\")\n",
        "\n",
        "    # --- Figure 1: Training History ---\n",
        "    if not history_df.empty and 'avg_reward' in history_df.columns:\n",
        "        plt.figure(figsize=(15, 8))\n",
        "\n",
        "        # 檢查數據完整性\n",
        "        if history_df['avg_reward'].isna().all():\n",
        "            print(\"⚠️ Warning: All reward values are NaN\")\n",
        "        else:\n",
        "            available_modes_history = [mode for mode in mode_order if mode in history_df['mode'].unique()]\n",
        "\n",
        "            if available_modes_history:\n",
        "                sns.lineplot(data=history_df, x='round', y='avg_reward', hue='mode',\n",
        "                           hue_order=available_modes_history, errorbar=('sd', 1),\n",
        "                           linewidth=2.5, marker='o', markersize=4)\n",
        "\n",
        "                plt.title('Federated Reinforcement Learning Training Performance\\n(Virtual Client Augmentation)',\n",
        "                         fontsize=16, weight='bold', pad=20)\n",
        "                plt.xlabel('Communication Round', fontsize=14)\n",
        "                plt.ylabel('Average Episodic Reward', fontsize=14)\n",
        "                plt.legend(title='Training Mode', fontsize=11, title_fontsize=12)\n",
        "                plt.grid(True, alpha=0.3)\n",
        "\n",
        "                # 添加最佳性能註釋\n",
        "                if len(available_modes_history) > 1:\n",
        "                    final_performance = history_df.groupby('mode')['avg_reward'].last()\n",
        "                    best_mode = final_performance.idxmax()\n",
        "                    best_reward = final_performance.max()\n",
        "                    plt.figtext(0.02, 0.02, f'Best Final Performance: {best_mode} ({best_reward:.2f})',\n",
        "                               fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\", alpha=0.7))\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'training_performance.png'),\n",
        "                           dpi=300, bbox_inches='tight', facecolor='white')\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"⚠️ No valid modes found in training history\")\n",
        "    else:\n",
        "        print(\"🟡 Skipping training history plot - insufficient data\")\n",
        "\n",
        "    # --- Figure 2: Final Performance Comparison ---\n",
        "    if not eval_df.empty and available_modes:\n",
        "        # 選擇最佳的評估指標\n",
        "        reward_columns = ['reward_pfl_finetuned', 'reward_personalized', 'reward_global']\n",
        "        best_reward_col = None\n",
        "        for col in reward_columns:\n",
        "            if col in eval_df.columns and not eval_df[col].isna().all():\n",
        "                best_reward_col = col\n",
        "                break\n",
        "\n",
        "        if best_reward_col:\n",
        "            plt.figure(figsize=(14, 8))\n",
        "\n",
        "            # 創建boxplot\n",
        "            ax = sns.boxplot(data=eval_df, x='mode', y=best_reward_col,\n",
        "                           order=available_modes, palette=\"Set2\")\n",
        "\n",
        "            # 添加散點圖顯示原始數據\n",
        "            sns.stripplot(data=eval_df, x='mode', y=best_reward_col,\n",
        "                         order=available_modes, color='black', alpha=0.6, size=3)\n",
        "\n",
        "            # 計算並顯示統計資訊\n",
        "            stats_data = eval_df.groupby('mode')[best_reward_col].agg(['count', 'mean', 'std']).round(3)\n",
        "\n",
        "            for i, mode in enumerate(available_modes):\n",
        "                if mode in stats_data.index:\n",
        "                    mean_val = stats_data.loc[mode, 'mean']\n",
        "                    std_val = stats_data.loc[mode, 'std']\n",
        "                    count_val = stats_data.loc[mode, 'count']\n",
        "\n",
        "                    ax.text(i, ax.get_ylim()[1] * 0.95,\n",
        "                           f'μ={mean_val:.2f}\\nσ={std_val:.2f}\\nn={count_val}',\n",
        "                           ha='center', va='top', fontsize=9,\n",
        "                           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
        "\n",
        "            plt.title(f'Final Performance Comparison\\n({best_reward_col.replace(\"_\", \" \").title()})',\n",
        "                     fontsize=16, weight='bold')\n",
        "            plt.xlabel('Federated Learning Method', fontsize=14)\n",
        "            plt.ylabel('Average Reward Score', fontsize=14)\n",
        "            plt.xticks(rotation=15)\n",
        "\n",
        "            # 統計顯著性檢驗\n",
        "            if len(available_modes) > 1:\n",
        "                groups = [eval_df[best_reward_col][eval_df['mode'] == mode].dropna()\n",
        "                         for mode in available_modes]\n",
        "                groups = [g for g in groups if len(g) > 1]  # 過濾空組\n",
        "\n",
        "                if len(groups) > 1:\n",
        "                    try:\n",
        "                        h_stat, p_value = stats.kruskal(*groups)\n",
        "                        significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
        "                        plt.figtext(0.5, 0.02,\n",
        "                                   f'Kruskal-Wallis: H={h_stat:.2f}, p={p_value:.4f} {significance}',\n",
        "                                   ha='center', fontsize=11,\n",
        "                                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\"))\n",
        "                    except Exception as e:\n",
        "                        print(f\"⚠️ Statistical test failed: {e}\")\n",
        "\n",
        "            plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
        "            plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'final_performance_comparison.png'),\n",
        "                       dpi=300, bbox_inches='tight', facecolor='white')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"🟡 No valid reward columns found for performance comparison\")\n",
        "\n",
        "    # --- Figure 3: Privacy-Performance Trade-off ---\n",
        "    if not privacy_df.empty and not eval_df.empty:\n",
        "        # 合併隱私和性能數據\n",
        "        privacy_summary = privacy_df.groupby(['mode', 'seed'])['cumulative_epsilon'].max().reset_index()\n",
        "        eval_summary = eval_df.groupby(['mode', 'seed'])['reward_global'].mean().reset_index()\n",
        "\n",
        "        combined_data = pd.merge(privacy_summary, eval_summary, on=['mode', 'seed'], how='inner')\n",
        "\n",
        "        if not combined_data.empty:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "\n",
        "            # 創建散點圖\n",
        "            for mode in combined_data['mode'].unique():\n",
        "                mode_data = combined_data[combined_data['mode'] == mode]\n",
        "                plt.scatter(mode_data['cumulative_epsilon'], mode_data['reward_global'],\n",
        "                           label=mode, s=100, alpha=0.7)\n",
        "\n",
        "            # 添加理想線（假設的帕累托前沿）\n",
        "            if len(combined_data) > 2:\n",
        "                # 簡單的趨勢線\n",
        "                from scipy import stats as scipy_stats\n",
        "                slope, intercept, r_value, p_value, std_err = scipy_stats.linregress(\n",
        "                    combined_data['cumulative_epsilon'], combined_data['reward_global'])\n",
        "\n",
        "                x_trend = np.linspace(combined_data['cumulative_epsilon'].min(),\n",
        "                                    combined_data['cumulative_epsilon'].max(), 100)\n",
        "                y_trend = slope * x_trend + intercept\n",
        "                plt.plot(x_trend, y_trend, '--', color='red', alpha=0.5,\n",
        "                        label=f'Trend (R²={r_value**2:.3f})')\n",
        "\n",
        "            plt.xlabel('Privacy Cost (Cumulative ε)', fontsize=14)\n",
        "            plt.ylabel('Average Reward Performance', fontsize=14)\n",
        "            plt.title('Privacy-Performance Trade-off Analysis', fontsize=16, weight='bold')\n",
        "            plt.legend(fontsize=12)\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            # 標註最佳隱私效率點\n",
        "            if 'cumulative_epsilon' in combined_data.columns and combined_data['cumulative_epsilon'].max() > 0:\n",
        "                combined_data['privacy_efficiency'] = combined_data['reward_global'] / combined_data['cumulative_epsilon']\n",
        "                best_efficiency = combined_data.loc[combined_data['privacy_efficiency'].idxmax()]\n",
        "                plt.annotate(f'Best Efficiency\\n{best_efficiency[\"mode\"]}',\n",
        "                           xy=(best_efficiency['cumulative_epsilon'], best_efficiency['reward_global']),\n",
        "                           xytext=(10, 10), textcoords='offset points',\n",
        "                           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
        "                           arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'privacy_performance_tradeoff.png'),\n",
        "                       dpi=300, bbox_inches='tight', facecolor='white')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"🟡 Cannot create privacy-performance plot - insufficient overlapping data\")\n",
        "\n",
        "    # --- Figure 4: Virtual Client Benefits ---\n",
        "    if not eval_df.empty and 'client_id' in eval_df.columns:\n",
        "        # 分析虛擬客戶端的效益\n",
        "        target_mode = 'ClusteredFL' if 'ClusteredFL' in eval_df['mode'].unique() else eval_df['mode'].unique()[0]\n",
        "        target_data = eval_df[eval_df['mode'] == target_mode]\n",
        "\n",
        "        if not target_data.empty and len(target_data) >= 6:  # 確保有足夠的客戶端\n",
        "            # 假設前3個是真實客戶端，其餘是虛擬客戶端\n",
        "            real_clients = target_data[target_data['client_id'] < 3]\n",
        "            virtual_clients = target_data[target_data['client_id'] >= 3]\n",
        "\n",
        "            plt.figure(figsize=(14, 6))\n",
        "\n",
        "            reward_col = 'reward_pfl_finetuned' if 'reward_pfl_finetuned' in target_data.columns else 'reward_global'\n",
        "\n",
        "            # 比較真實 vs 虛擬客戶端性能\n",
        "            comparison_data = []\n",
        "            if not real_clients.empty:\n",
        "                comparison_data.append({'Type': 'Real Clients', 'Reward': real_clients[reward_col].mean(), 'Count': len(real_clients)})\n",
        "            if not virtual_clients.empty:\n",
        "                comparison_data.append({'Type': 'Virtual Clients', 'Reward': virtual_clients[reward_col].mean(), 'Count': len(virtual_clients)})\n",
        "\n",
        "            if comparison_data:\n",
        "                comp_df = pd.DataFrame(comparison_data)\n",
        "                bars = plt.bar(comp_df['Type'], comp_df['Reward'],\n",
        "                              color=['skyblue', 'lightcoral'], alpha=0.8)\n",
        "\n",
        "                # 添加數值標籤\n",
        "                for bar, row in zip(bars, comp_df.itertuples()):\n",
        "                    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                           f'{row.Reward:.3f}\\n(n={row.Count})',\n",
        "                           ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "                plt.title(f'Virtual Client Augmentation Benefits\\n({target_mode} Mode)',\n",
        "                         fontsize=16, weight='bold')\n",
        "                plt.ylabel('Average Reward Score', fontsize=14)\n",
        "                plt.xlabel('Client Type', fontsize=14)\n",
        "\n",
        "                # 計算改進百分比\n",
        "                if len(comp_df) == 2:\n",
        "                    improvement = ((comp_df.iloc[1]['Reward'] / comp_df.iloc[0]['Reward']) - 1) * 100\n",
        "                    plt.figtext(0.5, 0.02, f'Virtual clients show {improvement:+.1f}% performance difference',\n",
        "                               ha='center', fontsize=12,\n",
        "                               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\" if improvement > 0 else \"lightpink\"))\n",
        "\n",
        "                plt.grid(axis='y', alpha=0.3)\n",
        "                plt.tight_layout(rect=[0, 0.08, 1, 1])\n",
        "                plt.savefig(os.path.join(FIGURES_OUTPUT_DIR, 'virtual_client_benefits.png'),\n",
        "                           dpi=300, bbox_inches='tight', facecolor='white')\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"🟡 Insufficient data for virtual client comparison\")\n",
        "\n",
        "print(f\"\\n✅ Visualization completed!\")\n",
        "print(f\"📁 All figures saved to: {FIGURES_OUTPUT_DIR}\")\n",
        "\n",
        "# 生成最終報告\n",
        "if not (eval_df.empty and history_df.empty and privacy_df.empty):\n",
        "    report_path = os.path.join(FIGURES_OUTPUT_DIR, \"experiment_report.txt\")\n",
        "    with open(report_path, 'w') as f:\n",
        "        f.write(\"Federated Reinforcement Learning Experiment Report\\n\")\n",
        "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "        if not eval_df.empty:\n",
        "            f.write(\"PERFORMANCE SUMMARY:\\n\")\n",
        "            for mode in eval_df['mode'].unique():\n",
        "                mode_data = eval_df[eval_df['mode'] == mode]\n",
        "                if 'reward_global' in mode_data.columns:\n",
        "                    avg_reward = mode_data['reward_global'].mean()\n",
        "                    f.write(f\"  {mode}: {avg_reward:.4f} average reward\\n\")\n",
        "\n",
        "        if not privacy_df.empty:\n",
        "            f.write(f\"\\nPRIVACY ANALYSIS:\\n\")\n",
        "            max_epsilon = privacy_df['cumulative_epsilon'].max()\n",
        "            f.write(f\"  Maximum privacy cost: ε = {max_epsilon:.4f}\\n\")\n",
        "\n",
        "        f.write(f\"\\nDATA QUALITY:\\n\")\n",
        "        f.write(f\"  Evaluation records: {len(eval_df)}\\n\")\n",
        "        f.write(f\"  Training records: {len(history_df)}\\n\")\n",
        "        f.write(f\"  Privacy records: {len(privacy_df)}\\n\")\n",
        "\n",
        "    print(f\"📄 Detailed report saved to: {report_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eRyd8I7o2l4U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "adf6d4d8b8bb4e0a94833044bd43d7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90cb0f7ce15f4320bf1533860a33ba72",
              "IPY_MODEL_79233c6a328f43d38bd153fb7be6ac53",
              "IPY_MODEL_8177404e6c3e49fcb7a282fc9dc511aa"
            ],
            "layout": "IPY_MODEL_23fbd48c5c6240e09d8b90cb16e69f50"
          }
        },
        "90cb0f7ce15f4320bf1533860a33ba72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e08b6bb93964764abb8a92b0bf11697",
            "placeholder": "​",
            "style": "IPY_MODEL_fba740bc81ea45e19f28784ceeae705a",
            "value": "處理客戶端數據: 100%"
          }
        },
        "79233c6a328f43d38bd153fb7be6ac53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_641052e8de5a4bf8a800409f33944ca9",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50037d1d410442b8aeddd1c232946536",
            "value": 3
          }
        },
        "8177404e6c3e49fcb7a282fc9dc511aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b1351faa78e4e9ba7337bfa9657cf2f",
            "placeholder": "​",
            "style": "IPY_MODEL_901a2caee05d45d8b91a9d4db2b952f4",
            "value": " 3/3 [00:00&lt;00:00,  3.21it/s]"
          }
        },
        "23fbd48c5c6240e09d8b90cb16e69f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e08b6bb93964764abb8a92b0bf11697": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba740bc81ea45e19f28784ceeae705a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "641052e8de5a4bf8a800409f33944ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50037d1d410442b8aeddd1c232946536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b1351faa78e4e9ba7337bfa9657cf2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "901a2caee05d45d8b91a9d4db2b952f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d3d1404483f441db96027bb518bd35d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cde168f1fb1a4c8dac2752e3df87020a",
              "IPY_MODEL_09dd428dd809495c89c2c2c1cc35f6c5",
              "IPY_MODEL_e9fbf4d213f24882bbf9c2d92bbec63e"
            ],
            "layout": "IPY_MODEL_4538927fab94458191b9cd1c2ba3db54"
          }
        },
        "cde168f1fb1a4c8dac2752e3df87020a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2a7a40f85974863bd7830c990683d4c",
            "placeholder": "​",
            "style": "IPY_MODEL_296ba0f6a70e4592affde73d0bacd733",
            "value": "ClusteredFL Training:   7%"
          }
        },
        "09dd428dd809495c89c2c2c1cc35f6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdafbc16c86f422c895f56a4342b72e9",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25c9727ea9f642b788851b2dbe66feb7",
            "value": 1
          }
        },
        "e9fbf4d213f24882bbf9c2d92bbec63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d9153f821734f3e827f175ec86ed42d",
            "placeholder": "​",
            "style": "IPY_MODEL_f3922222487a40b3b940e4b5132ae615",
            "value": " 1/15 [07:23&lt;1:43:27, 443.37s/it, reward=285.36, loss=13177611.5907, ε_used=7.500, resets=0]"
          }
        },
        "4538927fab94458191b9cd1c2ba3db54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a7a40f85974863bd7830c990683d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "296ba0f6a70e4592affde73d0bacd733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdafbc16c86f422c895f56a4342b72e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25c9727ea9f642b788851b2dbe66feb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d9153f821734f3e827f175ec86ed42d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3922222487a40b3b940e4b5132ae615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}